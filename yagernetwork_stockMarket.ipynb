{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries \n",
    "import keras #library for neural network\n",
    "import pandas as pd #loading data in table form  \n",
    "import seaborn as sns #visualisation \n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import normalize #machine learning algorithm library\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout, LSTM\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "import yfinance as yf\n",
    "from datetime import date as dt\n",
    "import datetime\n",
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>72.485854</td>\n",
       "      <td>72.625843</td>\n",
       "      <td>72.000565</td>\n",
       "      <td>72.597847</td>\n",
       "      <td>693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>72.439173</td>\n",
       "      <td>72.793807</td>\n",
       "      <td>72.000543</td>\n",
       "      <td>72.560493</td>\n",
       "      <td>856900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>72.364528</td>\n",
       "      <td>72.467187</td>\n",
       "      <td>71.963229</td>\n",
       "      <td>72.392525</td>\n",
       "      <td>678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>72.541833</td>\n",
       "      <td>72.859136</td>\n",
       "      <td>72.252519</td>\n",
       "      <td>72.467171</td>\n",
       "      <td>708200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-06</td>\n",
       "      <td>72.541841</td>\n",
       "      <td>72.653827</td>\n",
       "      <td>68.790155</td>\n",
       "      <td>68.967476</td>\n",
       "      <td>2600800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-23</td>\n",
       "      <td>195.419998</td>\n",
       "      <td>196.729996</td>\n",
       "      <td>195.259995</td>\n",
       "      <td>195.580002</td>\n",
       "      <td>745800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>194.910004</td>\n",
       "      <td>197.130005</td>\n",
       "      <td>194.389999</td>\n",
       "      <td>196.779999</td>\n",
       "      <td>662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>196.639999</td>\n",
       "      <td>196.639999</td>\n",
       "      <td>194.520004</td>\n",
       "      <td>195.779999</td>\n",
       "      <td>896500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>193.830002</td>\n",
       "      <td>194.330002</td>\n",
       "      <td>189.380005</td>\n",
       "      <td>190.960007</td>\n",
       "      <td>1309700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>191.929993</td>\n",
       "      <td>194.410004</td>\n",
       "      <td>190.919998</td>\n",
       "      <td>193.990005</td>\n",
       "      <td>874000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Volume\n",
       "Date                                                               \n",
       "2017-10-02   72.485854   72.625843   72.000565   72.597847   693100\n",
       "2017-10-03   72.439173   72.793807   72.000543   72.560493   856900\n",
       "2017-10-04   72.364528   72.467187   71.963229   72.392525   678600\n",
       "2017-10-05   72.541833   72.859136   72.252519   72.467171   708200\n",
       "2017-10-06   72.541841   72.653827   68.790155   68.967476  2600800\n",
       "...                ...         ...         ...         ...      ...\n",
       "2021-09-23  195.419998  196.729996  195.259995  195.580002   745800\n",
       "2021-09-24  194.910004  197.130005  194.389999  196.779999   662500\n",
       "2021-09-27  196.639999  196.639999  194.520004  195.779999   896500\n",
       "2021-09-28  193.830002  194.330002  189.380005  190.960007  1309700\n",
       "2021-09-29  191.929993  194.410004  190.919998  193.990005   874000\n",
       "\n",
       "[1006 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = yf.download(  # or pdr.get_data_yahoo(...\n",
    "        # tickers list or string as well\n",
    "        tickers = \"NDAQ\",\n",
    "\n",
    "        # use \"period\" instead of start/end\n",
    "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "        # (optional, default is '1mo')\n",
    "        period = \"4y\",\n",
    "        ## yyyy - mm - dd\n",
    "#         start = datetime.datetime(1995,9,28),\n",
    "#         end = datetime.datetime(1999,9,27),\n",
    "#         start = datetime.datetime(2009,1,1),\n",
    "#         end = datetime.datetime(2010,1,1),\n",
    "\n",
    "        # fetch data by interval (including intraday if period < 60 days)\n",
    "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "        # (optional, default is '1d')\n",
    "        interval = \"1d\",\n",
    "\n",
    "        # adjust all OHLC automatically\n",
    "        # (optional, default is False)\n",
    "        auto_adjust = True,\n",
    "\n",
    "        # download pre/post regular market hours data\n",
    "        # (optional, default is False)\n",
    "        prepost = True,\n",
    "\n",
    "        # use threads for mass downloading? (True/False/Integer)\n",
    "        # (optional, default is True)\n",
    "        threads = True,\n",
    "\n",
    "        # proxy URL scheme use use when downloading?\n",
    "        # (optional, default is None)\n",
    "        proxy = None\n",
    "    )\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>72.485854</td>\n",
       "      <td>72.625843</td>\n",
       "      <td>72.000565</td>\n",
       "      <td>72.597847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>72.439173</td>\n",
       "      <td>72.793807</td>\n",
       "      <td>72.000543</td>\n",
       "      <td>72.560493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>72.364528</td>\n",
       "      <td>72.467187</td>\n",
       "      <td>71.963229</td>\n",
       "      <td>72.392525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>72.541833</td>\n",
       "      <td>72.859136</td>\n",
       "      <td>72.252519</td>\n",
       "      <td>72.467171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-06</td>\n",
       "      <td>72.541841</td>\n",
       "      <td>72.653827</td>\n",
       "      <td>68.790155</td>\n",
       "      <td>68.967476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-23</td>\n",
       "      <td>195.419998</td>\n",
       "      <td>196.729996</td>\n",
       "      <td>195.259995</td>\n",
       "      <td>195.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>194.910004</td>\n",
       "      <td>197.130005</td>\n",
       "      <td>194.389999</td>\n",
       "      <td>196.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>196.639999</td>\n",
       "      <td>196.639999</td>\n",
       "      <td>194.520004</td>\n",
       "      <td>195.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>193.830002</td>\n",
       "      <td>194.330002</td>\n",
       "      <td>189.380005</td>\n",
       "      <td>190.960007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>191.929993</td>\n",
       "      <td>194.410004</td>\n",
       "      <td>190.919998</td>\n",
       "      <td>193.990005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close\n",
       "Date                                                      \n",
       "2017-10-02   72.485854   72.625843   72.000565   72.597847\n",
       "2017-10-03   72.439173   72.793807   72.000543   72.560493\n",
       "2017-10-04   72.364528   72.467187   71.963229   72.392525\n",
       "2017-10-05   72.541833   72.859136   72.252519   72.467171\n",
       "2017-10-06   72.541841   72.653827   68.790155   68.967476\n",
       "...                ...         ...         ...         ...\n",
       "2021-09-23  195.419998  196.729996  195.259995  195.580002\n",
       "2021-09-24  194.910004  197.130005  194.389999  196.779999\n",
       "2021-09-27  196.639999  196.639999  194.520004  195.779999\n",
       "2021-09-28  193.830002  194.330002  189.380005  190.960007\n",
       "2021-09-29  191.929993  194.410004  190.919998  193.990005\n",
       "\n",
       "[1006 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(columns=['Volume'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>72.485854</td>\n",
       "      <td>72.625843</td>\n",
       "      <td>72.000565</td>\n",
       "      <td>72.597847</td>\n",
       "      <td>70.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>72.439173</td>\n",
       "      <td>72.793807</td>\n",
       "      <td>72.000543</td>\n",
       "      <td>72.560493</td>\n",
       "      <td>69.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>72.364528</td>\n",
       "      <td>72.467187</td>\n",
       "      <td>71.963229</td>\n",
       "      <td>72.392525</td>\n",
       "      <td>69.3781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>72.541833</td>\n",
       "      <td>72.859136</td>\n",
       "      <td>72.252519</td>\n",
       "      <td>72.467171</td>\n",
       "      <td>69.1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-10-06</td>\n",
       "      <td>72.541841</td>\n",
       "      <td>72.653827</td>\n",
       "      <td>68.790155</td>\n",
       "      <td>68.967476</td>\n",
       "      <td>69.7234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>194.580002</td>\n",
       "      <td>196.570007</td>\n",
       "      <td>194.580002</td>\n",
       "      <td>195.550003</td>\n",
       "      <td>195.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-15</td>\n",
       "      <td>195.589996</td>\n",
       "      <td>197.139999</td>\n",
       "      <td>194.500000</td>\n",
       "      <td>195.839996</td>\n",
       "      <td>196.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.460007</td>\n",
       "      <td>194.559998</td>\n",
       "      <td>195.429993</td>\n",
       "      <td>195.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>194.860001</td>\n",
       "      <td>194.910004</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>192.899994</td>\n",
       "      <td>190.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>189.669998</td>\n",
       "      <td>192.110001</td>\n",
       "      <td>188.509995</td>\n",
       "      <td>190.979996</td>\n",
       "      <td>193.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   output\n",
       "Date                                                               \n",
       "2017-10-02   72.485854   72.625843   72.000565   72.597847   70.582\n",
       "2017-10-03   72.439173   72.793807   72.000543   72.560493  69.9101\n",
       "2017-10-04   72.364528   72.467187   71.963229   72.392525  69.3781\n",
       "2017-10-05   72.541833   72.859136   72.252519   72.467171  69.1635\n",
       "2017-10-06   72.541841   72.653827   68.790155   68.967476  69.7234\n",
       "...                ...         ...         ...         ...      ...\n",
       "2021-09-14  194.580002  196.570007  194.580002  195.550003   195.58\n",
       "2021-09-15  195.589996  197.139999  194.500000  195.839996   196.78\n",
       "2021-09-16  196.000000  196.460007  194.559998  195.429993   195.78\n",
       "2021-09-17  194.860001  194.910004  191.000000  192.899994   190.96\n",
       "2021-09-20  189.669998  192.110001  188.509995  190.979996   193.99\n",
       "\n",
       "[999 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Reading data \n",
    "step=7\n",
    "## here\n",
    "num_input=4\n",
    "output_cluster=10 #output cluster\n",
    "num_output=1 #numb of output\n",
    "num_var=num_input+num_output\n",
    "data.insert(num_input, \"output\", True)\n",
    "num_line = len(data.index)\n",
    "\n",
    "## here\n",
    "col_names=list(data)[0:5]\n",
    "\n",
    "## here\n",
    "# 1st row 5th col = 5th row 4th col  \n",
    "for i in range(num_line-step):\n",
    "    data.iloc[i,4]=data.iloc[i+step,3]\n",
    "     \n",
    "for i in range(step):\n",
    "#     print(data.index[num_line-(1+i)])\n",
    "    temp_date = data.index[num_line-(1+i)]\n",
    "    data = data.drop(temp_date)\n",
    "\n",
    "num_line = len(data.index)\n",
    "    \n",
    "data_test=data\n",
    "test_num_line = len(data_test.index)\n",
    "data_train=data\n",
    "train_num_line=len(data_train.index)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Normal Density')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5xU9b3/8ddHEGwoICBNBRVRFCOGKGhM7DURr4mKPwsac7mW2LElRuM1FjTqTbmacO0lKqAx9hJjJMYWEBUQFeyrlEVUkF6+vz8+53BmZmdnZ3fnzMyy7+fjMY9zzvecmfksjvOZ860WQkBERARgnUoHICIi1UNJQURE1lBSEBGRNZQURERkDSUFERFZo22lA2iOLl26hD59+lQ6DBGRFmXSpEnzQghd851r0UmhT58+TJw4sdJhiIi0KGb2cX3nVH0kIiJrKCmIiMgaqSUFM9vczJ43s+lmNs3MzorKO5vZs2Y2I9p2isrNzH5nZjPN7C0z2yWt2EREJL807xRWAueFELYHhgCnm9kA4CLguRBCP+C56BjgYKBf9BgJ3JxibCIikkdqSSGEMCuE8Hq0vxCYDvQChgF3RpfdCRwe7Q8D7gruFaCjmfVIKz4REamrLG0KZtYHGAS8CmwWQpgFnjiAbtFlvYBPM55WE5XlvtZIM5toZhNra2vTDFtEpNVJPSmY2UbAg8DZIYQFhS7NU1ZnCtcQwpgQwuAQwuCuXfN2sxURkSZKNSmY2bp4Qrg3hPBQVDwnrhaKtnOj8hpg84yn9wY+TzM+EZFq9sUXcOqpMH58+d4zzd5HBtwKTA8h3JBx6hFgRLQ/AvhrRvkJUS+kIcDXcTWTiEhr1KUL/PGPcOSR8HG9w81KK807hT2A44F9zOyN6HEIcA2wv5nNAPaPjgGeAD4AZgL/B5yWYmwiIlUtd/2zOXO87L//G6ZOTe99U5vmIoTwIvnbCQD2zXN9AE5PKx4RkZbkww+zjydOhC22gMsug//7P/j00/zPa64WPfeRiMjaavLk7OPTT4eXX/b9+fPTe19NcyEiUoXeftu3n32WlN1zj2979kzvfZUURESq0Jw50KkT9MgzhHfmTJgwIZ33VVIQEalCc+dC165gBg8+CMOGZZ9/9tl03ldJQUSkCk2dCttu6/tHHAG75EwRus026byvkoKISBX67DPYeuvkeJNNss9nnislJQURkSpxxRVeTbRqFSxYAB07JueWLs2+Nq2koC6pIiJV4tJLfXvTTb6dMyc5Zzmjvrp3TycGJQURkSozapRv9947KTvjDB/R/P3ve++j3CRRKkoKIiJVYPny7P2rr4ajjkrK1l8fLrzQ94cMSS8OJQURkQq76y54883ssv79KxOLkoKISAW99x6MGFG3PK0upw1R7yMRkQqZPh1ujlaj79ULxoxJzm21VWVi0p2CiEgFPPooHHaYNxj37w/vvAOrV8PIkX5+ww0rE5fuFEREKuD9930bgk9nAbBOFXwj605BRKQCzjkn2c+sKvrHP7ynUaUoKYiIVNjBByf73/9+5eIAVR+JiFTUpZfCD35Q6SgSulMQEamAXr3goIPg8ssrHUk23SmIiJRZCDBvHnTpUulI6lJSEBEps0WLYNmyVpYUzOw2M5trZlMzynY2s1fM7A0zm2hmu0blZma/M7OZZvaWme1S/yuLiLRs8+b5tlUlBeAO4KCcsmuBy0MIOwOXRscABwP9osdI4OYU4xIRqahWmRRCCBOA+bnFwMbR/ibA59H+MOCu4F4BOppZnuWqRURavjgpbLppZePIp9y9j84Gnjaz3+AJafeovBfwacZ1NVHZrNwXMLOR+N0EW2yxRarBiog0x9y50K5d9gpqIcDChb7foUNl4iqk3A3NpwLnhBA2B84Bbo3K8y0XEfK9QAhhTAhhcAhhcNd4bLiISBXabDPo3Ts5/vhjn8pi3Dg/3mCDysRVSLmTwgjgoWh/HLBrtF8DbJ5xXW+SqiURkRZr0SKYFdV5zJjh2zgpVHI6i/qUOyl8DsSDuPcBon8iHgFOiHohDQG+DiHUqToSEWmJevaEl17ymVAzVeOdQmptCmZ2H7AX0MXMaoDLgP8EfmtmbYGlRG0DwBPAIcBMYDFwUlpxiYiUQ8ipAN9jj7rXVOOdQmpJIYRwTD2nvp3n2gCcnlYsIiLl9uqr9Z/bfntfYGfddcsXT7E0ollEJAV33ZXsjxqVfe6hh6C21hfYqTZKCiIiKZg2LdmPV1OLbbJJdQ5cAyUFEZFU1NTA4YfDnDnQrx+8915yrnPnysXVECUFEZEUfPMNdO8O3br5cb9+ybn27SsTUzG0noKISAoWLarb5fTuu2Hy5MrEUywlBRGREgsBFi+umxSOO84f1UzVRyIiJbZsmSeGDTesdCSNp6QgIlJiixb5thpHLDdESUFEpMQWL/at7hRERER3CiIi4nbfHXbayfdb4p2Ceh+JiJTQyy8n+7pTEBGRNTbZpNIRNJ6SgohIiWROl33PPTB4cOViaSolBRGREli9OqkuGjMGjj22OmdBbYiSgohICXzxBSxd6vtHHFHZWJpDSUFEpARmz072N920cnE0l5KCiEgJvPhipSMoDSUFEZEmqK311dXmzIEJE+C00yodUWlonIKISBMMHw5//3vd8u22K38spaSkICLSSPffnz8hfPklbLRR+eMppdSqj8zsNjOba2ZTc8rPMLN3zWyamV2bUX6xmc2Mzh2YVlwiIk21fDm88II/cg0dCh07QtsW/lM7zfDvAP4A3BUXmNnewDBgpxDCMjPrFpUPAIYDOwA9gb+Z2bYhhFUpxici0igXXQQ33pj/XEscvZxPancKIYQJwPyc4lOBa0IIy6Jr5kblw4D7QwjLQggfAjOBXdOKTUSkKaZMqf/cJ5+UL440lbv30bbAnmb2qpm9YGbficp7AZ9mXFcTlYmIVI3MEcrnnJN9buONyxtLWsqdFNoCnYAhwPnAWDMzIN9g8JCnDDMbaWYTzWxibW1tepGKiERWr4YDD4Rnn03K9t472b/yShg/vvxxpaHcSaEGeCi414DVQJeofPOM63oDn+d7gRDCmBDC4BDC4K5du6YesIjI/PnwzDPZZb0y6jL22Sf7uCUrd1J4GNgHwMy2BdoB84BHgOFm1t7M+gL9gNfKHJuISF4LFiT7117ro5d32SUpa+ndUDOl2SX1PuBloL+Z1ZjZycBtwFZRN9X7gRHRXcM0YCzwNvAUcLp6HolINQgBLr/c9zt0gPPPhz328OPTT/dtx46ViS0NFkLeqvvkArPOIYTcXkRVYfDgwWHixImVDkNE1mIffwx9+vj+M8/A/vsn51avhnfegQEDKhJak5nZpBBC3tUeirlTeNXMxpnZIVGjsIhIqxH3Z9liC9htt+xz66zT8hJCQ4pJCtsCY4DjgZlmdlXUHiAistaLG5j//Oe1p9tpIQ0mhajO/9kQwjHAT4ERwGvROIOhqUcoIlJBX3zh20GDKhtHuTQ4zYWZbQoch98pzAHOwHsL7QyMA/qmGaCISCUtWAA9eiRLba7tipn76GXgbuDwEEJNRvlEM/tjOmGJiFSHBQtaR7VRrJg2hUtCCFdkJgQzOxIghDA6tchERKrAggXeFbW1KCYpXJSn7OJSByIiUm1efRWeesp7HrUW9VYfmdnBwCFALzP7XcapjYGVaQcmIlJpQ4b4tn//ysZRToXaFD4HJgKHAZMyyhcC5+R9hojIWkh3CkAI4U3gTTO7N4SgOwMRaTXmz/dJ7mI9elQulnIrVH00NoRwFDDZzDLnwjB8+MJOqUcnIlIBr70Gb76ZHB9ySOViKbdC1UdnRdsflCMQEZFqsWJFsn/99bDuupWLpdzq7X0UQpgV7c4DPg0hfAy0B75FPWsdiIisDZYsSfY33LBycVRCMV1SJwDrmVkv4DngJOCONIMSEamkpUuTfSWFuiyEsBg4Avh9COE/gLVsXkARETdlCowYkRy3luktYkUlhWjiu2OBx6OyYqbHEBFpcZ5/Ptk/7DDYc8/KxVIJxXy5n4WPYP5LCGGamW0FPN/Ac0REWozZs2HYMF9R7bVoIeD11oPx41tXIzMUkRRCCBPwdoX4+APgzDSDEhEpp/HjPRnECWHoUHjppcrGVCnFTJ29LTAK6JN5fQhhn/qeIyJS7T7+GHr29DuB3HaDbbapTEzVoJg2hXHAZOAS4PyMh4hIizR6tK+7PDqa5/mNN7LPr1pV9pCqRjFtCitDCDenHomISInV1sKMGbD77n48bx6YwQMP+PHLL/u2JloY4Kij4Kuv4JJLyh9rtSgmKTxqZqcBfwGWxYUhhPmpRSUiUgKHHgr//rePO2jfHrp2zT6/cKFvV6zw5TbjZNGaFZMU4h67mVVGAdiq0JPM7DZ8ioy5IYQdc86NAq4DuoYQ5pmZAb/Fp+peDJwYQni9uD9BRKSut9/2hADw5z/nH4T2zTe+XbEC2rUrX2zVrJjeR01dg/kO4A/AXZmFZrY5sD/wSUbxwUC/6LEbcHO0FRFptC++gB12SI5/8hPvbppr8mQYPhyeeSb/+daowYZmM9vAzC4xszHRcT8za3CSvKgra74qphuBC/C7jdgw4K7gXgE6mlkrmqxWREpp8uS6ZXF309pab2CO7wweeABCaH3jEepTTO+j24HlQNRUQw3w66a8mZkdBnwWrdWQqRfwacZxTVSW7zVGmtlEM5tYW1vblDBEZC2X76thxQr41regSxe44ALYfvvs86o+csUkha1DCNcCKwBCCEvwNRUaxcw2AH4BXJrvdJ6ykKeMEMKYEMLgEMLgrrmtRiIi5E8KkD0e4dxzs8/pTsEVkxSWm9n6RF/SZrY1Gb2QGmFroC++mttHQG/gdTPrjt8ZbJ5xbW80PbeINFHc9fThh+GDD+A3v/Hyr75KrjnhBB/JHFNScMX0ProMeArY3MzuBfYATmzsG4UQpgDd4uMoMQyOeh89AvzMzO7HG5i/zljPQUSkUWprYdNNfT4jgN2ibiszZmRft956yX7cE6m1K6b30bNm9jowBK/mOSuEMK+h55nZfcBeQBczqwEuCyHcWs/lT+DdUWfiXVJPKi58EZG6amuzxyRsvHH+63bM6Cw/Z066MbUUBZOCmbXFu4tuFxVNB76q/xmJEMIxDZzvk7EfgNOLeV0RkYbkJoX11/et5bRebrklPPcc7Ltv9sI6rVm9bQpm1hOYBpwH9MR7A50PTIvOiYgULQRfwKYc7/Phh7DZZklZoYVy+vTxbb9+qYbVYhRqaL4KuDmEsFcI4ZwQwtkhhO8D/wtcXZ7wRGRtccMNsNNOyXiBtDz/PHz6Kfzwh0lZoaSw1VZw//1w1131X9OaFKo+GhJCODG3MITwOzN7N72QRGRt9OCDvl2wIN33uece6NgRfvzjpCyuPtpkk/zPOfrodGNqSQrdKSwpcG5xqQMRkbXbBx/4NuQdgVQ6s2bBttsmiQC8l9F118E//5nue68NCt0pbGJmR+QpN6CetnwRkfzi3j2LU/5JuWhR/uqiUaPSfd+1RaGk8ALww3rOTainXERaoRDg97+H44+HTp3qnp+VMeoo7aSweDF0757ue6zN6k0KIQSNFRCRovztb3DWWfDWW3DLLXXPNycpHHggtGkDTzzR8LV//ztMmgQ779y495BEMdNciIgU9Ek0Ef7y5b699Va4++7kfNyeAA0nhRB8XqKJE/34mWfgySeLiyPuQbR6dXHXS11KCiLSbHPn+jYeMPbTn/rcQrEjj0z2G0oKc+fCjTdmdyktVtuo7uO22xr/XHFKCiLSbJl3BQ8/nH3u3nuzjxtKCh9/7NumTGX97ruw557w7W83/rni6m1TqKfn0RohhIdKH46ItDQhwPTpvn/DDf6ILVgAxx3n+6edBnfc0XBS+Ogj33bsmF0NtGJFMpPp6tU+ZUU8bcWbb/rCOW+9pTEHzVXoTuGHBR4NrrwmIq3DsgIT6WcOFjvySO8qWmxS2HDD7PmIDj3UtytWeMPzFVck5847D+67z5PQdtshzaDeRyLSLAsX+rZbt6RtAXwA2XvvJce77eZf5lOn1v9aIcDll/v+nDk+5iD27LO+nRfN0XzZZb4ewgsv+KR2sT33bPrfIkW2KZjZoWZ2gZldGj/SDkxEWoY4KXTp4tvttvNqnGuv9eP77/df9+uv71/0EybAmDFelmvatOROYs6c/NNZf/FFsj9lSt2eSd/5TvP+ntauwfUUzOyPwAbA3sAtwI+BlKe0EpGWIp7LaNUq3554Igwc6I8FC6BDh7rP+a//gtmz4dKcn5eZk+UtWpR0dY0tXw4vvZRdduyxvt1mG/jDH5r8Z0ikmJXXdg8h7GRmb4UQLjez6wE1MosIkPyav/pqr8459dTkXL6EEMtXjfToo9nHb7+dffzUU55Q8nnhBeipSf2brZjqo3hivMXROgor8LWWRUSYPNm3gwZ599P6VjnLVVubffzuu96d9cwzvdEYvDoJ/C4AYORI3+bObXTuuUoIpVJMUnjMzDoC1wGvAx8B96cZlIi0HA8/DLvs4quYNca773rDcpxUJkQzqh1xBHTu7Ptvv+29kO6804/ju5LctQ/+9a+mxS51NZgUQghXhBC+CiE8CGwJbBdC+GX6oYlItZs/H/79bx99nLvUZT6ZdwezZnlj9C67+LxJ48b5a+y+e5IUpk3zye2+/e3k7mC33WD77bNfdx0Nwy2ZYhqa2wCHAn3i682MEMINhZ4nImu/557zgWQHHljc9V26wDnn+Kjlhx7yXkgAv/udbwcO9AFqcVXQokW+rGb79tC3ryeJnXeGAQM8wdTW+n68pKY0XzENzY8CS4EpgKaZEpE13o3WYNxll+Kfc8MNvlzmQw9lT5QHyTrJ3bv7NBfLl8Omm3rZDjt4Uoi7vnbp4o+//AX22ad5f4ckikkKvUMIOzX2hc3sNnzk89wQwo5R2XX4iOjlwPvASSGEr6JzFwMnA6uAM0MITzf2PUWkvObN84bl9u0b97y4eijXN9/4dp11vI1ixozk2l12gbFjs8cpABx+eOPeWworpibuSTM7oAmvfQdwUE7Zs8COUZJ5D7gYwMwGAMOBHaLn3BRVW4lIFZs0yat3GivfymjHHw8XXpgcxw3X8Z1C/OW/996Nfz8pXjF3Cq8AfzGzdfDuqAaEEELBjmchhAlm1ien7Jmc142X1h4G3B9CWAZ8aGYzgV2Bl4v5I0Sk/Fas8Inohg1r/HPzNUrn9iiKB7LFPY7694clSxp/VyKNU8ydwvXAUGCDEMLGIYQODSWEIv0EiAeo9wI+zThXE5XVYWYjzWyimU2sze3oLCJlM2iQT3HRK+//qQ3LHL18/vl1z198sW+XLEnK1luvuF5O0nTF3CnMAKaGEEKp3tTMfgGsBOKZ1vP9Z877fiGEMcAYgMGDB5csJhHJb/Ron+30lFOSsttuSwaW5dbxFytuVI7fI9d550FNTf6EIekpJinMAv5hZk8CaybJbWqXVDMbgTdA75uRaGqAzTMu6w183pTXF5HSuugi355yis9l1K4dnHxycr6pX9qZ02rn+/W/7rqay6gSiqk++hB4DmgHdMh4NJqZHQRcCBwWQsicVf0RYLiZtTezvkA/NOmeSFW59Vb/It9666Tsyy99iuymMPPpLCZNKk18UhoF7xSiHkAbhRAa/VvAzO4D9gK6mFkNcBne26g98Kz5T4NXQginhBCmmdlY4G28Wun0EMKqxr6niJROTU2ysA34ussAn0f38I8/7qujNcfw4c17vpRewaQQQlhlZo0YlpL13GPyFN9a4PorgSub8l4irdGqVd6fP62G11tu8XUR6tO1azrvK5VVTPXRG2b2iJkdb2ZHxI/UIxORei1eDG3bJgvZpOG1Bipw45HFsnYpJil0Br4A9kFrNItUhQ8/9O0vfpHee3z5JQwZ4nMVxc44I9lXUlg7Ndj7SGs1i1SfOCmsSqnl7f334dVX4aijfK6iG2/08sylLjfaKJ33lspq8E7BzHqb2V/MbK6ZzTGzB82sdzmCE5H8MieSe/fdZFF78C/zq65q3utvs42vdZC7RkJmUtAgsrVTMdVHt+NdRnvio4wfjcpEpAIWLYI77kiOt9sODjggWatgyBCvVlrdhDmNQ4Ann0yOjz46+/y228LQoXWXzZS1RzFJoWsI4fYQwsrocQegfgciFfL73/tqZbmjgLt1g/feS47jGUcb49FH4ZBDkuNBg7LPr7MOvPQS/ECtimutYpLCPDM7zszaRI/j8IZnEamAuXO9Pj9z2onYLbck+1991fjX/jxjHoGzz1YVUWtUTFL4CXAUMBuf8uLHUZmIVMCSJT4xXIcOvp4xJIvMrLdecl1TkkKbjAnrf/3rZP/ss+G//qvxryctTzG9jz4BDitDLCJShKVLYf31/Vf8gw9mL3RzxRXJdYsWNf61M9c63nDDZD/ufSRrv3qTgpldWuB5IYRwRYHzIpKSJUs8KcTqGy9QTJvC9Olwzz3wox/5ymbxNNWTJzc/TmmZClUfLcrzAF8y88L6niQi6cpNCrEddsg+LnSncOedPrHd3nt799VjoklpFizw7fbblyZWaXnqTQohhOvjB75+wfrAScD9wFZlik9EctSXFM49N/u40J3CySf7WIfu3f04HgS3cKFPWa3VzVqvgg3NZtbZzH4NvIVXNe0SQrgwhDC3LNGJSJbly32gWr6RzD17Zh8XSgrxaOQVK3y7dKlvFy70BmxpvQq1KVwHHIHfJQwMITSh17OIlMqKFfDLX/p+vjUIcpNCoeqjddf1bTzg7bPPYMQIXyc5c0U0aX0K3Smch49ivgT43MwWRI+FZragPOGJSOz225NZUadOrXu+MXcK8R3Cgoz/k++6y7f779/0GKXlq/dOIYRQzBgGEUnJyy97g3DXrt7VNF7boKYGevWqe/2mm2Yf15cUMgekLVtW9/z11zctXlk7FLNGs4iUUU0N7LefT3QX2247ePpp/xWfLyFA9pd9u3b5q48amlX1wguzB8BJ66OkIFJlxozJTggAxx3n21GjinuNjh3z3ynE4xDqkzvXkbQ+qiISqSKLF8PNN/t+377wpz9lnz/88OJepzFJYeutk/3ly4t7fVl7KSmIVMiCBTBzZnbZPff4tBVDhvg4gp/+1Mu3394X1tlss+Jeu1On/NVHixfXLdt1V2+vGDoUDj20cX+DrH1UfSRSAatWeQPy8uWeHEaNgh49/IvfLFk0Z511fDrsbt1gk02Kf/2NNmr4TuH00+F//9eTz8CBPiW2SGpJwcxuw9dynhtC2DEq6ww8APQBPgKOCiF8aWYG/BY4BFgMnBhCeD2t2EQq7amnkqqajTfOPnfYYdlLXTZl3MDGG8Ps2XXLM2dO/fnPPSnkvr+0bmlWH90BHJRTdhHwXAihH/BcdAxwMNAveowEbk4xLpG8Fi3yRt54dG9DPvsMJkxo2nu99lr953baqWmvmalLF6+GypW5jGfPnj7L6j33NP/9ZO2RWlIIIUwA5ucUDwPujPbvBA7PKL8ruFeAjmbWI63YRPIZPdrXDLjhhuKuHzoUvv99X8KyMZYvh5tugq22gi++8PEIS5fCJ5/A974Hxx7b+Nhzde3qSSE3tjgpvP++b484wqumRGLlbmjeLIQwCyDaxh/HXsCnGdfVRGV1mNlIM5toZhNr4zH6Is20ZIl/UYOvb3zbbQ0/59PoE3v//dCnDxx5pP9C/6KBdQmPO86/sEeOhM6dvVG5fXvYfHN44QUfk9BU8VKaXbp4u0XuQjvxNBlbaUpLqUe19D7Kt+hf3t9fIYQxIYTBIYTBXbtqqWgpjalT/cs8/pV+8snFP/exx+Djj2H8eH+NQlVDAOPG+faCC5oWayGPPOJ3HfEaC5lVSPl6HonkKndSmBNXC0XbeLbVGmDzjOt6A58jUiZxb5+zz06WpIznB2pI7p3B5zmf3Oee88bjZcuS1/zv/05n/eM2bfyuI/69lJkU4obtgQNL/76y9ih3UngEGBHtjwD+mlF+grkhwNdxNZNI2hYs8CojgC23hFNO8f3p0+t/zsqVyf78nJaz3FrNCy6ARx/1O4i50c+g3HmKSi2+U4hjmTPHYwCttSyFpZYUzOw+4GWgv5nVmNnJwDXA/mY2A9g/OgZ4AvgAmAn8H3BaWnGJ5PrXv5L9rl3h1FN9P99MpPPnwz/+AdOmJWVvv519zZw52cdxIvje9+CHP/T9b3+7WSE3KLf6aN994YQTfL9du3TfW1q21MYphBCOqefUvnmuDcDpacUiUsiECb6+QNwo26+fH+cmhdra/D114pHDs2f7iOA//cm7q779to8FyLyTmDzZJ7T7znfS+Vti8UC3r7/2beZdT7yWgkg+GtEsrd7773tvnA028ON27aB/f5gyJblm+XLvvlmfQw/1KSgGDfIFcOLG5HzdSwcO9JHKaWob/Z8dz4rapg2sXu37ulOQQqql95FI2b34Ihx0kDcU504hseOO3qto3jy4+25vvH3xxexrfvvbZH/8+OR59fnJT+C73/XxEGnLlxRiSgpSiO4UpNXac89kP3e1sbhHUX29ns18+co//AHOOitZg6B//+zrhg/3AWRXXpk9G2na4iQQz2ekpCDFUlIQoe78P1dfnXRTzTR4sI8DePppv7t4773s85lJYfTodMYiFCO+U3jkEd9mJgW1KUghqj6SVuWrr+DMM+v2GOrbN/u4vt5BBxzgbQ256yHHttgi2a9UQoDsNos33sg+bt++/PFIy6GkIK3GuHG+zsDvfw877JB9Lt/UErnjDwC+/LLwe7RpAxdfnDQ0V4Mbb0wa0UFzHUlhSgrC6tU+eGvGjEpHkq5XXqlbFlerHHBA3XOdOiVtCg8/7Nt4nEEhV10FP/5x02JMw2efZY+y7qGpJqUAJYVWYvny/CtxAbzzjn+RHX98eWMqt8WL/Yt+2DA4+mj/srzwQj9X34pmW27p2/328548Bx9cnlhLqaYm+7hz58rEIS2DksJaYOXKpA96rquu8p4y7dtnL9wSW7IExo5NN75qsXixNyg//LDPbNqzJ/z6195wXF+PnEcf9cbaDTdMf2xBWnKTQhpzLsnao7ixa3IAABJ/SURBVIV+zAXgr3/16QzWXde7RObeCYSQzOlTn3PPhcsv9/1OndKJs1osWuRf7pnihFmf7t2LqzKqZosWeW+k3XeH++6rdDRS7ZQUWqjVq+GYY/xLrU0bn31zo418GoXYpEm+ze1Zk+nll5P96dNb/jq9M2f6qOL+/eGSS7InrsuXFFqLlSt9LMbw4ZWORKqdkkILtHix95NfsgQuvdSPhw3zc/EvwRCS+XUmTUqqjq66ymcBXbLE1+d9802fNfOSS3xNgD32aF5sIcCf/5y9QHxz1NYmo3Ib8vXXMGCAd8F87z0fMJY51uCrr6Bjx9LE1RJpfIIUQ0mhBfrud5MVtnr39vrwhx/2qo64y2Tck2ijjbxa6Fe/8uNf/MInbNtgA/jZz7xs0CC/64i9+WbTY3vuOZ/v55JLmv4asZoa7z55zTUNXws+h1HuGgiHHAJ77+1Jav781t3IqqQgxVBSaGHmz8+uItpvv2S/WzeYONGXlYyrgV591bf1zd9/6qlw4on+C/vKK71s552LX3f4kUc8EcTiaaLjNYCb6p13fHlK8L+pkBDgrbeS9Ycvuij7/D/+ATvt5HcPrbmPvqa3kGJomosW5uqrs487dEj2993XByqdnjEJeTwoa5ttkrITT/QG6iOPhF13TcozR+k+9hhsv33283KtWJFUW8VJJO7p0tjF7HP95S/Jfu4UFLlGj/YBY7FRo7xKbPXqZL6hmTP9DmvUqObF1ZLpTkGKoaTQQsyf7wvF/+Y3Pp5g1KjsUarg7QU33phdFnejHDo0mef/0kuz58KJHXusv8ell/rykVD4yz3zDgG8iiZu03jtNV9spr7+/w2ZO9f/vgED6i5aA95VdORI7z11881J+ZZbehVRfGe0dCl89JF3uz3zzLqzoa7NttzS24liSgpSDCWFFmD5cp+DPx6VetRRXh2Sa731fKrneNWte+5JzrVp41+ihay7rq8OVqx4sjWAWbPg+uu9kfe883z/r39t+D3rM2OG36V07163nz1428js2cn8QvFqaT/7WXY//PbtvSfSL3/ZtDjWJqo+kmIoKVS5EOCf/8yepmDo0Pqv33RTr1ufPRuGDGn8+227rW833jj/3USmmTOT/bjqacMNvVH7+uuTlcwasno13HWXL2KzahXcfjs8/jj86Ec+wdyzz2Y3Ei9dWndCu3339eslkXuXV9804CKZ1NBcxU480at/4sbk+fP9f/SGFn3v29cTR1NGrvbo4V/MZ53lX+r1jZQGr2rKnS10jz08MbRp41VAhZ4fGz8eTjrJk0nnzn6nAT4f0UknwbJl3s01NmWKx5i5yM322xf9J7ZavXpVOgJpCZQUqtTq1XDnndll5RpxvM463ksnBF9jePHiutesWuU9hI48Mrt8q608Ga1a5XcLe+3V8Pv98Y++zWwPufZar3oaONC71cY9iwD+9S/fDhvmk9wddVRyhyOJ3Pal3r0rE4e0LEoKVWjePOjTJ7vsppvKG0NcRTV6dP76+Ftu8W3mojJ77QUnn+z78RiIf/4zf5tAbOpUeP55b1COu4s+9lh2L6FOnZJprD//3MdA9O3rVUu77QYPPJAsKiOJI47warhYQ3eYIlChpGBm55jZNDObamb3mdl6ZtbXzF41sxlm9oCZtZpmsZkz/ct01iz/sj35ZK+ayVSoHSENO++c7N9wA3z4YXK8cqV3jR040EdHx5591lcmA1+zIB4jkTmVRq543qUrr/ReRiHAoYdmV3117uwjm7/80sdfLFrkSVITuzUsM1nq30uKUfakYGa9gDOBwSGEHYE2wHBgNHBjCKEf8CVwcrljK4eVK72K5e67k7J+/eC227x+/j//M7tXT9yls9y3/m3aeCyxzFHFn3ziXR3POMO/aF56yXsD5f5a33lnr4qqb4T01KnwxBN+VxSPd8inUye/rnPnpLrqu99t0p/V6qgbqjRWpaqP2gLrm1lbYANgFrAPMD46fydweIViS9WcOf6r+4QTCl/Xtq3Xoz/5pM/5X4lb/zFj/Jf74YfDM88k5fGo5bjhcuhQn4I6V7t2XiU0e3b+1x871tsrHn208K/YfKud5ZsGXOpSUpDGKntNbAjhMzP7DfAJsAR4BpgEfBVCiOe0rAHWyr4S8RcqeHKIp23u1Ml70Nx2m/cAWr48GW8waFD548z0ve/53Epz5/qXfJwgipkyok8fbxhesaLuF9TkyX53tOOOhV8j907jrLOKDr3VU1KQxqpE9VEnYBjQF+gJbAjkW88q71haMxtpZhPNbGJtbW16gabkySeT/a22Sn5tn3aaf3n27+9jBOKEUA3igXJTpvh2fHQ/N3Bgw88dNcp7KT31VHb54497g3IxC9e8+qq3a4QACxfW7VUj9VNSkMaqRPXRfsCHIYTaEMIK4CFgd6BjVJ0E0Bv4PN+TQwhjQgiDQwiDu7aw0ThffpksehNPIxGr5imd4y//t97yL+YQfObRQovTxOIBdLNmec+h00/3f4e43eT88xt+jV13hXPO8f2NNlKDaWOoV5Y0ViWSwifAEDPbwMwM2Bd4G3geiJc7HwH8tQKxpSqew+eaa3wKiDFjknPNXccgTd26edI691xfo3jq1GQG04bEo5DHjvW7optu8l/9M2Z4Q/QZZ6QXt+hOQRqv7EkhhPAq3qD8OjAlimEMcCFwrpnNBDYFbi13bKWwbBlMm1a3fOlSH38ASXfPeFF4yJ6ttBrF1TxPP+3bzC6rhay/vt9RZE6ed9VVPjZhyBD96k+bkoI0VkVuLkMIlwGX5RR/AFT5V2NdL74I48Z5D5xttvGZRt97z/vvx7N3huAJ4Isv/Dj+9Zy5NGRD8wxV2oIFyf7xxyfVOcXYZJPsBvbVq71a47TTShef5KekII2lGsdm2nNP3/7ud9nlf/yjL3f5zTc+8CrzSzEerRzfKfz856mH2WyZax0fcEDjnpv5t4PfHXz9dd2pv6X0lBSksZQUmiH3yw7gBz/wKpNx47x//qBBda+Lexb17u3dUoutn6+kxx6D11+Ho4/2wXZN1batj9ZWQigPJQVpLM191ICVK/2xdKm3F2SKe9A88QTsvrvv33OPzzkDvqBNvsSRWY/ep0/1Vx2BTz3xy1/6xHNNbQd47TVPlN27lzY2qZ96H0lj6SNTwOef+1w+e+zhffS7dYMJE/zcO+/4IKptt/XqlIMO8nKzZPnIceOyX+/BB/MvjtNafOtbWuil3HSnII2lO4UCTjnF+9ePHw/vvuszfv79737ub3/zKRoef9x/6Zslv6DjdZP/9Kfs14sbo1ubeKyCEkL5KSlIYykp1OONN3xOntNOy54e+sQTffv8835rHi8Mnymep2jBAp+yYtkynym0R4/Uw65Kzzzj4xKk/JQUpLGUFPKYNCmZb2jwYG9gHTsW/t//80bS//kfeOghTxb56te33z5ZM3jpUv+F3JSlMdcWHTq0zjukalDMNCIimVrtR2bhwrpr2IJXE8Uzft53n/fJ32ADn7J5xAgvP+ccv0O49978r20Gxx3n+3H7gkglVXpSRWk5WmVSuP9+n7bho4/qnhs1ymcEHTAAhg/P7r2RubTkU095w2l91lvPt8VMGieSpilTvLpTpBitMikMGOCjavv1826SmaZP9/UD8i0M064d3H673yk0VB0yaJDP8ZO7zrJIue24o48qFylGq+ySusMOvl21Cq67Luk6GgK8/75P+lZf/+64obkhZo2bCkJEpBq0yjuFNm18zAB4d9OxY/2OIW5LyB2kJiLSWrTKOwXwUccHHuizfh59dPY5TecsIq1Vq7xTiN19d/aC9OD1rw0tDykisrZq1Umha1e48EL44AOfk+fUU33xG83xLyKtVautPsrUt69vb7qpsnGIiFRaq75TEBGRbEoKIiKyhpKCiIisoaQgIiJrKCmIiMgaSgoiIrKGkoKIiKyhpCAiImtYyLfSTAthZrXAx5WOI9IFmFfpIPJQXI1TrXFB9cZWrXFB9cZW6bi2DCF0zXeiRSeFamJmE0MIgysdRy7F1TjVGhdUb2zVGhdUb2zVGheo+khERDIoKYiIyBpKCqUzptIB1ENxNU61xgXVG1u1xgXVG1u1xqU2BRERSehOQURE1lBSEBGRRAihVT6AzYHngenANOCsqLwz8CwwI9p2isq3A14GlgGjcl7rnOg1pgL3AevV854jotedAYzIKL8S+BT4plriAjoAb2Q85kcxliKus6KYpgFnF/hvdBDwLjATuCij/GdRWQB2KuG/V3Pj+mfGv9fnwNONjO1Y4K3o8RLwrYbes0yfsVTiyvMZmwfcUsLYbgPmAlMb+C5I43OWZly5n7OHS/rdWMoXa0kPoAewS8aH8z1gAHBt/B8AuAgYHe13A74T/c81KuN1egEfAutHx2OBE/O8X2fgg2jbKdqPP0BDoni+qaa4cq57Ezi5BHHtiH/xboCv/Pc3oF+e92sDvA9sBbSL3n9AdG4Q0Af4CNihRP9ezY4r57oHgTMaGdvuGZ+Jg4FXG/meaX3GUosr57pJwOGliC06/h6wCwW+fAv9DTTvc5ZaXHk+ZyeU9LuxlC/Wkh/AX4H98czcIyrrAbybc92vqPvl+2n0gW8LPAYckOf1jwH+lHH8J+CYnGu+qdK4+kWvZSWI60jglozjXwIX5IlrKPB0xvHFwMU513wEdCnRv1cp4+oAfAls3JTYovJOwGfFvmc5PmMpx1XnM9ac2DLK+lD4yzfVz1nKceX9nDX3oTYFwMz64L8KXgU2CyHMAoi23Qo9N4TwGfAb4BNgFvB1COGZPJfGX9KxmqisJcR1DPBAiD6JzYkL/zX+PTPb1Mw2AA7BqzOaEleWKorrP4DnQggLmhHbycCTjXjPxly3RhXFlfUZK0FsxSr3v1kp46rzOSuFVp8UzGwj/Bbs7Kb845pZJ2AY0BfoCWxoZsfluzRPWchTVo1xDcfbJJodVwhhOjAar399Cr8tXtnEuJKLqyuuY4j+vZoSm5ntjX+RXNiI92zMddUY15rPWIliK1a5/81KGVfW56xUWnVSMLN18f/A94YQHoqK55hZj+h8D7xBqJD9gA9DCLUhhBXAQ8DuZrabmb0RPQ7DM33mL8/eeCNRVcdlZt8C2oYQJpUoLkIIt4YQdgkhfA9vwJ5hZptnxHVKQ3Flqqa4zGxTYFfg8abEZmY74Y2tw0IIX0TFed+znJ+xNOPK/IyVMLa8yvk5SzOu3M9ZSZWyLqolPfBMfBfwPznl15HdcHRtzvlfkV0XvRveG2GD6DXvBM7I836d8YbfTtHjQ6BzzjXfVFtcwDXA5aWKKyrrFm23AN4hf6NjW7xBsi9JQ9sOOdd8hM82WTVxAacAdzblMxa970xg98b+W6T5GUs7rvgzVsp/s4zn9aFw3X0qn7O048r8nJX6UbYv4Wp7AN/Fb8feIunedQiwKfAc3sXsufjDC3THs/cC4Ktof+Po3OX4l8hU4G6gfT3v+ZPogzITOCmj/Nro9VbjvzSqIq7o3Ad4N85S/nv9E3g7+qDvW+C/0SF4L4/3gV9klJ8Zvd5KvBtjVcQVnfsHcFATP2O34A2H8bUTi3nPMnzGUosr8zOWwr/ZfXh72orobz+5jJ+z1OLK/ZyV+qFpLkREZI1W3aYgIiLZlBRERGQNJQUREVlDSUFERNZQUhARkTWUFETwwUAZg4dmm9lnGccvpfSeg8zslgLnu5rZU2m8t0h92lY6AJFqEHzE6c4AZvYrfOK436T8tj8Hfl0gplozm2Vme4QQ/pVyLCKA7hREGmRm30TbvczsBTMba2bvmdk1Znasmb1mZlPMbOvouq5m9qCZ/Tt67JHnNTsAO4UQ3oyOv59xZzI5Og/wMD43v0hZKCmINM638MV4BgLHA9uGEHbFR7CeEV3zW+DGEMJ3gB9F53INxkeax0YBp4cQdgb2BJZE5ROjY5GyUPWRSOP8O0RTJZvZ+0A8HfkUYO9ofz9ggNmaiS43NrMOIYSFGa/TA6jNOP4XcIOZ3Qs8FEKoicrn4rPcipSFkoJI4yzL2F+dcbya5P+ndYChIYQl1G8JsF58EEK4xswex+e7ecXM9gshvBNdU+h1REpK1UcipfcMvr4vAGa2c55rpgPbZFyzdQhhSghhNF5ltF10aluyq5lEUqWkIFJ6ZwKDzewtM3sbn+Y4S3QXsElGg/LZZjbVzN7E7wzilbr2Jo0580XqoVlSRSrEzM4BFoYQCo1VmIAv0vJl+SKT1kx3CiKVczPZbRRZzKwrcIMSgpST7hRERGQN3SmIiMgaSgoiIrKGkoKIiKyhpCAiImsoKYiIyBr/H7AJSMsKke+EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "time=[0]*len(data)\n",
    "for i in range(len(data)):\n",
    "    time[i]=i\n",
    "\n",
    "plt.plot(data.index, data['output'], 'b')\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Normal Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## yager network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningConst = 0.0018 #float(1/train_num_line)\n",
    "mlvq_lwidth=1.5\n",
    "pfkp_lwidth=0.2\n",
    "epsilon = 0.0005\n",
    "discreteSamplePoints=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct(nw,data,ndx):\n",
    "    e1=0\n",
    "    le1=0\n",
    "    e2=0\n",
    "    le2=0\n",
    "    neighbours = 0\n",
    "    iterations=0\n",
    "    min1=max1=data[0]\n",
    "    \n",
    "    for k in range(train_num_line):\n",
    "        max1=max(max1,data[k])\n",
    "        min1=min(min1,data[k])\n",
    "    for j in range(1,nw.num_layers):\n",
    "        lyr=nw.layers[j]\n",
    "        for i in range(lyr.dim):\n",
    "            lyr.neus[i].value=min1+(i+0.5)/(lyr.dim)*(max1-min1)\n",
    "    \n",
    "    neighbours = int(nw.layers[2].dim/5);\n",
    "    interval = (max1-min1)/nw.layers[2].dim;\n",
    "    \n",
    "    for j in range(nw.layers[1].dim): \n",
    "        lyr = nw.layers[2]\n",
    "        for i in range(lyr.dim):\n",
    "            lyr.neus[i].wt[j]=0\n",
    "    \n",
    "    while(1):\n",
    "        for k in range(train_num_line):\n",
    "            winner1=findWinner(data[k],nw.layers[1])\n",
    "            e1+= math.fabs(data[k]-nw.layers[1].neus[winner1].value)\n",
    "            nw.layers[1].neus[winner1].value *= (1-learningConst)\n",
    "            nw.layers[1].neus[winner1].value += learningConst*data[k];\n",
    "            \n",
    "            \n",
    "            lyr = nw.layers[2];\n",
    "            winner2 = findWinner(data[k], lyr);\n",
    "            diff = math.fabs(data[k]-lyr.neus[winner2].value);\n",
    "            lyr.neus[winner2].wt[winner1] += learningConst*(1-diff/interval)\n",
    "            e2 += diff;\n",
    "            \n",
    "            \n",
    "            i=(winner2-1)\n",
    "            for l in range(2,neighbours+2):\n",
    "                if i>=0:\n",
    "                    diff = math.fabs(data[k]-lyr.neus[i].value)\n",
    "                    lyr.neus[i].wt[winner1] += learningConst/l*(1-diff/(l*interval));\n",
    "                i=i-1\n",
    "                \n",
    "            i=(winner2+1)\n",
    "            for l in range(2,neighbours+2):\n",
    "                if i<lyr.dim:\n",
    "                    diff = math.fabs(data[k]-lyr.neus[i].value)\n",
    "                    lyr.neus[i].wt[winner1] += learningConst/l*(1-diff/(l*interval));\n",
    "                i=i+1\n",
    "                \n",
    "            max2 = 0\n",
    "            for i in range(lyr.dim):\n",
    "                max2= max(max2,lyr.neus[i].wt[winner1]);\n",
    "                \n",
    "                \n",
    "            for i in range(lyr.dim):\n",
    "                lyr.neus[i].wt[winner1] = lyr.neus[i].wt[winner1]/max2\n",
    "                \n",
    "        iterations=iterations+1\n",
    "        \n",
    "        if (math.fabs(e1-le1) <= epsilon) and (math.fabs(e2-le2) <= epsilon):\n",
    "            print(\"No. of iterations =\", iterations);\n",
    "            break;\n",
    "        le1 = e1\n",
    "        e1 = 0\n",
    "        le2 = e2\n",
    "        e2 = 0\n",
    "     \n",
    "        \n",
    "    return nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlvq(nw,data,ndx):\n",
    "    e=0\n",
    "    le=0\n",
    "    iterations=0\n",
    "    min2=0\n",
    "    widthFactor=0\n",
    "    interval=0\n",
    "    temp=0\n",
    "    min1=max1=data[0]\n",
    "    \n",
    "    for k in range(train_num_line):\n",
    "        max1=max(max1,data[k])\n",
    "        min1=min(min1,data[k])\n",
    "    for j in range(1,nw.num_layers):\n",
    "        lyr=nw.layers[j]\n",
    "        for i in range(lyr.dim):\n",
    "            lyr.neus[i].value=min1+(i+0.5)/(lyr.dim)*(max1-min1)\n",
    "    \n",
    "    \n",
    "    while(1):\n",
    "        for k in range(train_num_line):\n",
    "            winner1=findWinner(data[k],nw.layers[1])\n",
    "            nw.layers[1].neus[winner1].value *= (1-learningConst)\n",
    "            nw.layers[1].neus[winner1].value += learningConst*data[k];\n",
    "            e+= math.fabs(data[k]-nw.layers[1].neus[winner1].value)\n",
    "            \n",
    "        iterations=iterations+1\n",
    "        \n",
    "        if (math.fabs(e-le) <= epsilon):\n",
    "            print(\"No. of iterations =\", iterations);\n",
    "            break;\n",
    "            \n",
    "        le = e\n",
    "        e = 0\n",
    "        \n",
    "    lyr=nw.layers[1]\n",
    "    for j in range(lyr.dim):\n",
    "        if (j==lyr.dim-1):\n",
    "            widthFactor = math.fabs(lyr.neus[j].value - lyr.neus[j-1].value)/mlvq_lwidth\n",
    "        elif (j==0):\n",
    "            widthFactor = math.fabs(lyr.neus[j].value - lyr.neus[j+1].value)/mlvq_lwidth\n",
    "        else:\n",
    "            min2=min(math.fabs(lyr.neus[j].value - lyr.neus[j-1].value), math.fabs(lyr.neus[j].value-lyr.neus[j+1].value))\n",
    "            widthFactor=min2/mlvq_lwidth\n",
    "        \n",
    "        interval=(max1-min1)/nw.layers[2].dim\n",
    "        cur=min1\n",
    "        \n",
    "        for i in range(nw.layers[2].dim):\n",
    "            temp=0-pow(cur-lyr.neus[j].value,2)/widthFactor\n",
    "            nw.layers[2].neus[i].wt[j]=math.exp(temp)\n",
    "            cur += interval\n",
    "            \n",
    "    return nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pfkp(nw,data,ndx):\n",
    "    e=0\n",
    "    le=0\n",
    "    iterations=0\n",
    "    min2=0\n",
    "    widthFactor=0\n",
    "    interval=0\n",
    "    temp=0\n",
    "    min1=max1=data[0]\n",
    "    \n",
    "    for k in range(train_num_line):\n",
    "        max1=max(max1,data[k])\n",
    "        min1=min(min1,data[k])\n",
    "    for j in range(1,nw.num_layers):\n",
    "        lyr=nw.layers[j]\n",
    "        for i in range(lyr.dim):\n",
    "            lyr.neus[i].value=min1+(i+0.5)/(lyr.dim)*(max1-min1)\n",
    "    \n",
    "    alpha=[0]*nw.layers[1].dim\n",
    "    beta=[0]*nw.layers[1].dim\n",
    "    sigma=[0]*nw.layers[1].dim\n",
    "    tau=[0]*nw.layers[1].dim\n",
    "    phi=[0]*nw.layers[1].dim\n",
    "    \n",
    "    \n",
    "    while(1):\n",
    "        for k in range(train_num_line):\n",
    "            winner1=findWinner(data[k],nw.layers[1])\n",
    "            nw.layers[1].neus[winner1].value *= (1-learningConst)\n",
    "            nw.layers[1].neus[winner1].value += learningConst*data[k];\n",
    "            e+= math.fabs(data[k]-nw.layers[1].neus[winner1].value)\n",
    "            \n",
    "        iterations=iterations+1\n",
    "        \n",
    "        if (math.fabs(e-le) <= epsilon):\n",
    "            print(\"No. of iterations =\", iterations);\n",
    "            break;\n",
    "            \n",
    "        le = e\n",
    "        e = 0\n",
    "        \n",
    "    le = 0 \n",
    "    e = 0\n",
    "    lyr = nw.layers[1]\n",
    "    for j in range(lyr.dim):\n",
    "        phi[j] = alpha[j] = beta[j] = sigma[j] = tau[j] = lyr.neus[j].value;\n",
    "        \n",
    "    for k in range(train_num_line):\n",
    "        winner= findWinner(data[k], nw.layers[1])\n",
    "        phi[winner] *= (1-pfkp_lwidth);\n",
    "        phi[winner] += pfkp_lwidth*data[k];\n",
    "        if(winner):\n",
    "            alpha[winner]=sigma[winner-1]\n",
    "        else:\n",
    "            alpha[winner] = min(alpha[winner],data[k])\n",
    "        beta[winner]= min(beta[winner],phi[winner])\n",
    "        sigma[winner]= max(sigma[winner],phi[winner])\n",
    "        if(winner == nw.layers[1].dim - 1):\n",
    "            tau[winner]= max(tau[winner],data[k])\n",
    "        else:\n",
    "            tau[winner] = beta[winner+1]\n",
    "            \n",
    "    lyr=nw.layers[2]\n",
    "    for j in range(nw.layers[1].dim):\n",
    "        for i in range(lyr.dim):\n",
    "            if(lyr.neus[i].value <= alpha[j] or lyr.neus[i].value >=tau[j]):\n",
    "                lyr.neus[i].wt[j]=0\n",
    "            elif(lyr.neus[i].value < beta[j]):\n",
    "                slope = 1/(beta[j]-alpha[j])\n",
    "                lyr.neus[i].wt[j] = slope * (lyr.neus[i].value - alpha[j])\n",
    "            elif(lyr.neus[i].value >= beta[j] and lyr.neus[i].value <=sigma[j]):\n",
    "                lyr.neus[i].wt[j]=1\n",
    "            else: \n",
    "                slope = 1/(sigma[j]-tau[j])\n",
    "                lyr.neus[i].wt[j]= slope * (lyr.neus[i].value - tau[j]) \n",
    "            \n",
    "    return nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildConnections(source, dest, start, step, size): #layer2->layer3, 0-3\n",
    "    i=k=st=start\n",
    "    for i in range(dest.dim):\n",
    "        currneu=dest.neus[i]\n",
    "        #newneu=[None]*8\n",
    "        newneu=[neuron]*(output_cluster+1)\n",
    "        newwt=[0]*(output_cluster+1)\n",
    "        for k in range(currneu.num_inputs):\n",
    "            newneu[k] = currneu.input[k]\n",
    "            newwt[k] = currneu.wt[k]\n",
    "        currneu.input=newneu\n",
    "        currneu.wt = newwt\n",
    "        k=st\n",
    "        for k in range(st+size):\n",
    "            currneu.input[currneu.num_inputs]=source.neus[k]\n",
    "            currneu.wt[currneu.num_inputs]=0\n",
    "            currneu.num_inputs+=currneu.num_inputs\n",
    "        st+=step\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def printCluster(nw,ndx):\n",
    "        \n",
    "    f = open(\"cluster_dct.txt\", \"a\")\n",
    "    f.write(\" \")\n",
    "    f.write(str(nw.layers[2].dim))\n",
    "    f.write(\"\\n \")\n",
    "    \n",
    "    if ndx == 0:\n",
    "        with open('cluster_dct.csv', 'w', newline='') as csvfile:\n",
    "            spamwriter = csv.writer(csvfile, delimiter=' ')\n",
    "            \n",
    "            fd = open(\"mf_dct.txt\", \"a\")\n",
    "            print(nw.layers[2].dim)\n",
    "            val=[]*nw.layers[2].dim\n",
    "            for j in range(nw.layers[2].dim):\n",
    "                val.append(round(nw.layers[2].neus[j].value,6))\n",
    "                f.write(str(val[j]))\n",
    "                f.write(\" \")\n",
    "                fd.write(str(val[j]))\n",
    "                fd.write(\"\\n\")\n",
    "            f.write(\"\\n \")\n",
    "            spamwriter.writerow(str(val))\n",
    "\n",
    "            i=0\n",
    "            wt=[0]*nw.layers[1].dim*nw.layers[2].dim\n",
    "            for j in range(nw.layers[1].dim):\n",
    "                for k in range(nw.layers[2].dim):\n",
    "                    wt[i]=nw.layers[2].neus[k].wt[j]\n",
    "                    f.write(str(round(wt[i],6)))\n",
    "                    f.write(\" \")\n",
    "                    fd.write(str(round(wt[i],6)))\n",
    "                    fd.write(\"\\n\")\n",
    "                    i=i+1\n",
    "                f.write(\"\\n \")\n",
    "            f.close()   \n",
    "            fd.close()\n",
    "            spamwriter.writerow(str(wt))\n",
    "        \n",
    "    else:\n",
    "        with open('cluster_dct.csv', 'a', newline='') as csvfile:\n",
    "            spamwriter = csv.writer(csvfile, delimiter=' ')\n",
    "        \n",
    "            fd = open(\"mf_dct.txt\", \"a\")\n",
    "            print(nw.layers[2].dim)\n",
    "            val=[]*nw.layers[2].dim\n",
    "            for j in range(nw.layers[2].dim):\n",
    "                val.append(round(nw.layers[2].neus[j].value,6))\n",
    "                f.write(str(val[j]))\n",
    "                f.write(\" \")\n",
    "                fd.write(str(val[j]))\n",
    "                fd.write(\"\\n\")\n",
    "            f.write(\"\\n \")\n",
    "            spamwriter.writerow(str(val))\n",
    "\n",
    "            i=0\n",
    "            wt=[0]*nw.layers[1].dim*nw.layers[2].dim\n",
    "            for j in range(nw.layers[1].dim):\n",
    "                for k in range(nw.layers[2].dim):\n",
    "                    wt[i]=nw.layers[2].neus[k].wt[j]\n",
    "                    f.write(str(round(wt[i],6)))\n",
    "                    f.write(\" \")\n",
    "                    fd.write(str(round(wt[i],6)))\n",
    "                    fd.write(\"\\n\")\n",
    "                    i=i+1\n",
    "                f.write(\"\\n \")\n",
    "            f.close()   \n",
    "            fd.close()\n",
    "            spamwriter.writerow(str(wt))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWinner(value,lyr):\n",
    "    winner=0\n",
    "    error=math.fabs(value-lyr.neus[0].value)\n",
    "    for i in range(1,lyr.dim):\n",
    "        temp=min(error, math.fabs(value-lyr.neus[i].value))\n",
    "        if temp<error:\n",
    "            error=temp\n",
    "            winner=i\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return network \n",
    "def initNN(ndx):\n",
    "    x=[]\n",
    "    nw=network(3)\n",
    "    cent_lyr=output_cluster\n",
    "    \n",
    "#########################  LAYER 1: INPUT LAYER  #############################\n",
    "    layer1=layer(1,0,x) #numofneurons, not ipneu, data\n",
    "    nw.addLayers(0,layer1) #(layernum, layer)\n",
    "    \n",
    "#######################  LAYER 2: CENTROID LAYER  #############################\n",
    "    layer2=layer(cent_lyr,0,x) \n",
    "    nw.addLayers(1,layer2)\n",
    "#   for i in range(1):\n",
    "    buildConnections(layer1,layer2,0,0,1)\n",
    "    \n",
    "#######################  LAYER 3: MEMBERSHIP LAYER  #############################\n",
    "    layer3=layer(discreteSamplePoints,0,x)\n",
    "    nw.addLayers(2,layer3) \n",
    "    for i in range(cent_lyr):\n",
    "        buildConnections(layer2,layer3,i,0,1)\n",
    "    f = open(\"cluster_dct.txt\", \"a\")\n",
    "    f.write(col_names[ndx])\n",
    "    f.close()\n",
    "    print(col_names[ndx])\n",
    "#     nw=mlvq(nw, data_train.iloc[:,ndx],ndx)\n",
    "    nw=dct(nw, data_train.iloc[:,ndx],ndx)\n",
    "#     nw=pfkp(nw, data_train.iloc[:,ndx],ndx)\n",
    "\n",
    "    printCluster(nw,ndx)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "  def __init__(self,dim):\n",
    "    self.num_layers=dim\n",
    "    self.layers = [layer]*dim\n",
    "  def addLayers(self,i,layer):\n",
    "    self.layers[i]=layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer(network):\n",
    "  def __init__(self,dim,neu,x):\n",
    "    self.dim = dim\n",
    "    self.neus = [neuron]*dim\n",
    "    self.ipneus=[ipneuron]*dim\n",
    "    self.count=0\n",
    "    for i in range(dim):\n",
    "        if neu == 0:\n",
    "            self.neus[i]=neuron(dim)\n",
    "        elif neu==1:\n",
    "            self.ipneus[i]=ipneuron(dim,i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron(layer):\n",
    "  def __init__(self,dim):\n",
    "    self.name = None\n",
    "    self.value = 0\n",
    "    self.num_inputs = 0\n",
    "    self.input = [neuron]*(output_cluster*num_var)\n",
    "    self.wt= [0]*(output_cluster*num_var)\n",
    "    self.combFunc=-1\n",
    "    self.actFunc=-1\n",
    "    self.activation=0\n",
    "    self.ip_type=1\n",
    "    self.ipneu_input = [ipneuron]\n",
    "    self.actFunc_arg=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ipneuron(layer):\n",
    "  def __init__(self,dim,count,x):\n",
    "    self.numPt=discreteSamplePoints\n",
    "    self.ip_value=0\n",
    "    self.value=[0]*output_cluster #num_pattern\n",
    "    self.name=col_names[count]\n",
    "    self.mf = [[0 for i in range(discreteSamplePoints)] for j in range(output_cluster+1)]\n",
    "    self.cluster=0\n",
    "    for i in range(output_cluster+1):\n",
    "        for j in range(discreteSamplePoints):\n",
    "            self.mf[i][j]=x[(discreteSamplePoints*i)+j+(count*(discreteSamplePoints*(output_cluster+1)))]\n",
    "    if(count==num_input-1):\n",
    "        count=count+1\n",
    "        for i in range(output_cluster+1):\n",
    "            for j in range(discreteSamplePoints):\n",
    "                Outmf[i][j]=x[(discreteSamplePoints*i)+j+(count*(discreteSamplePoints*(output_cluster+1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWinner1(value,pt,numPt):\n",
    "    winner=0\n",
    "    error=math.fabs(value-pt[0])\n",
    "    for i in range(1,numPt):\n",
    "        temp=min(error, math.fabs(value-pt[i]))\n",
    "        if temp<error:\n",
    "            error=temp\n",
    "            winner=i\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initNN1(x):\n",
    "    nw = network(6)\n",
    "    nw.num_feature=num_input #input\n",
    "    nw.num_pattern=output_cluster #out\n",
    "    \n",
    "#########################  LAYER 1: INPUT LAYER  #############################\n",
    "    \n",
    "    # create input layer\n",
    "    lyr=layer(num_input,1,x) #dim,input neu, dataset\n",
    "    nw.addLayers(0,lyr)\n",
    "    \n",
    "#     print(\"layer 1 with \",nw.layers[0].dim,\" neurons\\n\");\n",
    "#     for j in range(nw.layers[0].dim):\n",
    "#         print(\"membership function of\")\n",
    "#         print(nw.layers[0].ipneus[j].mf,\"\\n\")\n",
    "        \n",
    "        \n",
    "#     print(\"membership function of \\n\")\n",
    "#     print(Outmf,\"\\n\") \n",
    "\n",
    "#######################  LAYER 2: ANTECEDENT LAYER  #############################\n",
    "    \n",
    "    # create antecedent layer\n",
    "    lyr=layer(num_input*output_cluster,0,x) #dim, not input neu, dataset\n",
    "    nw.addLayers(1,lyr)\n",
    "    \n",
    "    # make connections between antecedent and input layers\n",
    "    for i in range(num_input):\n",
    "        for j in range(output_cluster):\n",
    "            neu = lyr.neus[i*output_cluster+j]\n",
    "            neu.ip_type=0\n",
    "            neu.ipneu_input[0]=nw.layers[0].ipneus[i]\n",
    "            neu.wt[0]=1.0\n",
    "            neu.num_inputs=1\n",
    "        \n",
    "    \n",
    "#######################  LAYER 3: RULE LAYER  #############################\n",
    "    \n",
    "    # create rule layer\n",
    "    lyr=layer(pow(output_cluster,num_var),0,x) #dim, not input neu, dataset\n",
    "    nw.addLayers(2,lyr)\n",
    "    \n",
    "\n",
    "##################  LAYER 4: CONSEQUENT LAYER  #############################\n",
    "    \n",
    "    # create output label layer\n",
    "    lyr = layer(output_cluster,0,x)\n",
    "    nw.addLayers(3,lyr)\n",
    "\n",
    "##################  LAYER 5: OUTPUT POSSIBILITY LAYER  #############################\n",
    "    \n",
    "    # create output possibility layer\n",
    "    lyr = layer(output_cluster,0,x)\n",
    "    nw.addLayers(4,lyr)\n",
    "    \n",
    "    yagerTest(nw)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yagerTest(nw):\n",
    "    from sklearn.metrics import r2_score\n",
    "    RMSE=0\n",
    "    result=[0]*test_num_line\n",
    "    time=[0]*test_num_line\n",
    "    ## here change value if num of input change\n",
    "    train_x = (data_train.iloc[:,[0,1,2,3]]).values\n",
    "    train_y = (data_train.iloc[:,[4]]).values\n",
    "    test_x = (data_test.iloc[:,[0,1,2,3]]).values\n",
    "    test_y = (data_test.iloc[:,[4]]).values\n",
    "    global outputCluster\n",
    "    #print(feature)\n",
    "\n",
    "    ## train - rule creation\n",
    "    for i in range(train_num_line):\n",
    "        processRule_train(nw,train_x[i],train_y[i],i)\n",
    "    inputCluster=processInput_train(nw)\n",
    "    outputCluster=processOutput_train(nw)\n",
    "    currentRule=processRule()\n",
    "    \n",
    "    ## test - process the dataset using the rules created\n",
    "    for i in range(test_num_line):\n",
    "        inputCluster_test=processInput_test(nw,test_x[i],test_y[i],i)\n",
    "        result[i]=processOutput(inputCluster_test,outputCluster, currentRule)\n",
    "    \n",
    "    f = open(\"result_yagernetwork.txt\", \"w\")\n",
    "    \n",
    "    print(\"\\npredicted vs actual output\")\n",
    "    f.write(\"predicted vs actual output\\n\")\n",
    "    for i in range(test_num_line):\n",
    "        print(\" \", '{0:.2f}'.format(result[i]),\"  \",'{0:.2f}'.format(test_y[i][0]))\n",
    "        f.write(str( '{0:.2f}'.format(result[i])))\n",
    "        f.write(\"  \")\n",
    "        f.write(str('{0:.2f}'.format(test_y[i][0])))\n",
    "        f.write(\"\\n\")\n",
    "        time[i]=i\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.plot(time, result, 'r-')\n",
    "    plt.plot(time, test_y, 'b-')\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Normal Density\")\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    rms = mean_squared_error(test_y, result)\n",
    "    print(\"RMSE = \",rms)\n",
    "    f.write(\"RMSE = \")\n",
    "    f.write(str(rms))\n",
    "    TestR2Value = r2_score(test_y,result)\n",
    "    print(\"Testing Set R-Square=\", TestR2Value)\n",
    "    f.write(\"R-Square=\")\n",
    "    f.write(str(TestR2Value))\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOutput(x,outputCluster,currentRule):\n",
    "    for i in range(len(currentRule)):\n",
    "#         print(\"rule: \",currentRule[i],\"&& input: \",x)\n",
    "        if(currentRule[i][0]==x[0] and currentRule[i][1]==x[1] and currentRule[i][2]==x[2]):\n",
    "#             print(\"FOUND: rule: \",currentRule[i],\"&& input: \",x)\n",
    "#             print(\"output cluster: \",currentRule[i][4])\n",
    "            return outputCluster[currentRule[i][3]]\n",
    "        elif(i==len(currentRule)-1):\n",
    "#             print(\"NOT FOUND: rule: \",currentRule[i],\"&& input: \",x)\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRule():\n",
    "    updatedRule=[[0 for i in range(num_var+1)] for j in range(ruleCount)]\n",
    "    temp=[[0 for i in range(num_var+1)] for j in range(ruleCount)]\n",
    "    count=0\n",
    "    \n",
    "    for i in range(ruleCount):\n",
    "        for j in range(num_var+1):\n",
    "            updatedRule[i][j]=rules[i][j]\n",
    "#     print(\"updated\", updatedRule)\n",
    "            \n",
    "    for i in range(ruleCount):\n",
    "        tempval=0\n",
    "        tempindex=0\n",
    "        for j in range(i+1,ruleCount):\n",
    "            #here\n",
    "            if(updatedRule[i][0]==updatedRule[j][0] and updatedRule[i][1]==updatedRule[j][1] and updatedRule[i][2]==updatedRule[j][2] and updatedRule[i][num_var]!=-1):\n",
    "                if(updatedRule[i][num_var]>updatedRule[j][num_var] and updatedRule[i][num_var]>tempval):\n",
    "                    tempval=updatedRule[i][num_var]\n",
    "                    tempindex=i\n",
    "                elif(updatedRule[j][num_var]>updatedRule[i][num_var] and updatedRule[j][num_var]>tempval):\n",
    "                    tempval=updatedRule[j][num_var]\n",
    "                    tempindex=j\n",
    "        if(tempval!=0 and updatedRule[i][num_var]!=-1):\n",
    "            temp[count]=updatedRule[tempindex]\n",
    "            count=count+1\n",
    "        elif(updatedRule[i][num_var]!=-1):\n",
    "            temp[count]=updatedRule[i]\n",
    "            count=count+1\n",
    "        for j in range(ruleCount):\n",
    "            updatedRule[i][num_var]=-1\n",
    "            #here\n",
    "            if(updatedRule[i][0]==updatedRule[j][0] and updatedRule[i][1]==updatedRule[j][1] and updatedRule[i][2]==updatedRule[j][2]):\n",
    "                updatedRule[j][num_var]=-1\n",
    "        \n",
    "    currentRule=[[0 for i in range(num_var)] for j in range(count)]    \n",
    "    for i in range(count):\n",
    "        for j in range(num_var):\n",
    "            currentRule[i][j]=temp[i][j]\n",
    "    \n",
    "#     print(\"temp\", temp)\n",
    "    print(\"currentRule\", currentRule)\n",
    "    return currentRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processInput_test(nw,x,y,count):\n",
    "    value=[0]*output_cluster\n",
    "    inputCluster=[0]*num_input\n",
    "    \n",
    "    ##find the similarity score for input value\n",
    "    for i in range(num_input):\n",
    "        ipneu=nw.layers[0].ipneus[i]\n",
    "        ipneu.ip_value=x[i]\n",
    "        mf=ipneu.mf\n",
    "        winner=findWinner1(x[i],mf[0],ipneu.numPt)\n",
    "        for j in range(output_cluster):\n",
    "            ipneu.value[j] = mf[j+1][winner]\n",
    "            fuzzytest_ltsm.iloc[count][(i*output_cluster)+j]=mf[j+1][winner]#ipneu.value[j]\n",
    "            \n",
    "    ##find the cluster it belongs to for the input value        \n",
    "    for i in range(num_input):\n",
    "        temp=0\n",
    "        for j in range(output_cluster):\n",
    "            if(nw.layers[0].ipneus[i].value[j]>=temp):\n",
    "                nw.layers[0].ipneus[i].cluster=j\n",
    "                temp=nw.layers[0].ipneus[i].value[j]\n",
    "\n",
    "    for i in range(num_input):\n",
    "        inputCluster[i]=nw.layers[0].ipneus[i].cluster\n",
    "#         print(\"input cluster \",inputCluster[i])\n",
    "\n",
    "    for i in range(num_input):\n",
    "        print(\"test input: \",x[i],\" cluster: \",nw.layers[0].ipneus[i].cluster) \n",
    "\n",
    "    ##find the similarity score for output value             \n",
    "    winner=findWinner1(y[0],Outmf[0],ipneu.numPt)\n",
    "    for j in range(output_cluster):\n",
    "        value[j] = Outmf[j+1][winner]\n",
    "    fuzzytest_ltsm.iloc[count][(num_input*output_cluster)]= y[0]\n",
    "\n",
    "    ##find the cluster it belongs to for the output value             \n",
    "    temp=0\n",
    "    for j in range(output_cluster):\n",
    "        if(value[j]>=temp):\n",
    "            cluster=j\n",
    "            temp=value[j]\n",
    "\n",
    "    print(\"output cluster \",cluster) \n",
    "    \n",
    "    return inputCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRule_train(nw,x,y,count):\n",
    "    value=[0]*output_cluster\n",
    "    actualValue=[0]*output_cluster\n",
    "    global ruleCount\n",
    "    \n",
    "    ##find the similarity score for input value\n",
    "    for i in range(num_input):\n",
    "        ipneu=nw.layers[0].ipneus[i]\n",
    "        ipneu.ip_value=x[i]\n",
    "        mf=ipneu.mf\n",
    "        winner=findWinner1(x[i],mf[0],ipneu.numPt)\n",
    "        for j in range(output_cluster):\n",
    "            ipneu.value[j] = mf[j+1][winner]\n",
    "            fuzzytrain_ltsm.iloc[count][(i*output_cluster)+j]=mf[j+1][winner]#ipneu.value[j]\n",
    "            \n",
    "    ##find the cluster it belongs to for the input value        \n",
    "    for i in range(num_input):\n",
    "        temp=0\n",
    "        for j in range(output_cluster):\n",
    "            if(nw.layers[0].ipneus[i].value[j]>=temp):\n",
    "                nw.layers[0].ipneus[i].cluster=j\n",
    "                temp=nw.layers[0].ipneus[i].value[j]\n",
    "                \n",
    "    ##find the similarity score for output value             \n",
    "    winner=findWinner1(y[0],Outmf[0],ipneu.numPt)\n",
    "    for j in range(output_cluster):\n",
    "        value[j] = Outmf[j+1][winner]\n",
    "    fuzzytrain_ltsm.iloc[count][(num_input*output_cluster)]= y[0]\n",
    "        \n",
    "    ##find the cluster it belongs to for the output value             \n",
    "    temp=0\n",
    "    for j in range(output_cluster):\n",
    "        if(value[j]>=temp):\n",
    "            cluster=j\n",
    "            temp=value[j]\n",
    "\n",
    "    createNewRule=0\n",
    "    ##create rules\n",
    "    for i in range(ruleCount+1):\n",
    "        sameClusters=0\n",
    "        for j in range(num_var):\n",
    "            if(j<num_input): ##check input of rule\n",
    "                if (rules[i][j]==nw.layers[0].ipneus[j].cluster):\n",
    "                    sameClusters+=1\n",
    "            else: ##check ouput of rule\n",
    "                if(rules[i][j]==cluster):\n",
    "                    sameClusters+=1\n",
    "        if (sameClusters==num_var):\n",
    "            rules[i][num_var]+=1\n",
    "            break\n",
    "        elif (i==ruleCount):\n",
    "            createNewRule=1  \n",
    "    if createNewRule==1:\n",
    "        for i in range(num_input):\n",
    "            rules[ruleCount][i]=nw.layers[0].ipneus[i].cluster\n",
    "        rules[ruleCount][num_var-1]=cluster\n",
    "        rules[ruleCount][num_var]=1\n",
    "        ruleCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOutput_train(nw):\n",
    "    fuzzyValue=[0]*output_cluster\n",
    "    \n",
    "    for k in range(output_cluster):\n",
    "        tempValue=0\n",
    "        tempIndex=0\n",
    "        for j in range(discreteSamplePoints):\n",
    "            if(Outmf[k+1][j]>tempValue): \n",
    "                tempValue=Outmf[k+1][j]\n",
    "                tempIndex=j\n",
    "        fuzzyValue[k]=Outmf[0][tempIndex]\n",
    "                \n",
    "    return fuzzyValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processInput_train(nw):\n",
    "#     mf=[[0 for i in range(discreteSamplePoints)] for j in range(output_cluster+1)]\n",
    "    fuzzyValue=[[0 for i in range((output_cluster))] for j in range(num_input)] \n",
    "    tempValue=0\n",
    "    tempIndex=0\n",
    "    ##find the similarity score for input value\n",
    "    for i in range(num_input):\n",
    "        ipneu=nw.layers[0].ipneus[i]\n",
    "        mf=ipneu.mf\n",
    "        for k in range(output_cluster):\n",
    "            tempValue=0\n",
    "            tempIndex=0\n",
    "            for j in range(discreteSamplePoints):\n",
    "                if(mf[k+1][j]>tempValue): \n",
    "                    tempValue=mf[k+1][j]\n",
    "                    tempIndex=j\n",
    "            fuzzyValue[i][k]=mf[0][tempIndex]\n",
    "    \n",
    "    return fuzzyValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "No. of iterations = 107\n",
      "50\n",
      "High\n",
      "No. of iterations = 249\n",
      "50\n",
      "Low\n",
      "No. of iterations = 355\n",
      "50\n",
      "Close\n",
      "No. of iterations = 68\n",
      "50\n",
      "output\n",
      "No. of iterations = 67\n",
      "50\n",
      "2750\n",
      "currentRule [[0, 0, 0, 0, 0], [0, 1, 0, 1, 1], [1, 1, 0, 0, 0], [1, 0, 0, 0, 0], [1, 1, 1, 1, 1], [1, 2, 1, 2, 2], [2, 2, 1, 1, 1], [0, 0, 1, 1, 0], [1, 0, 1, 0, 1], [2, 2, 2, 2, 2], [2, 3, 2, 3, 3], [2, 3, 3, 3, 3], [3, 3, 3, 3, 3], [3, 3, 2, 3, 2], [4, 4, 3, 3, 4], [4, 3, 3, 3, 4], [3, 4, 3, 4, 4], [4, 4, 4, 4, 4], [4, 5, 5, 5, 4], [5, 5, 4, 4, 4], [4, 5, 4, 5, 5], [5, 5, 5, 5, 5], [5, 6, 5, 6, 6], [6, 6, 6, 6, 7], [6, 5, 5, 6, 6], [5, 6, 6, 6, 6], [6, 7, 7, 7, 7], [7, 7, 7, 7, 7], [7, 8, 8, 8, 8], [8, 8, 8, 8, 8], [8, 9, 8, 9, 9], [9, 9, 9, 9, 9]]\n",
      "test input:  72.48585391465383  cluster:  0\n",
      "test input:  72.62584347237448  cluster:  0\n",
      "test input:  72.00056485074225  cluster:  0\n",
      "test input:  72.59784698486328  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.43917302090834  cluster:  0\n",
      "test input:  72.7938069530622  cluster:  0\n",
      "test input:  72.00054253209338  cluster:  0\n",
      "test input:  72.56049346923828  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.36452823373693  cluster:  0\n",
      "test input:  72.46718676068467  cluster:  0\n",
      "test input:  71.96322866116783  cluster:  0\n",
      "test input:  72.39252471923828  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.54183274024707  cluster:  0\n",
      "test input:  72.85913566589218  cluster:  0\n",
      "test input:  72.25251917374189  cluster:  0\n",
      "test input:  72.46717071533203  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.54184062037088  cluster:  0\n",
      "test input:  72.65382654974574  cluster:  0\n",
      "test input:  68.79015534271858  cluster:  0\n",
      "test input:  68.96747589111328  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.59417361061045  cluster:  0\n",
      "test input:  70.27403377158873  cluster:  0\n",
      "test input:  68.52884611102593  cluster:  0\n",
      "test input:  69.52742767333984  cluster:  0\n",
      "output cluster  0\n",
      "test input:  69.37810276925322  cluster:  0\n",
      "test input:  69.79807136451667  cluster:  0\n",
      "test input:  68.72482778128342  cluster:  0\n",
      "test input:  69.58341979980469  cluster:  0\n",
      "output cluster  0\n",
      "test input:  69.67675782289011  cluster:  0\n",
      "test input:  70.63800845217936  cluster:  0\n",
      "test input:  69.41544068157914  cluster:  0\n",
      "test input:  70.5820083618164  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.65667909112032  cluster:  0\n",
      "test input:  70.69401011589835  cluster:  0\n",
      "test input:  69.73275936840031  cluster:  0\n",
      "test input:  69.91007995605469  cluster:  0\n",
      "output cluster  0\n",
      "test input:  69.80740830781396  cluster:  0\n",
      "test input:  69.94739072423606  cluster:  0\n",
      "test input:  69.15412617713527  cluster:  0\n",
      "test input:  69.37810516357422  cluster:  0\n",
      "output cluster  0\n",
      "test input:  69.37811953303411  cluster:  0\n",
      "test input:  69.5274436350302  cluster:  0\n",
      "test input:  68.82750292729499  cluster:  0\n",
      "test input:  69.1634750366211  cluster:  0\n",
      "output cluster  0\n",
      "test input:  69.2381225706507  cluster:  0\n",
      "test input:  69.91006664841822  cluster:  0\n",
      "test input:  69.04214006799577  cluster:  0\n",
      "test input:  69.7234115600586  cluster:  0\n",
      "output cluster  0\n",
      "test input:  69.69542773493914  cluster:  0\n",
      "test input:  69.91940676148623  cluster:  0\n",
      "test input:  69.23813514569076  cluster:  0\n",
      "test input:  69.62076568603516  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.99546792044322  cluster:  0\n",
      "test input:  69.09812642918678  cluster:  0\n",
      "test input:  67.5769249853294  cluster:  0\n",
      "test input:  68.07154846191406  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.1462109484461  cluster:  0\n",
      "test input:  68.5661795636913  cluster:  0\n",
      "test input:  67.38094287462924  cluster:  0\n",
      "test input:  68.05288696289062  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.01556845317967  cluster:  0\n",
      "test input:  68.66885071253866  cluster:  0\n",
      "test input:  67.7822548863011  cluster:  0\n",
      "test input:  68.58485412597656  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.82747964681043  cluster:  0\n",
      "test input:  69.0048001779119  cluster:  0\n",
      "test input:  68.35151813289542  cluster:  0\n",
      "test input:  68.54750061035156  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.85691018667454  cluster:  0\n",
      "test input:  68.7061749033136  cluster:  0\n",
      "test input:  67.52093811417605  cluster:  0\n",
      "test input:  67.60493469238281  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.76357631027065  cluster:  0\n",
      "test input:  68.00622435394487  cluster:  0\n",
      "test input:  67.20362531116055  cluster:  0\n",
      "test input:  67.46493530273438  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.81024482042407  cluster:  0\n",
      "test input:  67.81024482042407  cluster:  0\n",
      "test input:  66.97964213928671  cluster:  0\n",
      "test input:  67.5115966796875  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.46493029990903  cluster:  0\n",
      "test input:  68.24886021649861  cluster:  0\n",
      "test input:  67.25027875408318  cluster:  0\n",
      "test input:  67.56758880615234  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.56760503073588  cluster:  0\n",
      "test input:  67.97823203414767  cluster:  0\n",
      "test input:  67.14763637157898  cluster:  0\n",
      "test input:  67.80091857910156  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.14620558821797  cluster:  0\n",
      "test input:  68.14620558821797  cluster:  0\n",
      "test input:  67.5302616358696  cluster:  0\n",
      "test input:  67.5769271850586  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.51159885739708  cluster:  0\n",
      "test input:  68.52884953914452  cluster:  0\n",
      "test input:  67.25962338072712  cluster:  0\n",
      "test input:  68.28620147705078  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.21152920330442  cluster:  0\n",
      "test input:  68.25819474983784  cluster:  0\n",
      "test input:  67.5022613131032  cluster:  0\n",
      "test input:  67.56758880615234  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.39961143480612  cluster:  0\n",
      "test input:  67.62359042248042  cluster:  0\n",
      "test input:  67.03564290977401  cluster:  0\n",
      "test input:  67.16629791259766  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.00766457412942  cluster:  0\n",
      "test input:  67.91291530453131  cluster:  0\n",
      "test input:  66.86767499885802  cluster:  0\n",
      "test input:  67.21297454833984  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.30628239003349  cluster:  0\n",
      "test input:  68.04355391920559  cluster:  0\n",
      "test input:  67.14762379553494  cluster:  0\n",
      "test input:  67.88489532470703  cluster:  0\n",
      "output cluster  0\n",
      "test input:  67.71691751584673  cluster:  0\n",
      "test input:  68.86482323067847  cluster:  0\n",
      "test input:  67.33428702434547  cluster:  0\n",
      "test input:  68.80883026123047  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.54751468984566  cluster:  0\n",
      "test input:  68.83682831898753  cluster:  0\n",
      "test input:  68.08088761334524  cluster:  0\n",
      "test input:  68.65950775146484  cluster:  0\n",
      "output cluster  0\n",
      "test input:  68.72483001352313  cluster:  0\n",
      "test input:  70.82465169755432  cluster:  0\n",
      "test input:  68.42618899215636  cluster:  0\n",
      "test input:  70.37669372558594  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.28337132185428  cluster:  0\n",
      "test input:  70.93665353207824  cluster:  0\n",
      "test input:  70.02206128583047  cluster:  0\n",
      "test input:  70.89932250976562  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.86198425292969  cluster:  0\n",
      "test input:  71.33794583861746  cluster:  0\n",
      "test input:  70.60067424358385  cluster:  0\n",
      "test input:  70.86198425292969  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.92731899645896  cluster:  0\n",
      "test input:  71.15129801017015  cluster:  0\n",
      "test input:  70.73133646944112  cluster:  0\n",
      "test input:  70.89932250976562  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.92730367040693  cluster:  0\n",
      "test input:  71.09528967443283  cluster:  0\n",
      "test input:  70.70332470509337  cluster:  0\n",
      "test input:  70.8806381225586  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.88064295850621  cluster:  0\n",
      "test input:  72.0005521018075  cluster:  0\n",
      "test input:  70.88064295850621  cluster:  0\n",
      "test input:  71.75790405273438  cluster:  0\n",
      "output cluster  0\n",
      "test input:  71.9818751864572  cluster:  0\n",
      "test input:  72.19652672957685  cluster:  0\n",
      "test input:  71.79522724300219  cluster:  0\n",
      "test input:  72.08453369140625  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.20586589101146  cluster:  0\n",
      "test input:  72.20586589101146  cluster:  0\n",
      "test input:  71.83256286001101  cluster:  0\n",
      "test input:  72.01921081542969  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.1405452530798  cluster:  0\n",
      "test input:  72.26186572361969  cluster:  0\n",
      "test input:  71.93522821050168  cluster:  0\n",
      "test input:  72.09387969970703  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.3085393827688  cluster:  0\n",
      "test input:  72.55118035104861  cluster:  0\n",
      "test input:  71.93523627443079  cluster:  0\n",
      "test input:  72.07522583007812  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.28051901656906  cluster:  0\n",
      "test input:  73.18577653034252  cluster:  0\n",
      "test input:  71.93521959555319  cluster:  0\n",
      "test input:  73.11111450195312  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.30711698190794  cluster:  0\n",
      "test input:  74.36169161751887  cluster:  0\n",
      "test input:  73.08313085739964  cluster:  0\n",
      "test input:  73.31644439697266  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.70841016047311  cluster:  0\n",
      "test input:  74.52033665084639  cluster:  0\n",
      "test input:  73.44709303788305  cluster:  0\n",
      "test input:  73.87639617919922  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.1563668974031  cluster:  0\n",
      "test input:  74.39901494712078  cluster:  0\n",
      "test input:  73.49375736793404  cluster:  0\n",
      "test input:  73.96971893310547  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.66032472241831  cluster:  0\n",
      "test input:  74.66032472241831  cluster:  0\n",
      "test input:  73.437764183541  cluster:  0\n",
      "test input:  73.6617431640625  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.63375922482382  cluster:  0\n",
      "test input:  73.85773824349951  cluster:  0\n",
      "test input:  72.98981153594596  cluster:  0\n",
      "test input:  73.26979064941406  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.48443331474778  cluster:  0\n",
      "test input:  73.8857329033721  cluster:  0\n",
      "test input:  72.91514768623038  cluster:  0\n",
      "test input:  73.09246826171875  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.1484635596892  cluster:  0\n",
      "test input:  73.29778765330181  cluster:  0\n",
      "test input:  71.63659627276739  cluster:  0\n",
      "test input:  72.59784698486328  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.73782898369673  cluster:  0\n",
      "test input:  73.54975551780494  cluster:  0\n",
      "test input:  72.30853293941982  cluster:  0\n",
      "test input:  73.52175903320312  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.9137192370379  cluster:  0\n",
      "test input:  74.79098033821744  cluster:  0\n",
      "test input:  73.71773673744397  cluster:  0\n",
      "test input:  73.93238830566406  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.92306433845611  cluster:  0\n",
      "test input:  74.31502939367431  cluster:  0\n",
      "test input:  73.5777577211461  cluster:  0\n",
      "test input:  73.97905731201172  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.96971138306864  cluster:  0\n",
      "test input:  74.19369034139712  cluster:  0\n",
      "test input:  72.91512984395345  cluster:  0\n",
      "test input:  72.98979187011719  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.24300159595501  cluster:  0\n",
      "test input:  73.60874713342652  cluster:  0\n",
      "test input:  72.54902380112784  cluster:  0\n",
      "test input:  72.65218353271484  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.09297142916421  cluster:  0\n",
      "test input:  73.25239753792101  cluster:  0\n",
      "test input:  72.51152619408107  cluster:  0\n",
      "test input:  72.68971252441406  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.00855938986874  cluster:  0\n",
      "test input:  73.0554527854434  cluster:  0\n",
      "test input:  72.07074871779609  cluster:  0\n",
      "test input:  72.18328857421875  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.27705967035818  cluster:  0\n",
      "test input:  72.51151231067398  cluster:  0\n",
      "test input:  71.28298276499575  cluster:  0\n",
      "test input:  71.37676239013672  cluster:  0\n",
      "output cluster  0\n",
      "test input:  71.6299808906526  cluster:  0\n",
      "test input:  71.94884025901023  cluster:  0\n",
      "test input:  70.2889112622587  cluster:  0\n",
      "test input:  70.38269805908203  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.60776250052598  cluster:  0\n",
      "test input:  71.00164124409005  cluster:  0\n",
      "test input:  70.45770936682887  cluster:  0\n",
      "test input:  70.71092224121094  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.9078642305251  cluster:  0\n",
      "test input:  71.39552262318797  cluster:  0\n",
      "test input:  70.66403145672994  cluster:  0\n",
      "test input:  71.3580093383789  cluster:  0\n",
      "output cluster  0\n",
      "test input:  71.50807056784325  cluster:  0\n",
      "test input:  71.50807056784325  cluster:  0\n",
      "test input:  71.12356472124401  cluster:  0\n",
      "test input:  71.3955307006836  cluster:  0\n",
      "output cluster  0\n",
      "test input:  71.44240703748198  cluster:  0\n",
      "test input:  72.051985317881  cluster:  0\n",
      "test input:  71.30173402586274  cluster:  0\n",
      "test input:  71.59245300292969  cluster:  0\n",
      "output cluster  0\n",
      "test input:  71.60184027623963  cluster:  0\n",
      "test input:  71.96758585009061  cluster:  0\n",
      "test input:  71.55495403762612  cluster:  0\n",
      "test input:  71.90193939208984  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.02386877529113  cluster:  0\n",
      "test input:  72.37085417514655  cluster:  0\n",
      "test input:  71.83630233151825  cluster:  0\n",
      "test input:  72.052001953125  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.35208847905884  cluster:  0\n",
      "test input:  72.51151456224153  cluster:  0\n",
      "test input:  71.7143769914011  cluster:  0\n",
      "test input:  71.96758270263672  cluster:  0\n",
      "output cluster  0\n",
      "test input:  71.87381989733119  cluster:  0\n",
      "test input:  73.02733034166057  cluster:  0\n",
      "test input:  71.81755353831514  cluster:  0\n",
      "test input:  72.83039093017578  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.81160653929891  cluster:  0\n",
      "test input:  74.04951611126047  cluster:  0\n",
      "test input:  72.71782692042366  cluster:  0\n",
      "test input:  73.79631042480469  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.09642205371  cluster:  0\n",
      "test input:  74.60284066735989  cluster:  0\n",
      "test input:  73.80569588452938  cluster:  0\n",
      "test input:  74.28398132324219  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.33087820538395  cluster:  0\n",
      "test input:  75.52189464813856  cluster:  0\n",
      "test input:  74.27460469794218  cluster:  0\n",
      "test input:  74.98734283447266  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.1655502125763  cluster:  0\n",
      "test input:  75.72823536011752  cluster:  0\n",
      "test input:  75.10927668937128  cluster:  0\n",
      "test input:  75.1843032836914  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.39998300322313  cluster:  0\n",
      "test input:  76.31903349821464  cluster:  0\n",
      "test input:  75.15615021366442  cluster:  0\n",
      "test input:  76.1783676147461  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.24401010335318  cluster:  0\n",
      "test input:  76.24401010335318  cluster:  0\n",
      "test input:  74.98734008877544  cluster:  0\n",
      "test input:  75.45624542236328  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.69071133596925  cluster:  0\n",
      "test input:  76.47847615482776  cluster:  0\n",
      "test input:  75.2686993238539  cluster:  0\n",
      "test input:  76.36593627929688  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.78793439681168  cluster:  0\n",
      "test input:  77.04114728220566  cluster:  0\n",
      "test input:  75.24055252909804  cluster:  0\n",
      "test input:  75.41873168945312  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.8032379449922  cluster:  0\n",
      "test input:  75.8032379449922  cluster:  0\n",
      "test input:  75.3249525013529  cluster:  0\n",
      "test input:  75.45624542236328  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.21241813227178  cluster:  0\n",
      "test input:  75.24993142028671  cluster:  0\n",
      "test input:  73.99326846896285  cluster:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  74.86543273925781  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.9873477509998  cluster:  0\n",
      "test input:  75.34371326516614  cluster:  0\n",
      "test input:  74.86543492758382  cluster:  0\n",
      "test input:  75.09050750732422  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.39998441789888  cluster:  0\n",
      "test input:  75.64381721203245  cluster:  0\n",
      "test input:  75.12801844654376  cluster:  0\n",
      "test input:  75.61567687988281  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.67194640504601  cluster:  0\n",
      "test input:  75.82199239397022  cluster:  0\n",
      "test input:  74.82791535819825  cluster:  0\n",
      "test input:  75.22179412841797  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.51250724320488  cluster:  0\n",
      "test input:  76.26275859391266  cluster:  0\n",
      "test input:  74.9592024171264  cluster:  0\n",
      "test input:  76.12208557128906  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.22526463923785  cluster:  0\n",
      "test input:  76.75981653681154  cluster:  0\n",
      "test input:  75.82200568809074  cluster:  0\n",
      "test input:  76.13148498535156  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.33779862900242  cluster:  0\n",
      "test input:  76.33779862900242  cluster:  0\n",
      "test input:  75.74697326072354  cluster:  0\n",
      "test input:  76.30028533935547  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.30028438586552  cluster:  0\n",
      "test input:  77.2193349284813  cluster:  0\n",
      "test input:  76.20650474038428  cluster:  0\n",
      "test input:  76.57225036621094  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.42219135018242  cluster:  0\n",
      "test input:  77.10679630407036  cluster:  0\n",
      "test input:  76.30965864620417  cluster:  0\n",
      "test input:  76.75980377197266  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.94736898123742  cluster:  0\n",
      "test input:  78.11025221841696  cluster:  0\n",
      "test input:  75.52189274411492  cluster:  0\n",
      "test input:  75.87826538085938  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.31556256360334  cluster:  0\n",
      "test input:  77.05051779543138  cluster:  0\n",
      "test input:  75.16551659699661  cluster:  0\n",
      "test input:  76.30964660644531  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.00017597191164  cluster:  0\n",
      "test input:  76.71291406964133  cluster:  0\n",
      "test input:  75.28743787418198  cluster:  0\n",
      "test input:  75.34370422363281  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.64033729436994  cluster:  0\n",
      "test input:  75.94390052488508  cluster:  0\n",
      "test input:  72.39897068066436  cluster:  0\n",
      "test input:  72.65218353271484  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.25139690614789  cluster:  0\n",
      "test input:  73.15860839416561  cluster:  0\n",
      "test input:  68.44142212521658  cluster:  0\n",
      "test input:  72.88664245605469  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.69907514944718  cluster:  0\n",
      "test input:  73.75880571513699  cluster:  0\n",
      "test input:  72.4364893241203  cluster:  0\n",
      "test input:  72.4646224975586  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.37084573702305  cluster:  0\n",
      "test input:  73.08358383040138  cluster:  0\n",
      "test input:  70.14823908815447  cluster:  0\n",
      "test input:  70.5327377319336  cluster:  0\n",
      "output cluster  0\n",
      "test input:  70.54211156300661  cluster:  0\n",
      "test input:  71.8925610608022  cluster:  0\n",
      "test input:  69.23855545524489  cluster:  0\n",
      "test input:  71.37676239013672  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.2583092720789  cluster:  0\n",
      "test input:  73.28051938718853  cluster:  0\n",
      "test input:  72.24892916274086  cluster:  0\n",
      "test input:  72.73658752441406  cluster:  0\n",
      "output cluster  0\n",
      "test input:  72.56779059707439  cluster:  0\n",
      "test input:  73.76819432317724  cluster:  0\n",
      "test input:  72.26769145428067  cluster:  0\n",
      "test input:  73.6181411743164  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.336799754138  cluster:  0\n",
      "test input:  74.89356907523945  cluster:  0\n",
      "test input:  73.05546081455242  cluster:  0\n",
      "test input:  74.79978942871094  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.43749146125593  cluster:  0\n",
      "test input:  75.6625640153253  cluster:  0\n",
      "test input:  73.71191613358413  cluster:  0\n",
      "test input:  75.38121795654297  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.94981242469568  cluster:  0\n",
      "test input:  75.30618498900753  cluster:  0\n",
      "test input:  73.95573559777569  cluster:  0\n",
      "test input:  74.10578155517578  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.94638423547374  cluster:  0\n",
      "test input:  75.43750721043973  cluster:  0\n",
      "test input:  73.66504527288342  cluster:  0\n",
      "test input:  73.89949798583984  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.14331145373738  cluster:  0\n",
      "test input:  75.64381429365866  cluster:  0\n",
      "test input:  73.93699195550181  cluster:  0\n",
      "test input:  74.1995849609375  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.38716574094667  cluster:  0\n",
      "test input:  74.70602519082475  cluster:  0\n",
      "test input:  73.11174225129415  cluster:  0\n",
      "test input:  73.3368148803711  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.76819096502669  cluster:  0\n",
      "test input:  75.49375916880557  cluster:  0\n",
      "test input:  73.63689088828667  cluster:  0\n",
      "test input:  75.47500610351562  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.03769495686304  cluster:  0\n",
      "test input:  76.63789324575882  cluster:  0\n",
      "test input:  75.64381617132418  cluster:  0\n",
      "test input:  76.58162689208984  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.65662744247763  cluster:  0\n",
      "test input:  77.40687869638212  cluster:  0\n",
      "test input:  76.17834924416658  cluster:  0\n",
      "test input:  76.6097412109375  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.02240209789346  cluster:  0\n",
      "test input:  77.56633410499151  cluster:  0\n",
      "test input:  75.7188455961809  cluster:  0\n",
      "test input:  75.72822570800781  cluster:  0\n",
      "output cluster  1\n",
      "test input:  75.96267874564701  cluster:  0\n",
      "test input:  75.96267874564701  cluster:  0\n",
      "test input:  74.29337657972883  cluster:  0\n",
      "test input:  74.64974212646484  cluster:  0\n",
      "output cluster  1\n",
      "test input:  74.34962587729947  cluster:  0\n",
      "test input:  75.75634182751557  cluster:  0\n",
      "test input:  74.13393343835897  cluster:  0\n",
      "test input:  75.57815551757812  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.20301842065659  cluster:  0\n",
      "test input:  76.84418662404093  cluster:  0\n",
      "test input:  75.01545204731447  cluster:  0\n",
      "test input:  76.68475341796875  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.43504868067501  cluster:  0\n",
      "test input:  79.21689088963184  cluster:  0\n",
      "test input:  76.93801002950345  cluster:  0\n",
      "test input:  78.69171905517578  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.88517839803256  cluster:  0\n",
      "test input:  78.87925541090277  cluster:  0\n",
      "test input:  77.86641817801943  cluster:  0\n",
      "test input:  78.72920227050781  cluster:  0\n",
      "output cluster  0\n",
      "test input:  78.98241284978633  cluster:  0\n",
      "test input:  79.7232841102649  cluster:  0\n",
      "test input:  78.43848096412954  cluster:  0\n",
      "test input:  79.58261108398438  cluster:  0\n",
      "output cluster  0\n",
      "test input:  80.09839947868271  cluster:  0\n",
      "test input:  81.28003557541857  cluster:  1\n",
      "test input:  79.79829324531008  cluster:  0\n",
      "test input:  81.14874267578125  cluster:  1\n",
      "output cluster  0\n",
      "test input:  81.32693029436969  cluster:  1\n",
      "test input:  81.58951609794264  cluster:  1\n",
      "test input:  79.88270121979194  cluster:  0\n",
      "test input:  80.54854583740234  cluster:  1\n",
      "output cluster  0\n",
      "test input:  81.09249448640779  cluster:  1\n",
      "test input:  81.09249448640779  cluster:  1\n",
      "test input:  79.73266464302485  cluster:  0\n",
      "test input:  79.9483642578125  cluster:  0\n",
      "output cluster  0\n",
      "test input:  80.27660356542204  cluster:  1\n",
      "test input:  80.31411685625478  cluster:  0\n",
      "test input:  78.86988735637283  cluster:  0\n",
      "test input:  79.12310028076172  cluster:  0\n",
      "output cluster  0\n",
      "test input:  79.47166731273018  cluster:  0\n",
      "test input:  79.47166731273018  cluster:  0\n",
      "test input:  78.69918340481026  cluster:  0\n",
      "test input:  79.20789337158203  cluster:  0\n",
      "output cluster  0\n",
      "test input:  79.31148570607056  cluster:  0\n",
      "test input:  79.5940974409878  cluster:  0\n",
      "test input:  78.71798740687863  cluster:  0\n",
      "test input:  79.10423278808594  cluster:  0\n",
      "output cluster  0\n",
      "test input:  79.0571479417388  cluster:  0\n",
      "test input:  79.32092183832322  cluster:  0\n",
      "test input:  78.0585732797265  cluster:  0\n",
      "test input:  78.7745361328125  cluster:  0\n",
      "output cluster  0\n",
      "test input:  79.14193964561272  cluster:  0\n",
      "test input:  79.82963487643495  cluster:  0\n",
      "test input:  78.87816573859598  cluster:  0\n",
      "test input:  79.2738265991211  cluster:  0\n",
      "output cluster  1\n",
      "test input:  79.24554852402052  cluster:  0\n",
      "test input:  79.9709266071059  cluster:  0\n",
      "test input:  79.12307696062419  cluster:  0\n",
      "test input:  79.33032989501953  cluster:  0\n",
      "output cluster  1\n",
      "test input:  78.76510379645448  cluster:  0\n",
      "test input:  79.25496851677434  cluster:  0\n",
      "test input:  77.17303087764213  cluster:  0\n",
      "test input:  77.2672348022461  cluster:  0\n",
      "output cluster  1\n",
      "test input:  77.44622995203571  cluster:  0\n",
      "test input:  77.86073585929877  cluster:  0\n",
      "test input:  75.9483680936425  cluster:  0\n",
      "test input:  76.04257202148438  cluster:  0\n",
      "output cluster  1\n",
      "test input:  77.19188229604707  cluster:  0\n",
      "test input:  78.85931417870636  cluster:  0\n",
      "test input:  77.03172770507695  cluster:  0\n",
      "test input:  78.66148376464844  cluster:  0\n",
      "output cluster  1\n",
      "test input:  78.85931159420598  cluster:  0\n",
      "test input:  79.56585184438529  cluster:  0\n",
      "test input:  76.67374737447655  cluster:  0\n",
      "test input:  77.17303466796875  cluster:  0\n",
      "output cluster  1\n",
      "test input:  77.19189002638826  cluster:  0\n",
      "test input:  79.82022096888382  cluster:  0\n",
      "test input:  77.19189002638826  cluster:  0\n",
      "test input:  78.65206909179688  cluster:  0\n",
      "output cluster  1\n",
      "test input:  79.48107145567579  cluster:  0\n",
      "test input:  81.59126968342255  cluster:  1\n",
      "test input:  79.15134691830667  cluster:  0\n",
      "test input:  81.22386932373047  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.22387189787159  cluster:  1\n",
      "test input:  81.40286440242468  cluster:  1\n",
      "test input:  79.56585535844665  cluster:  0\n",
      "test input:  80.5738525390625  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.62095488592918  cluster:  1\n",
      "test input:  81.68547294668922  cluster:  1\n",
      "test input:  80.16876596145553  cluster:  1\n",
      "test input:  81.62895202636719  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.46080814395444  cluster:  1\n",
      "test input:  81.3934392733806  cluster:  1\n",
      "test input:  80.20644962582965  cluster:  1\n",
      "test input:  81.22386932373047  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.48764729301898  cluster:  1\n",
      "test input:  81.9021532323644  cluster:  1\n",
      "test input:  81.02604297975672  cluster:  1\n",
      "test input:  81.30865478515625  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.92240416133274  cluster:  1\n",
      "test input:  81.19560056269007  cluster:  1\n",
      "test input:  79.59410516031583  cluster:  0\n",
      "test input:  80.2629623413086  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.50791046980919  cluster:  1\n",
      "test input:  81.63837925210164  cluster:  1\n",
      "test input:  80.03688360734556  cluster:  1\n",
      "test input:  80.34776306152344  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.14849015053034  cluster:  1\n",
      "test input:  81.40284862742429  cluster:  1\n",
      "test input:  80.10281016173965  cluster:  1\n",
      "test input:  80.96949768066406  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.38543661912419  cluster:  1\n",
      "test input:  81.22386376072079  cluster:  1\n",
      "test input:  80.22528922967287  cluster:  1\n",
      "test input:  80.78109741210938  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.60211095596507  cluster:  1\n",
      "test input:  81.98693102232114  cluster:  1\n",
      "test input:  80.60211095596507  cluster:  1\n",
      "test input:  81.60069274902344  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.78908777834337  cluster:  1\n",
      "test input:  81.8927142423763  cluster:  1\n",
      "test input:  80.7245698691755  cluster:  1\n",
      "test input:  80.9506607055664  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.4876446051052  cluster:  1\n",
      "test input:  81.93983354104812  cluster:  1\n",
      "test input:  80.8376252557183  cluster:  1\n",
      "test input:  80.9977798461914  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.46880189339187  cluster:  1\n",
      "test input:  81.80793459124287  cluster:  1\n",
      "test input:  80.79993748463042  cluster:  1\n",
      "test input:  80.92240905761719  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.34633196377945  cluster:  1\n",
      "test input:  81.34633196377945  cluster:  1\n",
      "test input:  80.63979171999335  cluster:  1\n",
      "test input:  80.68689727783203  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.96008420842482  cluster:  1\n",
      "test input:  82.17533414772107  cluster:  1\n",
      "test input:  80.76225382583681  cluster:  1\n",
      "test input:  81.90213775634766  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.9586711448124  cluster:  1\n",
      "test input:  82.58043003098705  cluster:  1\n",
      "test input:  81.72315772198247  cluster:  1\n",
      "test input:  82.35433197021484  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.35431874297296  cluster:  1\n",
      "test input:  82.5144661198236  cluster:  1\n",
      "test input:  81.38400474672741  cluster:  1\n",
      "test input:  81.91155242919922  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.26011801102482  cluster:  1\n",
      "test input:  82.5804199644243  cluster:  1\n",
      "test input:  80.8752981036267  cluster:  1\n",
      "test input:  81.25212097167969  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.31806101029076  cluster:  1\n",
      "test input:  82.87245078349345  cluster:  1\n",
      "test input:  80.89413979364372  cluster:  1\n",
      "test input:  82.702880859375  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.23045323324193  cluster:  1\n",
      "test input:  83.54133271757522  cluster:  1\n",
      "test input:  82.35434289658464  cluster:  1\n",
      "test input:  83.05146789550781  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.20219939746897  cluster:  1\n",
      "test input:  83.79569076159781  cluster:  1\n",
      "test input:  82.66522896688551  cluster:  1\n",
      "test input:  83.65438842773438  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.74856412327608  cluster:  1\n",
      "test input:  84.55873077148607  cluster:  1\n",
      "test input:  83.2021713256836  cluster:  1\n",
      "test input:  83.2021713256836  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.91016473942857  cluster:  1\n",
      "test input:  83.89931700997428  cluster:  1\n",
      "test input:  82.86305917008319  cluster:  1\n",
      "test input:  83.85221862792969  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.3811639350752  cluster:  1\n",
      "test input:  84.12538712179548  cluster:  1\n",
      "test input:  82.4296878118887  cluster:  1\n",
      "test input:  82.81593322753906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.57101436041746  cluster:  1\n",
      "test input:  83.07030170844341  cluster:  1\n",
      "test input:  80.03688741971989  cluster:  1\n",
      "test input:  81.02604675292969  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.79993171631092  cluster:  1\n",
      "test input:  83.02317872144268  cluster:  1\n",
      "test input:  80.62094642497546  cluster:  1\n",
      "test input:  82.61809539794922  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.6369435063061  cluster:  1\n",
      "test input:  83.82393306285582  cluster:  1\n",
      "test input:  82.52389448610658  cluster:  1\n",
      "test input:  83.52247619628906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.57900042139347  cluster:  1\n",
      "test input:  83.94640076746295  cluster:  1\n",
      "test input:  83.12681150999317  cluster:  1\n",
      "test input:  83.23986053466797  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.38117427670997  cluster:  1\n",
      "test input:  85.09571170835669  cluster:  1\n",
      "test input:  82.9384078915799  cluster:  1\n",
      "test input:  84.86961364746094  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.88844115363587  cluster:  1\n",
      "test input:  85.68918518828654  cluster:  1\n",
      "test input:  84.58698432221568  cluster:  1\n",
      "test input:  85.13337707519531  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.13338593905063  cluster:  1\n",
      "test input:  85.62325064587512  cluster:  1\n",
      "test input:  84.93555554664275  cluster:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  85.29353332519531  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.53848983604033  cluster:  1\n",
      "test input:  85.92472816531885  cluster:  1\n",
      "test input:  84.82252691951639  cluster:  1\n",
      "test input:  85.16166687011719  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.84135078234827  cluster:  1\n",
      "test input:  85.69862306752697  cluster:  1\n",
      "test input:  84.54931644609135  cluster:  1\n",
      "test input:  84.73772430419922  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.73771364318529  cluster:  1\n",
      "test input:  85.4536763510569  cluster:  1\n",
      "test input:  84.20074340910612  cluster:  1\n",
      "test input:  85.01091003417969  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.75657704871308  cluster:  1\n",
      "test input:  85.45369481136164  cluster:  1\n",
      "test input:  84.49280314864605  cluster:  1\n",
      "test input:  85.32180786132812  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.16165611905102  cluster:  1\n",
      "test input:  85.3594865340434  cluster:  1\n",
      "test input:  84.80367111233203  cluster:  1\n",
      "test input:  84.85077667236328  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.08627840063362  cluster:  1\n",
      "test input:  86.06601497873886  cluster:  1\n",
      "test input:  85.08627840063362  cluster:  1\n",
      "test input:  85.9247055053711  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.93412477883814  cluster:  1\n",
      "test input:  86.61240447531742  cluster:  1\n",
      "test input:  85.25584508235886  cluster:  1\n",
      "test input:  86.20732116699219  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.78340893862983  cluster:  1\n",
      "test input:  86.60299825763629  cluster:  1\n",
      "test input:  85.49137458708361  cluster:  1\n",
      "test input:  86.56531524658203  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.45226248517906  cluster:  1\n",
      "test input:  87.34721778769924  cluster:  1\n",
      "test input:  85.8022503375982  cluster:  1\n",
      "test input:  87.24359130859375  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.06460002689798  cluster:  1\n",
      "test input:  87.51678895906606  cluster:  1\n",
      "test input:  86.73488267391043  cluster:  1\n",
      "test input:  87.40373992919922  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.88562086039013  cluster:  1\n",
      "test input:  87.49795005041464  cluster:  1\n",
      "test input:  86.30154494570702  cluster:  1\n",
      "test input:  86.85735321044922  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.48852713082346  cluster:  1\n",
      "test input:  88.86392462985674  cluster:  1\n",
      "test input:  87.39431601375749  cluster:  1\n",
      "test input:  88.02549743652344  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.88419308683895  cluster:  1\n",
      "test input:  88.53421245864543  cluster:  1\n",
      "test input:  86.339225548971  cluster:  1\n",
      "test input:  86.53705596923828  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.27185556258209  cluster:  1\n",
      "test input:  87.6298333867721  cluster:  1\n",
      "test input:  86.52763226542699  cluster:  1\n",
      "test input:  86.75372314453125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.13996157361362  cluster:  1\n",
      "test input:  87.99723383467371  cluster:  1\n",
      "test input:  86.97981417999763  cluster:  1\n",
      "test input:  87.71461486816406  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.80882714971604  cluster:  1\n",
      "test input:  88.26101610169819  cluster:  1\n",
      "test input:  87.4414267706741  cluster:  1\n",
      "test input:  87.89361572265625  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.06317333457577  cluster:  1\n",
      "test input:  89.41972562573133  cluster:  1\n",
      "test input:  87.93127921879402  cluster:  1\n",
      "test input:  89.37262725830078  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.25016524698373  cluster:  1\n",
      "test input:  90.16395848309944  cluster:  1\n",
      "test input:  89.22190478603983  cluster:  1\n",
      "test input:  89.71177673339844  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.74003291498114  cluster:  1\n",
      "test input:  89.86249730233128  cluster:  1\n",
      "test input:  87.39431414630562  cluster:  1\n",
      "test input:  89.61756134033203  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.758871762818  cluster:  1\n",
      "test input:  90.05090609809393  cluster:  1\n",
      "test input:  89.52335834732476  cluster:  1\n",
      "test input:  89.59872436523438  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.84364485654619  cluster:  1\n",
      "test input:  90.06031313659699  cluster:  1\n",
      "test input:  89.25014655184656  cluster:  1\n",
      "test input:  89.79653930664062  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.8719131935957  cluster:  1\n",
      "test input:  90.61613638612756  cluster:  1\n",
      "test input:  89.68349816474674  cluster:  1\n",
      "test input:  89.78712463378906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  90.2792743859151  cluster:  1\n",
      "test input:  90.6578449671151  cluster:  1\n",
      "test input:  89.57892350410673  cluster:  1\n",
      "test input:  89.69248962402344  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.50319563341918  cluster:  1\n",
      "test input:  90.00479851574929  cluster:  1\n",
      "test input:  88.97320122501488  cluster:  1\n",
      "test input:  89.83444213867188  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.34229819720791  cluster:  1\n",
      "test input:  89.77765174287636  cluster:  1\n",
      "test input:  89.07730101468204  cluster:  1\n",
      "test input:  89.1624755859375  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.65142203109873  cluster:  1\n",
      "test input:  89.02999259560133  cluster:  1\n",
      "test input:  88.21606840914228  cluster:  1\n",
      "test input:  88.95427703857422  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.25713789831384  cluster:  1\n",
      "test input:  89.59785070664218  cluster:  1\n",
      "test input:  88.79339271722439  cluster:  1\n",
      "test input:  88.8596420288086  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.06785145422863  cluster:  1\n",
      "test input:  89.60731216848109  cluster:  1\n",
      "test input:  88.17821169995395  cluster:  1\n",
      "test input:  89.08677673339844  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.31392417593472  cluster:  1\n",
      "test input:  89.44642279316285  cluster:  1\n",
      "test input:  88.17821245887956  cluster:  1\n",
      "test input:  88.58517456054688  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.14983763882988  cluster:  1\n",
      "test input:  88.61358288703371  cluster:  1\n",
      "test input:  86.21913385243083  cluster:  1\n",
      "test input:  86.94788360595703  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.79643760068919  cluster:  1\n",
      "test input:  87.34536457964438  cluster:  1\n",
      "test input:  86.35161771155768  cluster:  1\n",
      "test input:  86.73965454101562  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.97626103309554  cluster:  1\n",
      "test input:  87.72393594826887  cluster:  1\n",
      "test input:  86.17180305773772  cluster:  1\n",
      "test input:  86.23805236816406  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.20965105128923  cluster:  1\n",
      "test input:  86.92893441495985  cluster:  1\n",
      "test input:  85.80269617123625  cluster:  1\n",
      "test input:  86.64501190185547  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.91946558439079  cluster:  1\n",
      "test input:  87.61035739830194  cluster:  1\n",
      "test input:  86.3516133544083  cluster:  1\n",
      "test input:  86.3800048828125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.39894497639523  cluster:  1\n",
      "test input:  87.5157242557968  cluster:  1\n",
      "test input:  85.93519979022146  cluster:  1\n",
      "test input:  86.75858306884766  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.94160885306576  cluster:  1\n",
      "test input:  87.94160885306576  cluster:  1\n",
      "test input:  85.16858963379454  cluster:  1\n",
      "test input:  85.31055450439453  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.48089782594656  cluster:  1\n",
      "test input:  86.01089222641902  cluster:  1\n",
      "test input:  84.95090342547408  cluster:  1\n",
      "test input:  85.49036407470703  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.51875594409265  cluster:  1\n",
      "test input:  85.85000244571937  cluster:  1\n",
      "test input:  84.89411349476897  cluster:  1\n",
      "test input:  85.28215026855469  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.55661413688517  cluster:  1\n",
      "test input:  86.62606919611706  cluster:  1\n",
      "test input:  85.55661413688517  cluster:  1\n",
      "test input:  86.2948226928711  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.91627940903491  cluster:  1\n",
      "test input:  86.54092205947862  cluster:  1\n",
      "test input:  85.77431451387639  cluster:  1\n",
      "test input:  85.89735412597656  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.47143592131499  cluster:  1\n",
      "test input:  86.66393060361935  cluster:  1\n",
      "test input:  85.47143592131499  cluster:  1\n",
      "test input:  86.4841079711914  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.01410788648272  cluster:  1\n",
      "test input:  88.55677433304903  cluster:  1\n",
      "test input:  86.91000080879573  cluster:  1\n",
      "test input:  88.36749267578125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.23498750285536  cluster:  1\n",
      "test input:  88.50944371927186  cluster:  1\n",
      "test input:  87.70498590482362  cluster:  1\n",
      "test input:  88.12141418457031  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.16875738237806  cluster:  1\n",
      "test input:  89.35178596111993  cluster:  1\n",
      "test input:  88.16875738237806  cluster:  1\n",
      "test input:  88.8596420288086  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.53786596707174  cluster:  1\n",
      "test input:  89.43696484177791  cluster:  1\n",
      "test input:  88.32018552106581  cluster:  1\n",
      "test input:  89.38964080810547  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.4558870764831  cluster:  1\n",
      "test input:  90.52534954773641  cluster:  1\n",
      "test input:  89.34232095255072  cluster:  1\n",
      "test input:  90.46855926513672  cluster:  1\n",
      "output cluster  1\n",
      "test input:  90.0426701312566  cluster:  1\n",
      "test input:  90.74302102438982  cluster:  1\n",
      "test input:  89.815530667117  cluster:  1\n",
      "test input:  89.91017150878906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.65464051421118  cluster:  1\n",
      "test input:  89.98588707038004  cluster:  1\n",
      "test input:  89.24767839645133  cluster:  1\n",
      "test input:  89.91017150878906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.72087067574516  cluster:  1\n",
      "test input:  90.43068766773482  cluster:  1\n",
      "test input:  89.67354665469311  cluster:  1\n",
      "test input:  90.39282989501953  cluster:  1\n",
      "output cluster  1\n",
      "test input:  90.53481551786344  cluster:  1\n",
      "test input:  90.53481551786344  cluster:  1\n",
      "test input:  89.95749698755026  cluster:  1\n",
      "test input:  90.12785339355469  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.96374112234707  cluster:  1\n",
      "test input:  89.23820459441322  cluster:  1\n",
      "test input:  87.36428431709814  cluster:  1\n",
      "test input:  89.0678482055664  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.02998169052165  cluster:  1\n",
      "test input:  89.54105080690552  cluster:  1\n",
      "test input:  88.84070004177151  cluster:  1\n",
      "test input:  89.02051544189453  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.28553856358312  cluster:  1\n",
      "test input:  90.7524970395589  cluster:  1\n",
      "test input:  89.28553856358312  cluster:  1\n",
      "test input:  90.55374908447266  cluster:  1\n",
      "output cluster  1\n",
      "test input:  90.6294476507346  cluster:  1\n",
      "test input:  90.68623070706755  cluster:  1\n",
      "test input:  87.38321721876682  cluster:  1\n",
      "test input:  87.55357360839844  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.08356068009445  cluster:  1\n",
      "test input:  88.52838050580918  cluster:  1\n",
      "test input:  85.71750392257539  cluster:  1\n",
      "test input:  86.50303649902344  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.70179786148937  cluster:  1\n",
      "test input:  87.95107573459687  cluster:  1\n",
      "test input:  86.46519214900208  cluster:  1\n",
      "test input:  86.49358367919922  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.02984675409891  cluster:  1\n",
      "test input:  87.24126696289828  cluster:  1\n",
      "test input:  85.72699170189907  cluster:  1\n",
      "test input:  86.83430480957031  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.8343059373102  cluster:  1\n",
      "test input:  87.0425201422706  cluster:  1\n",
      "test input:  86.0582394046795  cluster:  1\n",
      "test input:  86.5882339477539  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.50305278694658  cluster:  1\n",
      "test input:  87.08037132213687  cluster:  1\n",
      "test input:  86.417870972908  cluster:  1\n",
      "test input:  87.01412200927734  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.38322364552151  cluster:  1\n",
      "test input:  88.55678596005508  cluster:  1\n",
      "test input:  87.2412587736153  cluster:  1\n",
      "test input:  88.34857177734375  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.4621469857297  cluster:  1\n",
      "test input:  88.60411186063166  cluster:  1\n",
      "test input:  87.83750442441445  cluster:  1\n",
      "test input:  87.9794692993164  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.01731836398228  cluster:  1\n",
      "test input:  88.60410308583663  cluster:  1\n",
      "test input:  87.67660558621303  cluster:  1\n",
      "test input:  87.84696197509766  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.26964571665773  cluster:  1\n",
      "test input:  88.57570658415021  cluster:  1\n",
      "test input:  86.73018500827683  cluster:  1\n",
      "test input:  87.1844711303711  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.29803941976697  cluster:  1\n",
      "test input:  88.3485693339323  cluster:  1\n",
      "test input:  86.59768855053446  cluster:  1\n",
      "test input:  87.0708999633789  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.27911083065304  cluster:  1\n",
      "test input:  87.76178847522822  cluster:  1\n",
      "test input:  87.2412530525851  cluster:  1\n",
      "test input:  87.60089111328125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.13715107248316  cluster:  1\n",
      "test input:  88.0741076674941  cluster:  1\n",
      "test input:  86.90054536117299  cluster:  1\n",
      "test input:  87.16554260253906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.00786051643956  cluster:  1\n",
      "test input:  88.20660845234043  cluster:  1\n",
      "test input:  87.26018558387912  cluster:  1\n",
      "test input:  87.72393798828125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.72393685508872  cluster:  1\n",
      "test input:  88.1308989720954  cluster:  1\n",
      "test input:  87.2791169573566  cluster:  1\n",
      "test input:  88.05518341064453  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.92268261930886  cluster:  1\n",
      "test input:  88.3580362559608  cluster:  1\n",
      "test input:  87.82804178014682  cluster:  1\n",
      "test input:  88.16875457763672  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.19713697778663  cluster:  1\n",
      "test input:  88.35802710977123  cluster:  1\n",
      "test input:  87.46838742834416  cluster:  1\n",
      "test input:  87.57249450683594  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.27910903539929  cluster:  1\n",
      "test input:  88.00785139147722  cluster:  1\n",
      "test input:  86.98572028719856  cluster:  1\n",
      "test input:  87.88481903076172  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.86588723138583  cluster:  1\n",
      "test input:  88.54731278675222  cluster:  1\n",
      "test input:  87.86588723138583  cluster:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  88.31070709228516  cluster:  1\n",
      "output cluster  2\n",
      "test input:  88.34858707363874  cluster:  1\n",
      "test input:  89.87232870660395  cluster:  1\n",
      "test input:  88.24447996425842  cluster:  1\n",
      "test input:  89.65465545654297  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.74928459714026  cluster:  1\n",
      "test input:  90.63891720574628  cluster:  1\n",
      "test input:  89.74928459714026  cluster:  1\n",
      "test input:  89.9291000366211  cluster:  1\n",
      "output cluster  1\n",
      "test input:  90.0710558254958  cluster:  1\n",
      "test input:  90.79033917273715  cluster:  1\n",
      "test input:  89.9006994332711  cluster:  1\n",
      "test input:  90.00480651855469  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.966959308917  cluster:  1\n",
      "test input:  90.27928060145717  cluster:  1\n",
      "test input:  89.46535632306181  cluster:  1\n",
      "test input:  89.7682113647461  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.63571388911205  cluster:  1\n",
      "test input:  89.7303547369878  cluster:  1\n",
      "test input:  89.23821799565359  cluster:  1\n",
      "test input:  89.43696594238281  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.36123622261348  cluster:  1\n",
      "test input:  90.44015760290975  cluster:  1\n",
      "test input:  88.95427414263277  cluster:  1\n",
      "test input:  90.32659149169922  cluster:  1\n",
      "output cluster  1\n",
      "test input:  90.39283465735275  cluster:  1\n",
      "test input:  91.57586303966319  cluster:  2\n",
      "test input:  90.35497688264296  cluster:  1\n",
      "test input:  91.55693054199219  cluster:  2\n",
      "output cluster  1\n",
      "test input:  91.40552734898739  cluster:  2\n",
      "test input:  91.65159210933757  cluster:  2\n",
      "test input:  89.20036021237652  cluster:  1\n",
      "test input:  89.43696594238281  cluster:  1\n",
      "output cluster  1\n",
      "test input:  89.36124361732229  cluster:  1\n",
      "test input:  89.89124532248272  cluster:  1\n",
      "test input:  87.98893337532887  cluster:  1\n",
      "test input:  88.0930404663086  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.08356331816891  cluster:  1\n",
      "test input:  88.67980703949344  cluster:  1\n",
      "test input:  87.82803235778195  cluster:  1\n",
      "test input:  88.1592788696289  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.35803913059797  cluster:  1\n",
      "test input:  89.0583900279421  cluster:  1\n",
      "test input:  88.19714897672479  cluster:  1\n",
      "test input:  88.3958969116211  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.1498180541669  cluster:  1\n",
      "test input:  89.1151733432061  cluster:  1\n",
      "test input:  87.82803777157574  cluster:  1\n",
      "test input:  88.73660278320312  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.79338289844607  cluster:  1\n",
      "test input:  89.09623789228893  cluster:  1\n",
      "test input:  86.44625128068948  cluster:  1\n",
      "test input:  86.61660766601562  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.26329089786933  cluster:  1\n",
      "test input:  87.45348696878085  cluster:  1\n",
      "test input:  86.44543473302272  cluster:  1\n",
      "test input:  87.348876953125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.04456693913428  cluster:  1\n",
      "test input:  87.42496637166435  cluster:  1\n",
      "test input:  86.21720597306077  cluster:  1\n",
      "test input:  86.28377532958984  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.3027816341851  cluster:  1\n",
      "test input:  86.3027816341851  cluster:  1\n",
      "test input:  84.62902868609918  cluster:  1\n",
      "test input:  84.7526626586914  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.76217090936518  cluster:  1\n",
      "test input:  85.71316578787243  cluster:  1\n",
      "test input:  84.76217090936518  cluster:  1\n",
      "test input:  85.67512512207031  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.28523808615756  cluster:  1\n",
      "test input:  85.87485764097896  cluster:  1\n",
      "test input:  84.57199178434051  cluster:  1\n",
      "test input:  85.56102752685547  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.91288493314607  cluster:  1\n",
      "test input:  86.35985374463107  cluster:  1\n",
      "test input:  84.95238520582306  cluster:  1\n",
      "test input:  85.4468994140625  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.70365889745196  cluster:  1\n",
      "test input:  86.31229502387603  cluster:  1\n",
      "test input:  85.27570685962834  cluster:  1\n",
      "test input:  86.11258697509766  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.87485100604427  cluster:  1\n",
      "test input:  85.91288442101468  cluster:  1\n",
      "test input:  85.3422888747502  cluster:  1\n",
      "test input:  85.48493957519531  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.59906761257722  cluster:  1\n",
      "test input:  85.66563697673577  cluster:  1\n",
      "test input:  83.34520670232389  cluster:  1\n",
      "test input:  83.38324737548828  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.25961439446165  cluster:  1\n",
      "test input:  83.77314530493388  cluster:  1\n",
      "test input:  81.63340657440762  cluster:  1\n",
      "test input:  81.70948791503906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.985279463044  cluster:  1\n",
      "test input:  82.52734633197208  cluster:  1\n",
      "test input:  81.85214074123823  cluster:  1\n",
      "test input:  82.21351623535156  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.99478355864281  cluster:  1\n",
      "test input:  82.33714231193483  cluster:  1\n",
      "test input:  81.52879807714027  cluster:  1\n",
      "test input:  81.59536743164062  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.17546591039525  cluster:  1\n",
      "test input:  83.07890808753622  cluster:  1\n",
      "test input:  81.67143256096941  cluster:  1\n",
      "test input:  82.86017608642578  cluster:  1\n",
      "output cluster  0\n",
      "test input:  82.79362162473109  cluster:  1\n",
      "test input:  82.8601909839046  cluster:  1\n",
      "test input:  81.2530143822824  cluster:  1\n",
      "test input:  81.70948791503906  cluster:  1\n",
      "output cluster  0\n",
      "test input:  82.19449982161251  cluster:  1\n",
      "test input:  82.24205247479168  cluster:  1\n",
      "test input:  81.12938278783842  cluster:  1\n",
      "test input:  81.55733489990234  cluster:  1\n",
      "output cluster  0\n",
      "test input:  81.47174630199369  cluster:  1\n",
      "test input:  82.64147343621254  cluster:  1\n",
      "test input:  81.21498082427163  cluster:  1\n",
      "test input:  81.62390899658203  cluster:  1\n",
      "output cluster  0\n",
      "test input:  81.8140823046772  cluster:  1\n",
      "test input:  82.22301036300415  cluster:  1\n",
      "test input:  81.00573816766288  cluster:  1\n",
      "test input:  81.33858489990234  cluster:  1\n",
      "output cluster  0\n",
      "test input:  81.24348940697135  cluster:  1\n",
      "test input:  81.35761139966615  cluster:  1\n",
      "test input:  80.00719321374615  cluster:  1\n",
      "test input:  80.77750396728516  cluster:  1\n",
      "output cluster  0\n",
      "test input:  80.54927218332506  cluster:  1\n",
      "test input:  80.82506159914405  cluster:  0\n",
      "test input:  79.32249503972174  cluster:  0\n",
      "test input:  80.3115234375  cluster:  1\n",
      "output cluster  0\n",
      "test input:  80.11180381456191  cluster:  0\n",
      "test input:  80.51122716416829  cluster:  0\n",
      "test input:  77.8484386925286  cluster:  0\n",
      "test input:  77.95304870605469  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.59166734801808  cluster:  0\n",
      "test input:  78.257368105071  cluster:  0\n",
      "test input:  75.10006545182047  cluster:  0\n",
      "test input:  75.74674224853516  cluster:  0\n",
      "output cluster  0\n",
      "test input:  78.81845596231682  cluster:  0\n",
      "test input:  78.81845596231682  cluster:  0\n",
      "test input:  75.21418436293143  cluster:  0\n",
      "test input:  76.0986099243164  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.99401328004487  cluster:  0\n",
      "test input:  76.72627623132946  cluster:  0\n",
      "test input:  75.87989126903912  cluster:  0\n",
      "test input:  76.089111328125  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.75479366414768  cluster:  0\n",
      "test input:  78.23834331208063  cluster:  0\n",
      "test input:  76.45047560160978  cluster:  0\n",
      "test input:  77.91500854492188  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.1827596537949  cluster:  0\n",
      "test input:  77.37295575644585  cluster:  0\n",
      "test input:  75.42341305445063  cluster:  0\n",
      "test input:  76.67872619628906  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.67871451046186  cluster:  0\n",
      "test input:  77.52509937264719  cluster:  0\n",
      "test input:  75.88939427478815  cluster:  0\n",
      "test input:  76.04154968261719  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.22224591837441  cluster:  0\n",
      "test input:  77.22078625240923  cluster:  0\n",
      "test input:  75.89890386579486  cluster:  0\n",
      "test input:  76.76431274414062  cluster:  0\n",
      "output cluster  1\n",
      "test input:  77.09715747079277  cluster:  0\n",
      "test input:  77.70579363596704  cluster:  0\n",
      "test input:  76.87842544791042  cluster:  0\n",
      "test input:  77.04010009765625  cluster:  0\n",
      "output cluster  1\n",
      "test input:  75.57558072528116  cluster:  0\n",
      "test input:  77.83894642037036  cluster:  0\n",
      "test input:  75.57558072528116  cluster:  0\n",
      "test input:  77.64875030517578  cluster:  0\n",
      "output cluster  1\n",
      "test input:  77.23030458693462  cluster:  0\n",
      "test input:  78.79944781866874  cluster:  0\n",
      "test input:  76.07008950340374  cluster:  0\n",
      "test input:  77.49658203125  cluster:  0\n",
      "output cluster  1\n",
      "test input:  77.7438328449693  cluster:  0\n",
      "test input:  79.91210004967132  cluster:  0\n",
      "test input:  77.10666800517824  cluster:  0\n",
      "test input:  79.49365997314453  cluster:  0\n",
      "output cluster  1\n",
      "test input:  78.93258542550889  cluster:  0\n",
      "test input:  80.02623113250772  cluster:  0\n",
      "test input:  78.10521715906295  cluster:  0\n",
      "test input:  79.41759490966797  cluster:  0\n",
      "output cluster  1\n",
      "test input:  80.2354375074269  cluster:  1\n",
      "test input:  80.90113099525068  cluster:  1\n",
      "test input:  79.02766999385605  cluster:  0\n",
      "test input:  79.95964813232422  cluster:  0\n",
      "output cluster  1\n",
      "test input:  80.33055511464762  cluster:  1\n",
      "test input:  81.72851903523235  cluster:  1\n",
      "test input:  79.57926813503009  cluster:  0\n",
      "test input:  81.62390899658203  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.20401181983794  cluster:  1\n",
      "test input:  82.86019344964166  cluster:  1\n",
      "test input:  81.90919842999712  cluster:  1\n",
      "test input:  82.46077728271484  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.32762890612177  cluster:  1\n",
      "test input:  83.19303775516248  cluster:  1\n",
      "test input:  81.72850472598883  cluster:  1\n",
      "test input:  82.73655700683594  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.11695642118883  cluster:  1\n",
      "test input:  83.56392518888983  cluster:  1\n",
      "test input:  81.9187008054076  cluster:  1\n",
      "test input:  82.73655700683594  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.86967951705972  cluster:  1\n",
      "test input:  84.47686291943901  cluster:  1\n",
      "test input:  82.81262215548875  cluster:  1\n",
      "test input:  84.41029357910156  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.14402169436778  cluster:  1\n",
      "test input:  85.33276517456022  cluster:  1\n",
      "test input:  84.13450971498222  cluster:  1\n",
      "test input:  85.21864318847656  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.74169855149115  cluster:  1\n",
      "test input:  86.50249007279487  cluster:  1\n",
      "test input:  85.29472981427385  cluster:  1\n",
      "test input:  86.31229400634766  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.59904352095161  cluster:  1\n",
      "test input:  86.96847109186508  cluster:  1\n",
      "test input:  85.59904352095161  cluster:  1\n",
      "test input:  86.86386108398438  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.48347830086136  cluster:  1\n",
      "test input:  86.8353417694084  cluster:  1\n",
      "test input:  85.20914136533685  cluster:  1\n",
      "test input:  85.96994018554688  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.9509257673732  cluster:  1\n",
      "test input:  86.11260043209087  cluster:  1\n",
      "test input:  83.991878382771  cluster:  1\n",
      "test input:  84.2581558227539  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.36275958365243  cluster:  1\n",
      "test input:  84.9713957599552  cluster:  1\n",
      "test input:  83.81118078152944  cluster:  1\n",
      "test input:  84.30570220947266  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.77170333900133  cluster:  1\n",
      "test input:  85.32328224291543  cluster:  1\n",
      "test input:  81.44322046130277  cluster:  1\n",
      "test input:  81.68096923828125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.69998394834913  cluster:  1\n",
      "test input:  83.86825138788326  cluster:  1\n",
      "test input:  81.04379507645788  cluster:  1\n",
      "test input:  83.76364135742188  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.42126202969615  cluster:  1\n",
      "test input:  84.6385341692252  cluster:  1\n",
      "test input:  82.92674068831606  cluster:  1\n",
      "test input:  84.39127349853516  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.3247102633863  cluster:  1\n",
      "test input:  84.9428583571312  cluster:  1\n",
      "test input:  84.09647353457032  cluster:  1\n",
      "test input:  84.6290283203125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.9253004570394  cluster:  1\n",
      "test input:  83.9253004570394  cluster:  1\n",
      "test input:  82.09939197878782  cluster:  1\n",
      "test input:  83.1454849243164  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.77312291305549  cluster:  1\n",
      "test input:  83.77312291305549  cluster:  1\n",
      "test input:  82.72703015329131  cluster:  1\n",
      "test input:  82.98380279541016  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.73655664395564  cluster:  1\n",
      "test input:  83.83020223460524  cluster:  1\n",
      "test input:  82.08987981904663  cluster:  1\n",
      "test input:  83.55441284179688  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.25815018112918  cluster:  1\n",
      "test input:  85.25669776972191  cluster:  1\n",
      "test input:  84.18206884465218  cluster:  1\n",
      "test input:  85.04747772216797  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.78118272120344  cluster:  1\n",
      "test input:  85.47540481994588  cluster:  1\n",
      "test input:  84.4958813963278  cluster:  1\n",
      "test input:  85.07598876953125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.48494669206923  cluster:  1\n",
      "test input:  85.78926482578007  cluster:  1\n",
      "test input:  84.31522681317179  cluster:  1\n",
      "test input:  85.52298736572266  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.39935799511231  cluster:  1\n",
      "test input:  86.9019246529331  cluster:  1\n",
      "test input:  84.74316909189822  cluster:  1\n",
      "test input:  85.96044158935547  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.9033733179859  cluster:  1\n",
      "test input:  87.13015764191792  cluster:  1\n",
      "test input:  85.6275839190695  cluster:  1\n",
      "test input:  86.84485626220703  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.84341036725489  cluster:  1\n",
      "test input:  88.57567332153735  cluster:  1\n",
      "test input:  87.45349893635928  cluster:  1\n",
      "test input:  88.10968780517578  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.05261407733225  cluster:  1\n",
      "test input:  88.40448480139456  cluster:  1\n",
      "test input:  85.6846388140893  cluster:  1\n",
      "test input:  85.96994018554688  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.2186621373063  cluster:  1\n",
      "test input:  85.77024097608557  cluster:  1\n",
      "test input:  84.39129387913736  cluster:  1\n",
      "test input:  85.48493957519531  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.54198401097212  cluster:  1\n",
      "test input:  85.69414666989618  cluster:  1\n",
      "test input:  82.89821948404311  cluster:  1\n",
      "test input:  83.07891082763672  cluster:  1\n",
      "output cluster  0\n",
      "test input:  83.0789181243788  cluster:  1\n",
      "test input:  83.0789181243788  cluster:  1\n",
      "test input:  80.93917952005349  cluster:  1\n",
      "test input:  82.83165740966797  cluster:  1\n",
      "output cluster  0\n",
      "test input:  83.93480625905548  cluster:  1\n",
      "test input:  85.2281598164898  cluster:  1\n",
      "test input:  82.96478746322232  cluster:  1\n",
      "test input:  83.03135681152344  cluster:  1\n",
      "output cluster  0\n",
      "test input:  83.83970960139732  cluster:  1\n",
      "test input:  84.3722643965393  cluster:  1\n",
      "test input:  83.12646346268289  cluster:  1\n",
      "test input:  83.2025375366211  cluster:  1\n",
      "output cluster  0\n",
      "test input:  83.54664333223239  cluster:  1\n",
      "test input:  83.80470662355047  cluster:  1\n",
      "test input:  82.58128142049256  cluster:  1\n",
      "test input:  83.17387390136719  cluster:  1\n",
      "output cluster  0\n",
      "test input:  82.88714015000261  cluster:  1\n",
      "test input:  83.4797326482413  cluster:  1\n",
      "test input:  82.20852169067759  cluster:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  82.71509552001953  cluster:  1\n",
      "output cluster  0\n",
      "test input:  82.48569622255391  cluster:  1\n",
      "test input:  82.686413720541  cluster:  1\n",
      "test input:  81.27182388286546  cluster:  1\n",
      "test input:  81.48210144042969  cluster:  1\n",
      "output cluster  0\n",
      "test input:  81.96001273327211  cluster:  1\n",
      "test input:  82.60039825464851  cluster:  1\n",
      "test input:  79.74255262214697  cluster:  0\n",
      "test input:  80.03884887695312  cluster:  0\n",
      "output cluster  0\n",
      "test input:  80.27779963841826  cluster:  1\n",
      "test input:  81.21448871013962  cluster:  1\n",
      "test input:  78.76763817661579  cluster:  0\n",
      "test input:  79.34111785888672  cluster:  0\n",
      "output cluster  0\n",
      "test input:  79.18817617299928  cluster:  0\n",
      "test input:  79.52270533823082  cluster:  0\n",
      "test input:  76.97071633065022  cluster:  0\n",
      "test input:  77.42950439453125  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.10453013889096  cluster:  0\n",
      "test input:  78.84408913861297  cluster:  0\n",
      "test input:  75.96713094550407  cluster:  0\n",
      "test input:  75.99580383300781  cluster:  0\n",
      "output cluster  0\n",
      "test input:  74.9635198074302  cluster:  0\n",
      "test input:  75.40318766853042  cluster:  0\n",
      "test input:  73.28130694899514  cluster:  0\n",
      "test input:  73.35777282714844  cluster:  0\n",
      "output cluster  0\n",
      "test input:  73.90260010290045  cluster:  0\n",
      "test input:  75.79509100910073  cluster:  0\n",
      "test input:  72.15348093526208  cluster:  0\n",
      "test input:  75.76641082763672  cluster:  0\n",
      "output cluster  0\n",
      "test input:  75.00176101433243  cluster:  0\n",
      "test input:  77.13319473445502  cluster:  0\n",
      "test input:  74.38048844717898  cluster:  0\n",
      "test input:  77.12364196777344  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.54420569603411  cluster:  0\n",
      "test input:  78.23238423233063  cluster:  0\n",
      "test input:  76.08182995249888  cluster:  0\n",
      "test input:  76.9707260131836  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.34347957151363  cluster:  0\n",
      "test input:  78.42354026784542  cluster:  0\n",
      "test input:  76.98983757404342  cluster:  0\n",
      "test input:  77.96475219726562  cluster:  0\n",
      "output cluster  0\n",
      "test input:  77.03762258986589  cluster:  0\n",
      "test input:  78.39485937756426  cluster:  0\n",
      "test input:  77.00894970300013  cluster:  0\n",
      "test input:  77.4199447631836  cluster:  0\n",
      "output cluster  0\n",
      "test input:  78.29928014400109  cluster:  0\n",
      "test input:  78.29928014400109  cluster:  0\n",
      "test input:  75.18337158853171  cluster:  0\n",
      "test input:  75.33629608154297  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.49281193681689  cluster:  0\n",
      "test input:  78.71027167762061  cluster:  0\n",
      "test input:  75.85242652238648  cluster:  0\n",
      "test input:  78.32794952392578  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.43546351132306  cluster:  0\n",
      "test input:  77.3817051574074  cluster:  0\n",
      "test input:  75.54656763403527  cluster:  0\n",
      "test input:  76.28253173828125  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.81779796606145  cluster:  0\n",
      "test input:  77.40083768291842  cluster:  0\n",
      "test input:  75.4127680678058  cluster:  0\n",
      "test input:  76.06271362304688  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.47371116106217  cluster:  0\n",
      "test input:  76.99939782456333  cluster:  0\n",
      "test input:  75.96713732677263  cluster:  0\n",
      "test input:  76.43547821044922  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.30167430845908  cluster:  0\n",
      "test input:  77.11410453829086  cluster:  0\n",
      "test input:  75.6612887278309  cluster:  0\n",
      "test input:  76.98985290527344  cluster:  0\n",
      "output cluster  0\n",
      "test input:  76.46414326245025  cluster:  0\n",
      "test input:  77.22878761195032  cluster:  0\n",
      "test input:  76.0722610279795  cluster:  0\n",
      "test input:  77.1332015991211  cluster:  0\n",
      "output cluster  1\n",
      "test input:  76.51194518377912  cluster:  0\n",
      "test input:  77.31481528133186  cluster:  0\n",
      "test input:  76.51194518377912  cluster:  0\n",
      "test input:  76.9707260131836  cluster:  0\n",
      "output cluster  1\n",
      "test input:  76.80822260402543  cluster:  0\n",
      "test input:  77.67799832974312  cluster:  0\n",
      "test input:  76.80822260402543  cluster:  0\n",
      "test input:  77.45816802978516  cluster:  0\n",
      "output cluster  1\n",
      "test input:  77.80225619469053  cluster:  0\n",
      "test input:  79.49402191589648  cluster:  0\n",
      "test input:  77.42949413252332  cluster:  0\n",
      "test input:  79.29330444335938  cluster:  0\n",
      "output cluster  1\n",
      "test input:  79.28375646346655  cluster:  0\n",
      "test input:  79.61829292751457  cluster:  0\n",
      "test input:  78.50955933828016  cluster:  0\n",
      "test input:  78.79630279541016  cluster:  0\n",
      "output cluster  1\n",
      "test input:  79.23597976173916  cluster:  0\n",
      "test input:  80.10575570750856  cluster:  0\n",
      "test input:  78.79631175840004  cluster:  0\n",
      "test input:  79.46537017822266  cluster:  0\n",
      "output cluster  1\n",
      "test input:  79.34109749569069  cluster:  0\n",
      "test input:  80.13440732800106  cluster:  0\n",
      "test input:  78.73893778549149  cluster:  0\n",
      "test input:  79.71385955810547  cluster:  0\n",
      "output cluster  1\n",
      "test input:  79.84768565330918  cluster:  0\n",
      "test input:  81.08067088752844  cluster:  1\n",
      "test input:  79.7043139205508  cluster:  0\n",
      "test input:  80.98509216308594  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.74615069457528  cluster:  1\n",
      "test input:  81.3196303972595  cluster:  1\n",
      "test input:  80.50720021077434  cluster:  1\n",
      "test input:  81.23360443115234  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.91220932256404  cluster:  1\n",
      "test input:  82.30409155114806  cluster:  1\n",
      "test input:  81.42475566696434  cluster:  1\n",
      "test input:  81.90265655517578  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.34829264851226  cluster:  1\n",
      "test input:  82.27542157114529  cluster:  1\n",
      "test input:  80.96597046599906  cluster:  1\n",
      "test input:  82.26586151123047  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.34233330323465  cluster:  1\n",
      "test input:  82.5526108832857  cluster:  1\n",
      "test input:  81.64459472326435  cluster:  1\n",
      "test input:  82.0173568725586  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.27183248499513  cluster:  1\n",
      "test input:  84.09145239920869  cluster:  1\n",
      "test input:  80.20133904909217  cluster:  1\n",
      "test input:  82.85846710205078  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.56216150402311  cluster:  1\n",
      "test input:  84.26349492918435  cluster:  1\n",
      "test input:  82.29453815171601  cluster:  1\n",
      "test input:  84.14879608154297  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.14878460302518  cluster:  1\n",
      "test input:  84.77005718167159  cluster:  1\n",
      "test input:  83.01137821868123  cluster:  1\n",
      "test input:  83.51795196533203  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.54663125957812  cluster:  1\n",
      "test input:  83.5753041442269  cluster:  1\n",
      "test input:  82.09380857174055  cluster:  1\n",
      "test input:  83.11651611328125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.21209495995853  cluster:  1\n",
      "test input:  83.21209495995853  cluster:  1\n",
      "test input:  82.30408624774147  cluster:  1\n",
      "test input:  82.97314453125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.04005947016678  cluster:  1\n",
      "test input:  83.2694571572705  cluster:  1\n",
      "test input:  82.63862445601906  cluster:  1\n",
      "test input:  83.08785247802734  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.70552839557192  cluster:  1\n",
      "test input:  83.06873774573111  cluster:  1\n",
      "test input:  81.97911698744251  cluster:  1\n",
      "test input:  82.98271179199219  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.73421146902604  cluster:  1\n",
      "test input:  83.24078531747135  cluster:  1\n",
      "test input:  82.02692009339617  cluster:  1\n",
      "test input:  83.21211242675781  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.42237825757277  cluster:  1\n",
      "test input:  83.52751703683097  cluster:  1\n",
      "test input:  82.57171525607566  cluster:  1\n",
      "test input:  82.86801147460938  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.14520286584703  cluster:  1\n",
      "test input:  83.92896010978745  cluster:  1\n",
      "test input:  83.0782970264444  cluster:  1\n",
      "test input:  83.69956970214844  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.94808104501996  cluster:  1\n",
      "test input:  84.41642192538035  cluster:  1\n",
      "test input:  83.80470930428402  cluster:  1\n",
      "test input:  84.10100555419922  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.37459168432636  cluster:  1\n",
      "test input:  85.00901183750577  cluster:  1\n",
      "test input:  82.70552606938182  cluster:  1\n",
      "test input:  83.30768585205078  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.69955988276965  cluster:  1\n",
      "test input:  83.90027737742993  cluster:  1\n",
      "test input:  83.10696016601881  cluster:  1\n",
      "test input:  83.88116455078125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.60397033624675  cluster:  1\n",
      "test input:  84.29214868148127  cluster:  1\n",
      "test input:  83.56573739571284  cluster:  1\n",
      "test input:  83.9384994506836  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.8716182241701  cluster:  1\n",
      "test input:  84.19658737572769  cluster:  1\n",
      "test input:  83.36504437486568  cluster:  1\n",
      "test input:  84.1870346069336  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.26349330330991  cluster:  1\n",
      "test input:  84.34951196823911  cluster:  1\n",
      "test input:  83.77603232547649  cluster:  1\n",
      "test input:  84.1774673461914  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.20612781404253  cluster:  1\n",
      "test input:  85.16192950839532  cluster:  1\n",
      "test input:  84.20612781404253  cluster:  1\n",
      "test input:  85.10458374023438  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.46779686568202  cluster:  1\n",
      "test input:  86.55741035546748  cluster:  1\n",
      "test input:  85.45824409787261  cluster:  1\n",
      "test input:  86.15597534179688  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.1655309698324  cluster:  1\n",
      "test input:  87.20735139822759  cluster:  1\n",
      "test input:  86.02215924598467  cluster:  1\n",
      "test input:  87.07353973388672  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.84415760672834  cluster:  1\n",
      "test input:  87.36029148633224  cluster:  1\n",
      "test input:  86.7103459296669  cluster:  1\n",
      "test input:  86.78681182861328  cluster:  1\n",
      "output cluster  0\n",
      "test input:  86.8537153750254  cluster:  1\n",
      "test input:  87.54188657081323  cluster:  1\n",
      "test input:  86.8537153750254  cluster:  1\n",
      "test input:  87.52277374267578  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.13447951953272  cluster:  1\n",
      "test input:  88.42122296474982  cluster:  1\n",
      "test input:  87.59923286679548  cluster:  1\n",
      "test input:  87.92420196533203  cluster:  1\n",
      "output cluster  0\n",
      "test input:  88.09623582777789  cluster:  1\n",
      "test input:  88.40209206234543  cluster:  1\n",
      "test input:  85.63026583472137  cluster:  1\n",
      "test input:  86.16551971435547  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.1655244696086  cluster:  1\n",
      "test input:  86.30889618264054  cluster:  1\n",
      "test input:  84.49287149934183  cluster:  1\n",
      "test input:  84.81784057617188  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.028136081927  cluster:  1\n",
      "test input:  85.06636903295964  cluster:  1\n",
      "test input:  83.4319486603105  cluster:  1\n",
      "test input:  83.79515075683594  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.79514057087188  cluster:  1\n",
      "test input:  83.79514057087188  cluster:  1\n",
      "test input:  81.92176995113411  cluster:  1\n",
      "test input:  82.17028045654297  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.46299962849037  cluster:  1\n",
      "test input:  81.6923900440371  cluster:  1\n",
      "test input:  78.58603385062207  cluster:  0\n",
      "test input:  79.75211334228516  cluster:  0\n",
      "output cluster  1\n",
      "test input:  80.05796192783151  cluster:  0\n",
      "test input:  80.60276866975224  cluster:  0\n",
      "test input:  80.03884180793864  cluster:  1\n",
      "test input:  80.30646514892578  cluster:  1\n",
      "output cluster  0\n",
      "test input:  80.6218768043868  cluster:  1\n",
      "test input:  80.71745552172005  cluster:  0\n",
      "test input:  80.07707009417975  cluster:  1\n",
      "test input:  80.11530303955078  cluster:  0\n",
      "output cluster  1\n",
      "test input:  80.46896437168019  cluster:  1\n",
      "test input:  82.1702905885616  cluster:  1\n",
      "test input:  80.19178094535155  cluster:  1\n",
      "test input:  81.29095458984375  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.3966337565556  cluster:  1\n",
      "test input:  81.67525861455994  cluster:  1\n",
      "test input:  80.5223274093581  cluster:  1\n",
      "test input:  80.69526672363281  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.70486653993319  cluster:  1\n",
      "test input:  81.28132840633921  cluster:  1\n",
      "test input:  80.13801444816518  cluster:  1\n",
      "test input:  80.27252197265625  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.51272050089024  cluster:  1\n",
      "test input:  81.127614177537  cluster:  1\n",
      "test input:  80.51272050089024  cluster:  1\n",
      "test input:  80.93545532226562  cluster:  1\n",
      "output cluster  1\n",
      "test input:  81.25251839536664  cluster:  1\n",
      "test input:  81.95388544517114  cluster:  1\n",
      "test input:  80.53193912356306  cluster:  1\n",
      "test input:  80.83938598632812  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.8489843888453  cluster:  1\n",
      "test input:  81.15643120835988  cluster:  1\n",
      "test input:  79.93624637489455  cluster:  1\n",
      "test input:  80.08997344970703  cluster:  0\n",
      "output cluster  1\n",
      "test input:  79.82096016496072  cluster:  0\n",
      "test input:  81.33898207682398  cluster:  1\n",
      "test input:  79.82096016496072  cluster:  0\n",
      "test input:  81.0411376953125  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.52232621307367  cluster:  1\n",
      "test input:  81.02193192693875  cluster:  1\n",
      "test input:  80.04194005057093  cluster:  1\n",
      "test input:  80.59918975830078  cluster:  1\n",
      "output cluster  1\n",
      "test input:  80.6568300166595  cluster:  1\n",
      "test input:  81.9923029001577  cluster:  1\n",
      "test input:  80.6568300166595  cluster:  1\n",
      "test input:  81.57917785644531  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.01153676438099  cluster:  1\n",
      "test input:  82.55917676664797  cluster:  1\n",
      "test input:  81.60801409536575  cluster:  1\n",
      "test input:  82.4534912109375  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.42465135453644  cluster:  1\n",
      "test input:  82.83778371096754  cluster:  1\n",
      "test input:  81.8481894765213  cluster:  1\n",
      "test input:  82.72248840332031  cluster:  1\n",
      "output cluster  1\n",
      "test input:  82.83778871519655  cluster:  1\n",
      "test input:  83.3950384073225  cluster:  1\n",
      "test input:  82.48230032605878  cluster:  1\n",
      "test input:  83.33738708496094  cluster:  1\n",
      "output cluster  1\n",
      "test input:  83.83698700179515  cluster:  1\n",
      "test input:  84.38462688073304  cluster:  1\n",
      "test input:  83.49110841192802  cluster:  1\n",
      "test input:  84.0579605102539  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.76893671617549  cluster:  1\n",
      "test input:  85.09559575452762  cluster:  1\n",
      "test input:  84.20207729123864  cluster:  1\n",
      "test input:  84.93226623535156  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.83619363827451  cluster:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  85.59519727450332  cluster:  1\n",
      "test input:  84.64403478787239  cluster:  1\n",
      "test input:  85.51834106445312  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.08519383536456  cluster:  1\n",
      "test input:  86.35420889786369  cluster:  1\n",
      "test input:  85.5087319399935  cluster:  1\n",
      "test input:  85.79696655273438  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.79697409322418  cluster:  1\n",
      "test input:  86.11402339897103  cluster:  1\n",
      "test input:  85.19168281929286  cluster:  1\n",
      "test input:  85.68167877197266  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.92186730404215  cluster:  1\n",
      "test input:  85.96990885121056  cluster:  1\n",
      "test input:  84.72090192594143  cluster:  1\n",
      "test input:  85.11481475830078  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.13403515299765  cluster:  1\n",
      "test input:  85.87382660799113  cluster:  1\n",
      "test input:  84.5383536807158  cluster:  1\n",
      "test input:  85.27815246582031  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.8746288465005  cluster:  1\n",
      "test input:  85.3838443670886  cluster:  1\n",
      "test input:  84.0195420115283  cluster:  1\n",
      "test input:  84.25973510742188  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.4134674722209  cluster:  1\n",
      "test input:  84.4903310269277  cluster:  1\n",
      "test input:  83.65445636224334  cluster:  1\n",
      "test input:  84.06758880615234  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.21168635773427  cluster:  1\n",
      "test input:  84.36540610092773  cluster:  1\n",
      "test input:  83.12600906032979  cluster:  1\n",
      "test input:  83.61600494384766  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.31736504875626  cluster:  1\n",
      "test input:  84.51912631851899  cluster:  1\n",
      "test input:  83.51992241342522  cluster:  1\n",
      "test input:  84.35579681396484  cluster:  1\n",
      "output cluster  1\n",
      "test input:  84.35581129255677  cluster:  1\n",
      "test input:  85.19167850645256  cluster:  1\n",
      "test input:  83.96189112913983  cluster:  1\n",
      "test input:  84.99952697753906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.35501037172008  cluster:  1\n",
      "test input:  86.3253924785082  cluster:  1\n",
      "test input:  84.98991952476243  cluster:  1\n",
      "test input:  86.22931671142578  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.2869662234569  cluster:  1\n",
      "test input:  86.8153939713684  cluster:  1\n",
      "test input:  86.0083413500228  cluster:  1\n",
      "test input:  86.66166687011719  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.73852475758643  cluster:  1\n",
      "test input:  87.00753983710042  cluster:  1\n",
      "test input:  86.27735814416562  cluster:  1\n",
      "test input:  86.45989990234375  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.39264765739628  cluster:  1\n",
      "test input:  86.57519674890777  cluster:  1\n",
      "test input:  85.79697349370414  cluster:  1\n",
      "test input:  86.2101058959961  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.23892528744751  cluster:  1\n",
      "test input:  86.65205767725465  cluster:  1\n",
      "test input:  85.84500511874514  cluster:  1\n",
      "test input:  86.13323974609375  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.36382626329365  cluster:  1\n",
      "test input:  87.70890902411604  cluster:  1\n",
      "test input:  84.51914510393733  cluster:  1\n",
      "test input:  85.68167877197266  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.36462091563854  cluster:  1\n",
      "test input:  86.06598794886287  cluster:  1\n",
      "test input:  84.75933698047244  cluster:  1\n",
      "test input:  85.93148040771484  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.11401823119631  cluster:  1\n",
      "test input:  86.55597260763808  cluster:  1\n",
      "test input:  85.27815102514573  cluster:  1\n",
      "test input:  86.33499908447266  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.46950069135916  cluster:  1\n",
      "test input:  88.00673479318345  cluster:  1\n",
      "test input:  86.31577361612153  cluster:  1\n",
      "test input:  87.86261749267578  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.853032047813  cluster:  1\n",
      "test input:  88.69850913489047  cluster:  1\n",
      "test input:  87.75694894214199  cluster:  1\n",
      "test input:  88.58321380615234  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.57360382232672  cluster:  1\n",
      "test input:  89.6592739209708  cluster:  1\n",
      "test input:  88.03556633077933  cluster:  1\n",
      "test input:  88.69850158691406  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.82340327829563  cluster:  1\n",
      "test input:  89.3037894665614  cluster:  1\n",
      "test input:  88.37184641861948  cluster:  1\n",
      "test input:  88.64086151123047  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.9771240347626  cluster:  1\n",
      "test input:  89.30378310104574  cluster:  1\n",
      "test input:  88.41987433686793  cluster:  1\n",
      "test input:  88.50634765625  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.12203282135184  cluster:  1\n",
      "test input:  89.27495660080172  cluster:  1\n",
      "test input:  87.47831716666084  cluster:  1\n",
      "test input:  89.09241485595703  cluster:  1\n",
      "output cluster  1\n",
      "test input:  88.47751970734527  cluster:  1\n",
      "test input:  88.86183010257065  cluster:  1\n",
      "test input:  86.90185368402118  cluster:  1\n",
      "test input:  87.3342056274414  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.24771501979464  cluster:  1\n",
      "test input:  87.97790389303502  cluster:  1\n",
      "test input:  87.01713176039071  cluster:  1\n",
      "test input:  87.420654296875  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.61361763317376  cluster:  1\n",
      "test input:  87.79536336619988  cluster:  1\n",
      "test input:  86.06597775760085  cluster:  1\n",
      "test input:  87.58399963378906  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.31497902908883  cluster:  1\n",
      "test input:  88.96750846410762  cluster:  1\n",
      "test input:  86.85381245612714  cluster:  1\n",
      "test input:  88.88104248046875  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.73772824387805  cluster:  1\n",
      "test input:  87.73772824387805  cluster:  1\n",
      "test input:  86.67127037893039  cluster:  1\n",
      "test input:  87.3342056274414  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.57439282158404  cluster:  1\n",
      "test input:  88.57359684996072  cluster:  1\n",
      "test input:  87.50713905669862  cluster:  1\n",
      "test input:  87.5936050415039  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.12283585563061  cluster:  1\n",
      "test input:  87.92988110065801  cluster:  1\n",
      "test input:  86.7193132331169  cluster:  1\n",
      "test input:  87.19969940185547  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.30537786065065  cluster:  1\n",
      "test input:  87.63203691043147  cluster:  1\n",
      "test input:  86.61362066098467  cluster:  1\n",
      "test input:  87.36302185058594  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.13242913090919  cluster:  1\n",
      "test input:  87.48791013718605  cluster:  1\n",
      "test input:  86.63282350517059  cluster:  1\n",
      "test input:  86.75772857666016  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.46950410373678  cluster:  1\n",
      "test input:  86.90184869221119  cluster:  1\n",
      "test input:  86.27735258221719  cluster:  1\n",
      "test input:  86.71930694580078  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.31498465497499  cluster:  1\n",
      "test input:  87.92027589988933  cluster:  1\n",
      "test input:  87.29577243407641  cluster:  1\n",
      "test input:  87.69929504394531  cluster:  1\n",
      "output cluster  1\n",
      "test input:  87.24773617299532  cluster:  1\n",
      "test input:  87.47832681841557  cluster:  1\n",
      "test input:  86.53676667489478  cluster:  1\n",
      "test input:  86.81539154052734  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.96031094302838  cluster:  1\n",
      "test input:  86.93069315493119  cluster:  1\n",
      "test input:  85.68168605723007  cluster:  1\n",
      "test input:  86.48873138427734  cluster:  1\n",
      "output cluster  1\n",
      "test input:  86.87303743635385  cluster:  1\n",
      "test input:  87.34382118346392  cluster:  1\n",
      "test input:  86.28696569412426  cluster:  1\n",
      "test input:  86.49833679199219  cluster:  1\n",
      "output cluster  2\n",
      "test input:  86.57520427012514  cluster:  1\n",
      "test input:  87.67048425412388  cluster:  1\n",
      "test input:  86.43108693957542  cluster:  1\n",
      "test input:  86.4406967163086  cluster:  1\n",
      "output cluster  2\n",
      "test input:  86.48871862562855  cluster:  1\n",
      "test input:  86.8922485597362  cluster:  1\n",
      "test input:  86.10441557236166  cluster:  1\n",
      "test input:  86.7961654663086  cluster:  1\n",
      "output cluster  2\n",
      "test input:  87.04596022776917  cluster:  1\n",
      "test input:  87.91065667750436  cluster:  1\n",
      "test input:  86.74812319012545  cluster:  1\n",
      "test input:  87.09400177001953  cluster:  1\n",
      "output cluster  2\n",
      "test input:  86.78655930972624  cluster:  1\n",
      "test input:  87.4206651845885  cluster:  1\n",
      "test input:  86.21009742436675  cluster:  1\n",
      "test input:  87.08439636230469  cluster:  1\n",
      "output cluster  2\n",
      "test input:  87.04597156186843  cluster:  1\n",
      "test input:  87.89145590285858  cluster:  1\n",
      "test input:  86.63283916709672  cluster:  1\n",
      "test input:  87.15165710449219  cluster:  1\n",
      "output cluster  2\n",
      "test input:  87.91066358376408  cluster:  1\n",
      "test input:  89.29417801202925  cluster:  1\n",
      "test input:  87.44948966430542  cluster:  1\n",
      "test input:  89.1212387084961  cluster:  1\n",
      "output cluster  2\n",
      "test input:  89.3902571195466  cluster:  1\n",
      "test input:  92.54158914177377  cluster:  2\n",
      "test input:  89.33261312624839  cluster:  1\n",
      "test input:  92.4070816040039  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.47433473334196  cluster:  2\n",
      "test input:  92.55119827728203  cluster:  2\n",
      "test input:  91.60002841377344  cluster:  2\n",
      "test input:  92.12845611572266  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.28217762517849  cluster:  2\n",
      "test input:  93.15647656178496  cluster:  2\n",
      "test input:  91.79218172481939  cluster:  2\n",
      "test input:  92.38786315917969  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.81059962799534  cluster:  2\n",
      "test input:  93.30059553713387  cluster:  2\n",
      "test input:  92.47433080019857  cluster:  2\n",
      "test input:  92.87785339355469  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.43512085494068  cluster:  2\n",
      "test input:  93.64649196696773  cluster:  2\n",
      "test input:  91.39828062008516  cluster:  2\n",
      "test input:  91.52318572998047  cluster:  2\n",
      "output cluster  2\n",
      "test input:  91.23493499910035  cluster:  2\n",
      "test input:  91.95551421044235  cluster:  2\n",
      "test input:  91.0427834747868  cluster:  2\n",
      "test input:  91.7057113647461  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.01468343928545  cluster:  2\n",
      "test input:  92.22709309316488  cluster:  2\n",
      "test input:  91.03949955825478  cluster:  2\n",
      "test input:  92.14985656738281  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.32364387313966  cluster:  2\n",
      "test input:  92.68088395317343  cluster:  2\n",
      "test input:  91.72501480880558  cluster:  2\n",
      "test input:  92.41053771972656  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.62297008844122  cluster:  2\n",
      "test input:  92.89331636673906  cluster:  2\n",
      "test input:  91.79261659573581  cluster:  2\n",
      "test input:  91.88916778564453  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.14019697886378  cluster:  2\n",
      "test input:  93.00917232844536  cluster:  2\n",
      "test input:  91.97605923682694  cluster:  2\n",
      "test input:  92.60365295410156  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.5843466152487  cluster:  2\n",
      "test input:  93.60780247092531  cluster:  2\n",
      "test input:  92.14986258461937  cluster:  2\n",
      "test input:  93.18297576904297  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.64642237561127  cluster:  2\n",
      "test input:  94.51539778428723  cluster:  2\n",
      "test input:  93.20228102592873  cluster:  2\n",
      "test input:  94.37056732177734  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.32230441854551  cluster:  2\n",
      "test input:  95.32645305707968  cluster:  2\n",
      "test input:  94.11954469822382  cluster:  2\n",
      "test input:  94.90161895751953  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.8050658910299  cluster:  2\n",
      "test input:  95.1719633729828  cluster:  2\n",
      "test input:  92.98022107776542  cluster:  2\n",
      "test input:  93.53057098388672  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.73332223301986  cluster:  2\n",
      "test input:  94.77609270822722  cluster:  2\n",
      "test input:  93.289180889813  cluster:  2\n",
      "test input:  94.6216049194336  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.6216150962823  cluster:  2\n",
      "test input:  94.69885899898694  cluster:  2\n",
      "test input:  91.1939924192001  cluster:  2\n",
      "test input:  91.34848022460938  cluster:  2\n",
      "output cluster  2\n",
      "test input:  91.87951399797983  cluster:  2\n",
      "test input:  93.19262338556123  cluster:  2\n",
      "test input:  91.87951399797983  cluster:  2\n",
      "test input:  92.85469055175781  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.77744665649323  cluster:  2\n",
      "test input:  93.44366236197948  cluster:  2\n",
      "test input:  92.69055279910805  cluster:  2\n",
      "test input:  92.85469055175781  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.69470243407204  cluster:  2\n",
      "test input:  94.0905645107615  cluster:  2\n",
      "test input:  93.09607328834606  cluster:  2\n",
      "test input:  93.80091094970703  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.0712604821091  cluster:  2\n",
      "test input:  96.44645512376285  cluster:  2\n",
      "test input:  93.66574106274022  cluster:  2\n",
      "test input:  96.2243881225586  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.8092152733857  cluster:  2\n",
      "test input:  98.12647340201818  cluster:  2\n",
      "test input:  95.7899006146962  cluster:  2\n",
      "test input:  97.92371368408203  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.78851898766867  cluster:  2\n",
      "test input:  97.92369210316932  cluster:  2\n",
      "test input:  96.65885479396378  cluster:  2\n",
      "test input:  97.56645202636719  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.43129480185638  cluster:  2\n",
      "test input:  97.80784959450722  cluster:  2\n",
      "test input:  96.91955950527473  cluster:  2\n",
      "test input:  97.36370086669922  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.08369149486266  cluster:  2\n",
      "test input:  98.16507644894182  cluster:  2\n",
      "test input:  96.9098964320453  cluster:  2\n",
      "test input:  98.10714721679688  cluster:  2\n",
      "output cluster  2\n",
      "test input:  98.64784789507348  cluster:  2\n",
      "test input:  100.02855118491426  cluster:  2\n",
      "test input:  98.64784789507348  cluster:  2\n",
      "test input:  99.46854400634766  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.48785368367346  cluster:  2\n",
      "test input:  100.53062409508053  cluster:  2\n",
      "test input:  99.06301965686701  cluster:  2\n",
      "test input:  100.4244155883789  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.63684771539963  cluster:  2\n",
      "test input:  101.01340252611708  cluster:  2\n",
      "test input:  100.17339167415608  cluster:  2\n",
      "test input:  100.68511962890625  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.7623551396127  cluster:  2\n",
      "test input:  100.85890632496991  cluster:  2\n",
      "test input:  100.02855287140801  cluster:  2\n",
      "test input:  100.62718200683594  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.84925512456512  cluster:  2\n",
      "test input:  101.08098682316339  cluster:  2\n",
      "test input:  99.71959071783748  cluster:  2\n",
      "test input:  99.729248046875  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.69061054482826  cluster:  2\n",
      "test input:  99.99957872837484  cluster:  2\n",
      "test input:  98.97612300157351  cluster:  2\n",
      "test input:  99.10163879394531  cluster:  2\n",
      "output cluster  2\n",
      "test input:  98.97614010580828  cluster:  2\n",
      "test input:  99.78717896538161  cluster:  2\n",
      "test input:  98.68647916088419  cluster:  2\n",
      "test input:  99.58441925048828  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.5844111114938  cluster:  2\n",
      "test input:  99.82579275707457  cluster:  2\n",
      "test input:  98.17474318526806  cluster:  2\n",
      "test input:  98.2230224609375  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.03542080256614  cluster:  2\n",
      "test input:  98.86026544028881  cluster:  2\n",
      "test input:  95.82851258362875  cluster:  2\n",
      "test input:  98.27129364013672  cluster:  2\n",
      "output cluster  2\n",
      "test input:  98.3002504619497  cluster:  2\n",
      "test input:  99.02439533587558  cluster:  2\n",
      "test input:  96.97748387339661  cluster:  2\n",
      "test input:  97.38300323486328  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.543009106063  cluster:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  96.78439077215123  cluster:  2\n",
      "test input:  92.95124873604864  cluster:  2\n",
      "test input:  94.83403015136719  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.8436853225195  cluster:  2\n",
      "test input:  95.40368517665021  cluster:  2\n",
      "test input:  94.09056835369825  cluster:  2\n",
      "test input:  94.24505615234375  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.41885358280803  cluster:  2\n",
      "test input:  94.99816810931964  cluster:  2\n",
      "test input:  94.02298411375506  cluster:  2\n",
      "test input:  94.6795425415039  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.70850176967082  cluster:  2\n",
      "test input:  94.83402494362936  cluster:  2\n",
      "test input:  93.09607409667876  cluster:  2\n",
      "test input:  93.33745574951172  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.01882584550101  cluster:  2\n",
      "test input:  93.73332080823612  cluster:  2\n",
      "test input:  92.65192840226794  cluster:  2\n",
      "test input:  93.46297454833984  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.63677763114428  cluster:  2\n",
      "test input:  93.70436420189722  cluster:  2\n",
      "test input:  92.54572780363924  cluster:  2\n",
      "test input:  93.04780578613281  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.8836506090923  cluster:  2\n",
      "test input:  94.8629829713323  cluster:  2\n",
      "test input:  92.8836506090923  cluster:  2\n",
      "test input:  94.2836685180664  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.35125150985145  cluster:  2\n",
      "test input:  95.07539639061713  cluster:  2\n",
      "test input:  93.61744930142174  cluster:  2\n",
      "test input:  94.57331848144531  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.95538656803966  cluster:  2\n",
      "test input:  93.97470122428501  cluster:  2\n",
      "test input:  90.7112167588241  cluster:  2\n",
      "test input:  91.10708618164062  cluster:  2\n",
      "output cluster  2\n",
      "test input:  91.73469171735918  cluster:  2\n",
      "test input:  92.82573421133921  cluster:  2\n",
      "test input:  90.96226742859092  cluster:  2\n",
      "test input:  92.54573059082031  cluster:  2\n",
      "output cluster  2\n",
      "test input:  91.61881841426282  cluster:  2\n",
      "test input:  93.15400953760208  cluster:  2\n",
      "test input:  90.23811508266881  cluster:  1\n",
      "test input:  92.8064193725586  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.45332480051789  cluster:  2\n",
      "test input:  94.9885086293331  cluster:  2\n",
      "test input:  92.73883714621053  cluster:  2\n",
      "test input:  94.87265014648438  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.54434581780319  cluster:  2\n",
      "test input:  95.55815151113931  cluster:  2\n",
      "test input:  94.06158260504924  cluster:  2\n",
      "test input:  95.14297485351562  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.5347167731715  cluster:  2\n",
      "test input:  94.78574839554929  cluster:  2\n",
      "test input:  93.24090724621657  cluster:  2\n",
      "test input:  93.25056457519531  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.95123849124442  cluster:  2\n",
      "test input:  95.08505866669901  cluster:  2\n",
      "test input:  92.78710074432732  cluster:  2\n",
      "test input:  94.55401611328125  cluster:  2\n",
      "output cluster  2\n",
      "test input:  93.07676709342553  cluster:  2\n",
      "test input:  94.13884489589742  cluster:  2\n",
      "test input:  91.97606734241495  cluster:  2\n",
      "test input:  92.03399658203125  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.15951779091574  cluster:  2\n",
      "test input:  93.9940199389038  cluster:  2\n",
      "test input:  92.07262392639895  cluster:  2\n",
      "test input:  93.63677978515625  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.02297806880246  cluster:  2\n",
      "test input:  94.59264259582227  cluster:  2\n",
      "test input:  93.59815137207842  cluster:  2\n",
      "test input:  94.16780853271484  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.00782655248298  cluster:  2\n",
      "test input:  96.24369952123334  cluster:  2\n",
      "test input:  94.78575217541817  cluster:  2\n",
      "test input:  95.99266052246094  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.59678769488981  cluster:  2\n",
      "test input:  96.25334605670973  cluster:  2\n",
      "test input:  95.05608780690787  cluster:  2\n",
      "test input:  95.50023651123047  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.0699056334844  cluster:  2\n",
      "test input:  96.0699056334844  cluster:  2\n",
      "test input:  95.2009301394022  cluster:  2\n",
      "test input:  95.89611053466797  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.19541357452087  cluster:  2\n",
      "test input:  96.95818048095875  cluster:  2\n",
      "test input:  95.7705868749431  cluster:  2\n",
      "test input:  96.67817687988281  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.25334801584555  cluster:  2\n",
      "test input:  96.98714291969868  cluster:  2\n",
      "test input:  93.6560791341607  cluster:  2\n",
      "test input:  94.15814971923828  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.85333977001675  cluster:  2\n",
      "test input:  95.29748116254697  cluster:  2\n",
      "test input:  94.10023013197052  cluster:  2\n",
      "test input:  95.26851654052734  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.96368612182393  cluster:  2\n",
      "test input:  95.96368612182393  cluster:  2\n",
      "test input:  94.46711697744131  cluster:  2\n",
      "test input:  94.88229370117188  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.64091068794593  cluster:  2\n",
      "test input:  95.1912605355026  cluster:  2\n",
      "test input:  93.94573774870314  cluster:  2\n",
      "test input:  95.13333129882812  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.20507348357101  cluster:  2\n",
      "test input:  96.3885259017717  cluster:  2\n",
      "test input:  95.14299565656502  cluster:  2\n",
      "test input:  96.3305892944336  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.58162287912856  cluster:  2\n",
      "test input:  96.92921303817619  cluster:  2\n",
      "test input:  95.95402912716014  cluster:  2\n",
      "test input:  96.3981704711914  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.39817258426112  cluster:  2\n",
      "test input:  96.64921156382796  cluster:  2\n",
      "test input:  95.60644106382728  cluster:  2\n",
      "test input:  96.09886169433594  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.57196041871377  cluster:  2\n",
      "test input:  96.71679087168428  cluster:  2\n",
      "test input:  95.7319570509739  cluster:  2\n",
      "test input:  96.46575927734375  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.23819127328231  cluster:  2\n",
      "test input:  98.58993010154022  cluster:  2\n",
      "test input:  96.78439255406006  cluster:  2\n",
      "test input:  98.5030288696289  cluster:  2\n",
      "output cluster  2\n",
      "test input:  98.82165021157468  cluster:  2\n",
      "test input:  100.83960472134518  cluster:  2\n",
      "test input:  98.62854782997016  cluster:  2\n",
      "test input:  100.66580963134766  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.17753535645612  cluster:  2\n",
      "test input:  101.63133404631014  cluster:  2\n",
      "test input:  99.13061627091287  cluster:  2\n",
      "test input:  99.29475402832031  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.34302756591421  cluster:  2\n",
      "test input:  99.34302756591421  cluster:  2\n",
      "test input:  94.1967692126256  cluster:  2\n",
      "test input:  94.76643371582031  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.69884371785218  cluster:  2\n",
      "test input:  95.20091427164739  cluster:  2\n",
      "test input:  93.39538437717694  cluster:  2\n",
      "test input:  94.79539489746094  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.35810031356277  cluster:  2\n",
      "test input:  97.0267954749782  cluster:  2\n",
      "test input:  95.35810031356277  cluster:  2\n",
      "test input:  96.04692077636719  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.70664540233953  cluster:  2\n",
      "test input:  96.91038042375544  cluster:  2\n",
      "test input:  94.83421507963065  cluster:  2\n",
      "test input:  96.5514144897461  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.38648467007212  cluster:  2\n",
      "test input:  97.52158293184448  cluster:  2\n",
      "test input:  95.53273687863788  cluster:  2\n",
      "test input:  96.31857299804688  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.91038275205435  cluster:  2\n",
      "test input:  99.94701538490075  cluster:  2\n",
      "test input:  96.3088740540293  cluster:  2\n",
      "test input:  99.6656723022461  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.14105346080852  cluster:  2\n",
      "test input:  100.19926135318985  cluster:  2\n",
      "test input:  98.24921553842364  cluster:  2\n",
      "test input:  99.55895233154297  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.4328009886436  cluster:  2\n",
      "test input:  100.23804451101317  cluster:  2\n",
      "test input:  98.152175857448  cluster:  2\n",
      "test input:  98.64696502685547  cluster:  2\n",
      "output cluster  2\n",
      "test input:  98.87012473960517  cluster:  2\n",
      "test input:  98.93803640980737  cluster:  2\n",
      "test input:  97.58949198410637  cluster:  2\n",
      "test input:  97.67681121826172  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.61860183475856  cluster:  2\n",
      "test input:  98.65668443584364  cluster:  2\n",
      "test input:  97.0753010796462  cluster:  2\n",
      "test input:  97.25963592529297  cluster:  2\n",
      "output cluster  2\n",
      "test input:  98.29772567176795  cluster:  2\n",
      "test input:  99.46192791397635  cluster:  2\n",
      "test input:  97.60890514824929  cluster:  2\n",
      "test input:  98.34623718261719  cluster:  2\n",
      "output cluster  2\n",
      "test input:  98.78280017425321  cluster:  2\n",
      "test input:  99.9761136311949  cluster:  2\n",
      "test input:  98.11337988851886  cluster:  2\n",
      "test input:  99.69476318359375  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.34549198142226  cluster:  2\n",
      "test input:  99.34549198142226  cluster:  2\n",
      "test input:  97.92904349335554  cluster:  2\n",
      "test input:  98.78279113769531  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.51043491788197  cluster:  2\n",
      "test input:  99.73357749513782  cluster:  2\n",
      "test input:  96.78425689306171  cluster:  2\n",
      "test input:  97.09471130371094  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.23052593228829  cluster:  2\n",
      "test input:  97.43426092709845  cluster:  2\n",
      "test input:  96.19244339578901  cluster:  2\n",
      "test input:  96.386474609375  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.34767896245418  cluster:  2\n",
      "test input:  96.36708652733512  cluster:  2\n",
      "test input:  95.10586127549608  cluster:  2\n",
      "test input:  95.64915466308594  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.9312319578375  cluster:  2\n",
      "test input:  95.02824757858613  cluster:  2\n",
      "test input:  92.77745112885783  cluster:  2\n",
      "test input:  92.88417053222656  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.6804403796832  cluster:  2\n",
      "test input:  94.28122411253872  cluster:  2\n",
      "test input:  92.45730518041441  cluster:  2\n",
      "test input:  94.24241638183594  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.48494693510592  cluster:  2\n",
      "test input:  96.376777300985  cluster:  2\n",
      "test input:  94.47524315323  cluster:  2\n",
      "test input:  96.27006530761719  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.9499059723051  cluster:  2\n",
      "test input:  96.88126917217875  cluster:  2\n",
      "test input:  95.12526216633731  cluster:  2\n",
      "test input:  96.05662536621094  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.69766076742405  cluster:  2\n",
      "test input:  95.69766076742405  cluster:  2\n",
      "test input:  93.9901578434064  cluster:  2\n",
      "test input:  94.18419647216797  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.04765138412239  cluster:  2\n",
      "test input:  95.32900185443651  cluster:  2\n",
      "test input:  93.99986495712164  cluster:  2\n",
      "test input:  94.42674255371094  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.46555010081836  cluster:  2\n",
      "test input:  95.95961428421657  cluster:  2\n",
      "test input:  94.12598433955101  cluster:  2\n",
      "test input:  95.62004852294922  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.77455674453552  cluster:  2\n",
      "test input:  96.85217220056627  cluster:  2\n",
      "test input:  95.30959646967831  cluster:  2\n",
      "test input:  96.3476791381836  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.41558808360136  cluster:  2\n",
      "test input:  96.68724217202237  cluster:  2\n",
      "test input:  95.30959377281846  cluster:  2\n",
      "test input:  95.41631317138672  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.6394542598461  cluster:  2\n",
      "test input:  96.06632444564791  cluster:  2\n",
      "test input:  94.86331453723326  cluster:  2\n",
      "test input:  94.99913787841797  cluster:  2\n",
      "output cluster  2\n",
      "test input:  94.69839000871374  cluster:  2\n",
      "test input:  95.30959506183886  cluster:  2\n",
      "test input:  93.55358795553062  cluster:  2\n",
      "test input:  95.13496398925781  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.11556115639905  cluster:  2\n",
      "test input:  95.5327349624199  cluster:  2\n",
      "test input:  94.75659523899886  cluster:  2\n",
      "test input:  95.39691162109375  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.44540683740011  cluster:  2\n",
      "test input:  96.09542694099126  cluster:  2\n",
      "test input:  94.73718625242638  cluster:  2\n",
      "test input:  95.67825317382812  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.28945438716595  cluster:  2\n",
      "test input:  96.28945438716595  cluster:  2\n",
      "test input:  94.67896726469533  cluster:  2\n",
      "test input:  95.23197174072266  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.1349568189139  cluster:  2\n",
      "test input:  95.84318483817367  cluster:  2\n",
      "test input:  93.7379157453779  cluster:  2\n",
      "test input:  94.94092559814453  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.7551452760502  cluster:  2\n",
      "test input:  98.53055236394788  cluster:  2\n",
      "test input:  95.2707776097181  cluster:  2\n",
      "test input:  98.28800964355469  cluster:  2\n",
      "output cluster  2\n",
      "test input:  98.95744438621524  cluster:  2\n",
      "test input:  98.95744438621524  cluster:  2\n",
      "test input:  97.27904525894346  cluster:  2\n",
      "test input:  97.97756958007812  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.92977552210593  cluster:  2\n",
      "test input:  97.49246900334302  cluster:  2\n",
      "test input:  94.51404471783677  cluster:  2\n",
      "test input:  95.4939193725586  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.72677310867661  cluster:  2\n",
      "test input:  96.12454678116892  cluster:  2\n",
      "test input:  95.22228743327545  cluster:  2\n",
      "test input:  95.78498840332031  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.47453479061794  cluster:  2\n",
      "test input:  97.20143804290052  cluster:  2\n",
      "test input:  95.19318430318282  cluster:  2\n",
      "test input:  95.69766998291016  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.74617267015218  cluster:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  97.3954603114385  cluster:  2\n",
      "test input:  95.20287190919474  cluster:  2\n",
      "test input:  97.07530212402344  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.76484899752974  cluster:  2\n",
      "test input:  97.24023809487805  cluster:  2\n",
      "test input:  96.01782061883763  cluster:  2\n",
      "test input:  96.79395294189453  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.4633714147665  cluster:  2\n",
      "test input:  97.4633714147665  cluster:  2\n",
      "test input:  95.72676454981801  cluster:  2\n",
      "test input:  96.27006530761719  cluster:  2\n",
      "output cluster  2\n",
      "test input:  96.75515640496384  cluster:  2\n",
      "test input:  96.80366051353164  cluster:  2\n",
      "test input:  95.59094677207767  cluster:  2\n",
      "test input:  95.64915466308594  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.96930788350008  cluster:  2\n",
      "test input:  96.10513122334412  cluster:  2\n",
      "test input:  94.97973677866247  cluster:  2\n",
      "test input:  95.48422241210938  cluster:  2\n",
      "output cluster  2\n",
      "test input:  95.23198053274649  cluster:  2\n",
      "test input:  97.09470691239606  cluster:  2\n",
      "test input:  95.05734947204081  cluster:  2\n",
      "test input:  96.9394760131836  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.44396868844306  cluster:  2\n",
      "test input:  97.6671038529993  cluster:  2\n",
      "test input:  96.20215110641132  cluster:  2\n",
      "test input:  97.53128051757812  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.31784391996767  cluster:  2\n",
      "test input:  98.23951074740131  cluster:  2\n",
      "test input:  97.17232420147214  cluster:  2\n",
      "test input:  97.65740966796875  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.37605341080616  cluster:  2\n",
      "test input:  99.52013015683147  cluster:  2\n",
      "test input:  97.23052629915941  cluster:  2\n",
      "test input:  99.47161865234375  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.56864352102828  cluster:  2\n",
      "test input:  99.56864352102828  cluster:  2\n",
      "test input:  98.27832176234067  cluster:  2\n",
      "test input:  99.39401245117188  cluster:  2\n",
      "output cluster  2\n",
      "test input:  99.00595748651995  cluster:  2\n",
      "test input:  100.65524529202365  cluster:  2\n",
      "test input:  98.22011391172695  cluster:  2\n",
      "test input:  100.18955993652344  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.18955172696606  cluster:  2\n",
      "test input:  100.22835945356263  cluster:  2\n",
      "test input:  99.33580394729256  cluster:  2\n",
      "test input:  100.17985534667969  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.03432211291593  cluster:  2\n",
      "test input:  101.0433007373535  cluster:  2\n",
      "test input:  99.76267544514747  cluster:  2\n",
      "test input:  100.5  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.68434139274228  cluster:  2\n",
      "test input:  101.55749674012563  cluster:  2\n",
      "test input:  100.43209486976109  cluster:  2\n",
      "test input:  101.4798812866211  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.67391678494712  cluster:  2\n",
      "test input:  102.10078696242407  cluster:  2\n",
      "test input:  100.68433828782375  cluster:  2\n",
      "test input:  101.93585968017578  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.8485488732899  cluster:  2\n",
      "test input:  102.65378513075997  cluster:  2\n",
      "test input:  101.654510243561  cluster:  2\n",
      "test input:  102.54706573486328  cluster:  2\n",
      "output cluster  2\n",
      "test input:  102.80902097169476  cluster:  2\n",
      "test input:  103.06126750154742  cluster:  2\n",
      "test input:  101.35376448701885  cluster:  2\n",
      "test input:  101.61570739746094  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.44107947470991  cluster:  2\n",
      "test input:  101.89706103836515  cluster:  2\n",
      "test input:  100.33508510414153  cluster:  2\n",
      "test input:  101.25675201416016  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.6642267861047  cluster:  2\n",
      "test input:  101.88736198602912  cluster:  2\n",
      "test input:  101.04331789667128  cluster:  2\n",
      "test input:  101.5186996459961  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.68361062527514  cluster:  2\n",
      "test input:  102.05228030793597  cluster:  2\n",
      "test input:  101.26643683824399  cluster:  2\n",
      "test input:  101.70301818847656  cluster:  2\n",
      "output cluster  2\n",
      "test input:  102.39184894053794  cluster:  2\n",
      "test input:  102.39184894053794  cluster:  2\n",
      "test input:  100.71344984206202  cluster:  2\n",
      "test input:  101.14032745361328  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.91718011059677  cluster:  2\n",
      "test input:  101.74183134893451  cluster:  2\n",
      "test input:  100.65523720791542  cluster:  2\n",
      "test input:  101.67391967773438  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.54778253957089  cluster:  2\n",
      "test input:  101.6447981455896  cluster:  2\n",
      "test input:  100.66493090243944  cluster:  2\n",
      "test input:  101.34404754638672  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.8589713152435  cluster:  2\n",
      "test input:  101.8582462118451  cluster:  2\n",
      "test input:  100.8589713152435  cluster:  2\n",
      "test input:  101.36346435546875  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.40227303953927  cluster:  2\n",
      "test input:  102.4791634775413  cluster:  2\n",
      "test input:  101.19853801097368  cluster:  2\n",
      "test input:  102.07169342041016  cluster:  2\n",
      "output cluster  2\n",
      "test input:  102.22692230694523  cluster:  2\n",
      "test input:  102.25602625304514  cluster:  2\n",
      "test input:  101.29555902266071  cluster:  2\n",
      "test input:  101.54779815673828  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.88734493815619  cluster:  2\n",
      "test input:  102.46945340119176  cluster:  2\n",
      "test input:  101.56719416566654  cluster:  2\n",
      "test input:  102.0910873413086  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.87766560468829  cluster:  2\n",
      "test input:  101.97468123082142  cluster:  2\n",
      "test input:  101.2470529320962  cluster:  2\n",
      "test input:  101.5186996459961  cluster:  2\n",
      "output cluster  2\n",
      "test input:  101.42167420456215  cluster:  2\n",
      "test input:  101.63511300248973  cluster:  2\n",
      "test input:  101.17913146179302  cluster:  2\n",
      "test input:  101.48958587646484  cluster:  2\n",
      "output cluster  3\n",
      "test input:  101.4119702295303  cluster:  2\n",
      "test input:  101.83884782457385  cluster:  2\n",
      "test input:  100.7037495670085  cluster:  2\n",
      "test input:  100.79106140136719  cluster:  2\n",
      "output cluster  3\n",
      "test input:  100.96648314527992  cluster:  2\n",
      "test input:  101.82411827536583  cluster:  2\n",
      "test input:  100.5863975527937  cluster:  2\n",
      "test input:  101.4830093383789  cluster:  2\n",
      "output cluster  3\n",
      "test input:  101.21012942186498  cluster:  2\n",
      "test input:  101.88259198731733  cluster:  2\n",
      "test input:  100.83979170628022  cluster:  2\n",
      "test input:  101.8241195678711  cluster:  2\n",
      "output cluster  3\n",
      "test input:  102.496574032166  cluster:  2\n",
      "test input:  104.00717596532728  cluster:  2\n",
      "test input:  102.39911752190352  cluster:  2\n",
      "test input:  102.52581024169922  cluster:  2\n",
      "output cluster  3\n",
      "test input:  102.87666337371294  cluster:  2\n",
      "test input:  103.58811005190418  cluster:  2\n",
      "test input:  102.21394867015528  cluster:  2\n",
      "test input:  103.30548095703125  cluster:  2\n",
      "output cluster  3\n",
      "test input:  103.56861004702365  cluster:  2\n",
      "test input:  103.90971898458052  cluster:  2\n",
      "test input:  102.9643752248591  cluster:  2\n",
      "test input:  103.22750854492188  cluster:  2\n",
      "output cluster  3\n",
      "test input:  103.63683060998574  cluster:  2\n",
      "test input:  104.63090634486359  cluster:  2\n",
      "test input:  103.40293349873129  cluster:  2\n",
      "test input:  104.29954528808594  cluster:  3\n",
      "output cluster  3\n",
      "test input:  105.00124009555009  cluster:  2\n",
      "test input:  105.25463296053057  cluster:  3\n",
      "test input:  104.05589636910217  cluster:  2\n",
      "test input:  104.86479949951172  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.89403034213456  cluster:  2\n",
      "test input:  105.15717107492988  cluster:  3\n",
      "test input:  104.3092838982458  cluster:  2\n",
      "test input:  104.44572448730469  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.35801371408147  cluster:  2\n",
      "test input:  104.68936729911697  cluster:  3\n",
      "test input:  103.71478743425357  cluster:  2\n",
      "test input:  103.9779281616211  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.06564471370196  cluster:  2\n",
      "test input:  105.05972041549863  cluster:  3\n",
      "test input:  104.06564471370196  cluster:  2\n",
      "test input:  105.04997253417969  cluster:  3\n",
      "output cluster  2\n",
      "test input:  105.1766680055535  cluster:  2\n",
      "test input:  105.52751738768069  cluster:  3\n",
      "test input:  104.8063302957326  cluster:  2\n",
      "test input:  105.24488830566406  cluster:  3\n",
      "output cluster  2\n",
      "test input:  105.3715892052003  cluster:  2\n",
      "test input:  105.3715892052003  cluster:  3\n",
      "test input:  104.11438014959309  cluster:  2\n",
      "test input:  104.29954528808594  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.3190452788759  cluster:  2\n",
      "test input:  104.82582361304013  cluster:  3\n",
      "test input:  103.94870755142725  cluster:  2\n",
      "test input:  104.37751770019531  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.53345357912366  cluster:  2\n",
      "test input:  105.21565660949156  cluster:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  104.44573751210186  cluster:  2\n",
      "test input:  105.07921600341797  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.26057724896711  cluster:  2\n",
      "test input:  105.7224473271691  cluster:  3\n",
      "test input:  104.02667268292667  cluster:  2\n",
      "test input:  105.52752685546875  cluster:  3\n",
      "output cluster  3\n",
      "test input:  105.04997537915297  cluster:  2\n",
      "test input:  105.50802915263543  cluster:  3\n",
      "test input:  104.17285192306475  cluster:  2\n",
      "test input:  105.45929718017578  cluster:  3\n",
      "output cluster  3\n",
      "test input:  105.25463610110259  cluster:  2\n",
      "test input:  105.50802897364377  cluster:  3\n",
      "test input:  103.68556176438864  cluster:  2\n",
      "test input:  103.71479797363281  cluster:  2\n",
      "output cluster  3\n",
      "test input:  103.80251570893564  cluster:  2\n",
      "test input:  104.24107372557278  cluster:  2\n",
      "test input:  102.56479497099099  cluster:  2\n",
      "test input:  103.13980102539062  cluster:  2\n",
      "output cluster  3\n",
      "test input:  103.56860666833197  cluster:  2\n",
      "test input:  105.14742884356838  cluster:  3\n",
      "test input:  103.29572547555269  cluster:  2\n",
      "test input:  104.62115478515625  cluster:  3\n",
      "output cluster  3\n",
      "test input:  105.01099398003333  cluster:  2\n",
      "test input:  105.10845049199568  cluster:  3\n",
      "test input:  104.06565019954256  cluster:  2\n",
      "test input:  104.1241226196289  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.28005108110996  cluster:  2\n",
      "test input:  104.79657724725953  cluster:  3\n",
      "test input:  104.11437427978929  cluster:  2\n",
      "test input:  104.36775970458984  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.53345021872981  cluster:  2\n",
      "test input:  104.53345021872981  cluster:  2\n",
      "test input:  103.62709054440292  cluster:  2\n",
      "test input:  103.84149932861328  cluster:  3\n",
      "output cluster  3\n",
      "test input:  103.695301211383  cluster:  2\n",
      "test input:  105.45928842321209  cluster:  3\n",
      "test input:  103.695301211383  cluster:  2\n",
      "test input:  105.1181869506836  cluster:  3\n",
      "output cluster  3\n",
      "test input:  105.80040006048279  cluster:  2\n",
      "test input:  105.87836824325277  cluster:  3\n",
      "test input:  105.04022886711336  cluster:  2\n",
      "test input:  105.55675506591797  cluster:  3\n",
      "output cluster  3\n",
      "test input:  105.70293486755807  cluster:  2\n",
      "test input:  106.58980614394697  cluster:  3\n",
      "test input:  105.28386521390976  cluster:  2\n",
      "test input:  106.53132629394531  cluster:  3\n",
      "output cluster  3\n",
      "test input:  106.34616952369606  cluster:  2\n",
      "test input:  107.34998570803661  cluster:  3\n",
      "test input:  106.19998104038949  cluster:  3\n",
      "test input:  106.47286224365234  cluster:  3\n",
      "output cluster  3\n",
      "test input:  106.59955109522879  cluster:  2\n",
      "test input:  106.66777139356887  cluster:  3\n",
      "test input:  105.46904223195686  cluster:  2\n",
      "test input:  106.36565399169922  cluster:  3\n",
      "output cluster  3\n",
      "test input:  106.27794235629901  cluster:  2\n",
      "test input:  106.89192502397121  cluster:  3\n",
      "test input:  105.72243210398948  cluster:  2\n",
      "test input:  106.84319305419922  cluster:  3\n",
      "output cluster  3\n",
      "test input:  106.87244038629882  cluster:  3\n",
      "test input:  107.48642307516414  cluster:  3\n",
      "test input:  106.46311115826703  cluster:  3\n",
      "test input:  107.40845489501953  cluster:  3\n",
      "output cluster  3\n",
      "test input:  106.35590904701233  cluster:  2\n",
      "test input:  107.4766774953637  cluster:  3\n",
      "test input:  106.22921632815542  cluster:  3\n",
      "test input:  106.98938751220703  cluster:  3\n",
      "output cluster  3\n",
      "test input:  107.03811439077595  cluster:  3\n",
      "test input:  108.75336969633103  cluster:  3\n",
      "test input:  107.0088781828507  cluster:  3\n",
      "test input:  108.31481170654297  cluster:  3\n",
      "output cluster  3\n",
      "test input:  109.2991306420153  cluster:  3\n",
      "test input:  112.82710490731777  cluster:  3\n",
      "test input:  106.96988541714347  cluster:  3\n",
      "test input:  112.40803527832031  cluster:  3\n",
      "output cluster  3\n",
      "test input:  112.32034765985297  cluster:  3\n",
      "test input:  113.16823495669566  cluster:  3\n",
      "test input:  110.51737610424794  cluster:  3\n",
      "test input:  113.01229858398438  cluster:  3\n",
      "output cluster  3\n",
      "test input:  112.90507842796774  cluster:  3\n",
      "test input:  113.8309337819405  cluster:  3\n",
      "test input:  112.6127089231246  cluster:  3\n",
      "test input:  113.49957275390625  cluster:  3\n",
      "output cluster  3\n",
      "test input:  114.2987384970589  cluster:  3\n",
      "test input:  115.86781285464802  cluster:  3\n",
      "test input:  114.05509350284264  cluster:  3\n",
      "test input:  114.7957763671875  cluster:  3\n",
      "output cluster  3\n",
      "test input:  115.91653734707214  cluster:  3\n",
      "test input:  117.17374632834947  cluster:  3\n",
      "test input:  115.44873571676594  cluster:  3\n",
      "test input:  115.65339660644531  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.20890619476367  cluster:  3\n",
      "test input:  116.21865407577488  cluster:  3\n",
      "test input:  112.9538128697518  cluster:  3\n",
      "test input:  113.50932312011719  cluster:  3\n",
      "output cluster  3\n",
      "test input:  114.23050427508805  cluster:  3\n",
      "test input:  114.25000003610432  cluster:  3\n",
      "test input:  112.59320981606989  cluster:  3\n",
      "test input:  112.90507507324219  cluster:  3\n",
      "output cluster  3\n",
      "test input:  113.02203948719075  cluster:  3\n",
      "test input:  113.34365265945698  cluster:  3\n",
      "test input:  111.33601287977346  cluster:  3\n",
      "test input:  111.4237289428711  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.21905752711818  cluster:  3\n",
      "test input:  112.9050765396668  cluster:  3\n",
      "test input:  111.11185314649899  cluster:  3\n",
      "test input:  112.78813171386719  cluster:  3\n",
      "output cluster  3\n",
      "test input:  112.77839431162761  cluster:  3\n",
      "test input:  113.71399018222364  cluster:  3\n",
      "test input:  111.76483025961814  cluster:  3\n",
      "test input:  111.88178253173828  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.9792421823867  cluster:  3\n",
      "test input:  112.13517111413316  cluster:  3\n",
      "test input:  110.06906629689739  cluster:  3\n",
      "test input:  111.16059112548828  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.26778670813663  cluster:  3\n",
      "test input:  111.97923331511052  cluster:  3\n",
      "test input:  111.05337793794027  cluster:  3\n",
      "test input:  111.491943359375  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.72584298576332  cluster:  3\n",
      "test input:  113.29491727359313  cluster:  3\n",
      "test input:  111.72584298576332  cluster:  3\n",
      "test input:  113.24618530273438  cluster:  3\n",
      "output cluster  3\n",
      "test input:  110.61483083217324  cluster:  3\n",
      "test input:  113.20721722069474  cluster:  3\n",
      "test input:  110.2542335526965  cluster:  3\n",
      "test input:  112.72966766357422  cluster:  3\n",
      "output cluster  3\n",
      "test input:  113.0220312473833  cluster:  3\n",
      "test input:  114.34746049513409  cluster:  3\n",
      "test input:  112.27160056680516  cluster:  3\n",
      "test input:  112.3398208618164  cluster:  3\n",
      "output cluster  2\n",
      "test input:  112.6127260310206  cluster:  3\n",
      "test input:  112.85637103979784  cluster:  3\n",
      "test input:  110.4394092811272  cluster:  3\n",
      "test input:  111.57966613769531  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.33600585561051  cluster:  3\n",
      "test input:  112.51524664406692  cluster:  3\n",
      "test input:  111.092360880257  cluster:  3\n",
      "test input:  112.25211334228516  cluster:  3\n",
      "output cluster  3\n",
      "test input:  109.9715922970122  cluster:  3\n",
      "test input:  112.48601022237877  cluster:  3\n",
      "test input:  109.53303431639328  cluster:  3\n",
      "test input:  111.82329559326172  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.98898589157403  cluster:  3\n",
      "test input:  112.38855980559389  cluster:  3\n",
      "test input:  109.00676618132647  cluster:  3\n",
      "test input:  109.55253601074219  cluster:  3\n",
      "output cluster  3\n",
      "test input:  109.61101153431396  cluster:  3\n",
      "test input:  111.7453440697436  cluster:  3\n",
      "test input:  109.61101153431396  cluster:  3\n",
      "test input:  110.14702606201172  cluster:  3\n",
      "output cluster  3\n",
      "test input:  109.15295441832485  cluster:  3\n",
      "test input:  109.64999227483568  cluster:  3\n",
      "test input:  104.59191995414093  cluster:  2\n",
      "test input:  104.71861267089844  cluster:  3\n",
      "output cluster  2\n",
      "test input:  102.55505081786643  cluster:  2\n",
      "test input:  102.76945215984615  cluster:  2\n",
      "test input:  97.91604820072831  cluster:  2\n",
      "test input:  99.94317626953125  cluster:  2\n",
      "output cluster  2\n",
      "test input:  100.38174255172757  cluster:  2\n",
      "test input:  107.54490424672576  cluster:  3\n",
      "test input:  100.38174255172757  cluster:  2\n",
      "test input:  107.32075500488281  cluster:  3\n",
      "output cluster  2\n",
      "test input:  107.92498523672539  cluster:  3\n",
      "test input:  111.17033836466172  cluster:  3\n",
      "test input:  106.35591086924106  cluster:  3\n",
      "test input:  107.27201843261719  cluster:  3\n",
      "output cluster  1\n",
      "test input:  109.31862520773349  cluster:  3\n",
      "test input:  113.58728991316615  cluster:  3\n",
      "test input:  107.69107856506022  cluster:  3\n",
      "test input:  113.411865234375  cluster:  3\n",
      "output cluster  2\n",
      "test input:  109.70846358314868  cluster:  3\n",
      "test input:  111.67711179097242  cluster:  3\n",
      "test input:  108.75337197004588  cluster:  3\n",
      "test input:  111.19956970214844  cluster:  3\n",
      "output cluster  1\n",
      "test input:  108.05166776829961  cluster:  3\n",
      "test input:  109.43556933393029  cluster:  3\n",
      "test input:  104.93300787009282  cluster:  2\n",
      "test input:  107.69107055664062  cluster:  3\n",
      "output cluster  2\n",
      "test input:  100.10885294415928  cluster:  2\n",
      "test input:  105.66395564560595  cluster:  3\n",
      "test input:  99.8554600770278  cluster:  2\n",
      "test input:  103.0325927734375  cluster:  2\n",
      "output cluster  1\n",
      "test input:  105.56649512006273  cluster:  2\n",
      "test input:  106.02454886555356  cluster:  3\n",
      "test input:  99.60206341860388  cluster:  2\n",
      "test input:  102.03851318359375  cluster:  2\n",
      "output cluster  1\n",
      "test input:  99.27070660035744  cluster:  2\n",
      "test input:  99.36816310070573  cluster:  2\n",
      "test input:  95.3041668090021  cluster:  2\n",
      "test input:  96.79527282714844  cluster:  2\n",
      "output cluster  0\n",
      "test input:  89.52952145983633  cluster:  1\n",
      "test input:  91.38023501501313  cluster:  1\n",
      "test input:  86.46458483800795  cluster:  1\n",
      "test input:  86.7877197265625  cluster:  1\n",
      "output cluster  0\n",
      "test input:  91.21376073541931  cluster:  2\n",
      "test input:  94.36683015143403  cluster:  2\n",
      "test input:  83.93820239941529  cluster:  1\n",
      "test input:  94.05348205566406  cluster:  2\n",
      "output cluster  1\n",
      "test input:  85.19160163809751  cluster:  1\n",
      "test input:  90.851456275736  cluster:  1\n",
      "test input:  81.61746973038343  cluster:  1\n",
      "test input:  83.53672790527344  cluster:  1\n",
      "output cluster  1\n",
      "test input:  85.65183346072408  cluster:  1\n",
      "test input:  93.88701774729921  cluster:  2\n",
      "test input:  85.19160177305751  cluster:  1\n",
      "test input:  93.0546875  cluster:  2\n",
      "output cluster  2\n",
      "test input:  88.56009423667129  cluster:  1\n",
      "test input:  93.50511920821525  cluster:  2\n",
      "test input:  87.29690759845211  cluster:  1\n",
      "test input:  89.6666030883789  cluster:  1\n",
      "output cluster  2\n",
      "test input:  89.86244725789517  cluster:  1\n",
      "test input:  90.67519650596593  cluster:  1\n",
      "test input:  83.74236099978721  cluster:  1\n",
      "test input:  86.17081451416016  cluster:  1\n",
      "output cluster  2\n",
      "test input:  87.95297767467918  cluster:  1\n",
      "test input:  87.95297767467918  cluster:  1\n",
      "test input:  78.01395673683977  cluster:  0\n",
      "test input:  78.82670593261719  cluster:  0\n",
      "output cluster  2\n",
      "test input:  78.89524929105893  cluster:  0\n",
      "test input:  78.89524929105893  cluster:  0\n",
      "test input:  70.17045891193546  cluster:  0\n",
      "test input:  71.34551239013672  cluster:  0\n",
      "output cluster  1\n",
      "test input:  75.31133213765767  cluster:  0\n",
      "test input:  81.46079321387289  cluster:  1\n",
      "test input:  74.80213681050154  cluster:  0\n",
      "test input:  81.26494598388672  cluster:  1\n",
      "output cluster  2\n",
      "test input:  81.26495513188809  cluster:  1\n",
      "test input:  89.12804113388881  cluster:  1\n",
      "test input:  80.56971419649169  cluster:  1\n",
      "test input:  85.15243530273438  cluster:  1\n",
      "output cluster  2\n",
      "test input:  86.2197819375537  cluster:  1\n",
      "test input:  94.09265466763509  cluster:  2\n",
      "test input:  86.2197819375537  cluster:  1\n",
      "test input:  91.86984252929688  cluster:  2\n",
      "output cluster  2\n",
      "test input:  88.16840454887021  cluster:  1\n",
      "test input:  93.45616014923809  cluster:  2\n",
      "test input:  87.42420002728166  cluster:  1\n",
      "test input:  90.85144805908203  cluster:  2\n",
      "output cluster  2\n",
      "test input:  92.07547367078796  cluster:  2\n",
      "test input:  97.75491677634501  cluster:  2\n",
      "test input:  90.8808316232129  cluster:  2\n",
      "test input:  97.3730239868164  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.45134772237536  cluster:  2\n",
      "test input:  98.31306059139727  cluster:  2\n",
      "test input:  92.61403694654521  cluster:  2\n",
      "test input:  92.9763412475586  cluster:  2\n",
      "output cluster  3\n",
      "test input:  88.24673971218118  cluster:  1\n",
      "test input:  91.3508452911573  cluster:  1\n",
      "test input:  88.12923138084935  cluster:  1\n",
      "test input:  90.35204315185547  cluster:  1\n",
      "output cluster  2\n",
      "test input:  90.13663302236576  cluster:  1\n",
      "test input:  92.48674015904551  cluster:  2\n",
      "test input:  88.4523840958191  cluster:  1\n",
      "test input:  92.00692749023438  cluster:  2\n",
      "output cluster  3\n",
      "test input:  92.56507801191874  cluster:  2\n",
      "test input:  93.92618457703918  cluster:  2\n",
      "test input:  91.62503367368647  cluster:  2\n",
      "test input:  93.24073791503906  cluster:  2\n",
      "output cluster  2\n",
      "test input:  97.8136569412649  cluster:  2\n",
      "test input:  100.14418288269464  cluster:  2\n",
      "test input:  96.03148828704032  cluster:  2\n",
      "test input:  99.47831726074219  cluster:  2\n",
      "output cluster  3\n",
      "test input:  102.54327750850132  cluster:  2\n",
      "test input:  104.88359805663951  cluster:  3\n",
      "test input:  98.1368151000858  cluster:  2\n",
      "test input:  98.84185028076172  cluster:  2\n",
      "output cluster  3\n",
      "test input:  99.41957600739735  cluster:  2\n",
      "test input:  102.63139607893439  cluster:  2\n",
      "test input:  99.12581634962024  cluster:  2\n",
      "test input:  101.96553039550781  cluster:  2\n",
      "output cluster  3\n",
      "test input:  102.60201207976091  cluster:  2\n",
      "test input:  106.33281395115714  cluster:  3\n",
      "test input:  102.60201207976091  cluster:  2\n",
      "test input:  105.67674255371094  cluster:  3\n",
      "output cluster  2\n",
      "test input:  103.10140985412544  cluster:  2\n",
      "test input:  104.76607013133541  cluster:  3\n",
      "test input:  100.5358673083427  cluster:  2\n",
      "test input:  101.14298248291016  cluster:  2\n",
      "output cluster  2\n",
      "test input:  103.4539320404251  cluster:  2\n",
      "test input:  105.6375744740767  cluster:  3\n",
      "test input:  102.10261231207689  cluster:  2\n",
      "test input:  105.32422637939453  cluster:  3\n",
      "output cluster  2\n",
      "test input:  103.90436785382917  cluster:  2\n",
      "test input:  105.86279528302839  cluster:  3\n",
      "test input:  102.43554728192976  cluster:  2\n",
      "test input:  103.7966537475586  cluster:  2\n",
      "output cluster  2\n",
      "test input:  104.66817284451866  cluster:  2\n",
      "test input:  106.66577009074028  cluster:  3\n",
      "test input:  104.28628002238312  cluster:  2\n",
      "test input:  106.05865478515625  cluster:  3\n",
      "output cluster  3\n",
      "test input:  108.79064504902784  cluster:  3\n",
      "test input:  109.58381325879007  cluster:  3\n",
      "test input:  107.10639622044668  cluster:  3\n",
      "test input:  108.927734375  cluster:  3\n",
      "output cluster  3\n",
      "test input:  107.48829079257878  cluster:  3\n",
      "test input:  108.57521866024895  cluster:  3\n",
      "test input:  106.49929027723127  cluster:  3\n",
      "test input:  107.49808502197266  cluster:  3\n",
      "output cluster  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  105.4809033583971  cluster:  2\n",
      "test input:  106.59720640412179  cluster:  3\n",
      "test input:  102.5824316369709  cluster:  2\n",
      "test input:  103.08182525634766  cluster:  2\n",
      "output cluster  3\n",
      "test input:  106.2447072395686  cluster:  2\n",
      "test input:  106.2447072395686  cluster:  3\n",
      "test input:  100.66319104572136  cluster:  2\n",
      "test input:  102.45514678955078  cluster:  2\n",
      "output cluster  3\n",
      "test input:  104.74649476742654  cluster:  2\n",
      "test input:  104.74649476742654  cluster:  3\n",
      "test input:  100.68275625985743  cluster:  2\n",
      "test input:  101.69134521484375  cluster:  2\n",
      "output cluster  3\n",
      "test input:  102.59221704294613  cluster:  2\n",
      "test input:  103.55184976527858  cluster:  2\n",
      "test input:  100.82963684857495  cluster:  2\n",
      "test input:  103.43434143066406  cluster:  2\n",
      "output cluster  3\n",
      "test input:  104.88358835829209  cluster:  2\n",
      "test input:  109.56422902176026  cluster:  3\n",
      "test input:  104.7758742450484  cluster:  2\n",
      "test input:  109.30963134765625  cluster:  3\n",
      "output cluster  2\n",
      "test input:  111.17013682735472  cluster:  3\n",
      "test input:  112.04163647491326  cluster:  3\n",
      "test input:  108.35000389185373  cluster:  3\n",
      "test input:  108.89836120605469  cluster:  3\n",
      "output cluster  3\n",
      "test input:  110.40636324669025  cluster:  3\n",
      "test input:  110.87638918890968  cluster:  3\n",
      "test input:  108.90816722900472  cluster:  3\n",
      "test input:  109.28026580810547  cluster:  3\n",
      "output cluster  3\n",
      "test input:  106.48949834730072  cluster:  2\n",
      "test input:  108.82981867883191  cluster:  3\n",
      "test input:  106.06843612396872  cluster:  3\n",
      "test input:  107.39037322998047  cluster:  3\n",
      "output cluster  3\n",
      "test input:  104.7758766307902  cluster:  2\n",
      "test input:  105.3046529794426  cluster:  3\n",
      "test input:  103.63019827744753  cluster:  2\n",
      "test input:  104.40377807617188  cluster:  3\n",
      "output cluster  3\n",
      "test input:  103.61060970777999  cluster:  2\n",
      "test input:  104.41356472433107  cluster:  2\n",
      "test input:  102.2103336760229  cluster:  2\n",
      "test input:  103.92395782470703  cluster:  3\n",
      "output cluster  3\n",
      "test input:  105.304653866661  cluster:  2\n",
      "test input:  107.20433104588321  cluster:  3\n",
      "test input:  103.73791326716209  cluster:  2\n",
      "test input:  106.56784057617188  cluster:  3\n",
      "output cluster  3\n",
      "test input:  107.48828558976781  cluster:  3\n",
      "test input:  107.48828558976781  cluster:  3\n",
      "test input:  103.40496621471237  cluster:  2\n",
      "test input:  103.43434143066406  cluster:  2\n",
      "output cluster  3\n",
      "test input:  104.53106851044052  cluster:  2\n",
      "test input:  106.94972768441889  cluster:  3\n",
      "test input:  104.23730139515587  cluster:  2\n",
      "test input:  105.09901428222656  cluster:  3\n",
      "output cluster  3\n",
      "test input:  106.9399361934381  cluster:  3\n",
      "test input:  107.0182750889611  cluster:  3\n",
      "test input:  104.85421352809378  cluster:  2\n",
      "test input:  105.35360717773438  cluster:  3\n",
      "output cluster  3\n",
      "test input:  103.77708293170863  cluster:  2\n",
      "test input:  107.6645554842053  cluster:  3\n",
      "test input:  103.64978035501667  cluster:  2\n",
      "test input:  106.96931457519531  cluster:  3\n",
      "output cluster  3\n",
      "test input:  107.71351827454457  cluster:  3\n",
      "test input:  108.19333094594118  cluster:  3\n",
      "test input:  105.95093044172866  cluster:  2\n",
      "test input:  106.24469757080078  cluster:  3\n",
      "output cluster  3\n",
      "test input:  106.26428273281414  cluster:  2\n",
      "test input:  108.00728964518571  cluster:  3\n",
      "test input:  105.21652422182923  cluster:  2\n",
      "test input:  106.62659454345703  cluster:  3\n",
      "output cluster  3\n",
      "test input:  105.11860774349599  cluster:  2\n",
      "test input:  107.39038362939922  cluster:  3\n",
      "test input:  105.0206878503847  cluster:  2\n",
      "test input:  107.20433807373047  cluster:  3\n",
      "output cluster  3\n",
      "test input:  107.50788930775462  cluster:  3\n",
      "test input:  109.91675447821899  cluster:  3\n",
      "test input:  106.41116710810218  cluster:  3\n",
      "test input:  109.75028991699219  cluster:  3\n",
      "output cluster  3\n",
      "test input:  112.53124619644088  cluster:  3\n",
      "test input:  113.50067322099838  cluster:  3\n",
      "test input:  111.49328197668532  cluster:  3\n",
      "test input:  112.55083465576172  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.82621426185796  cluster:  3\n",
      "test input:  113.5790078805776  cluster:  3\n",
      "test input:  110.08321487307765  cluster:  3\n",
      "test input:  110.28884887695312  cluster:  3\n",
      "output cluster  3\n",
      "test input:  110.64135847046235  cluster:  3\n",
      "test input:  113.20690116060102  cluster:  3\n",
      "test input:  110.64135847046235  cluster:  3\n",
      "test input:  112.32560729980469  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.49328747194004  cluster:  3\n",
      "test input:  112.31582350455712  cluster:  3\n",
      "test input:  110.66095720917981  cluster:  3\n",
      "test input:  111.6205825805664  cluster:  3\n",
      "output cluster  3\n",
      "test input:  111.70870099639878  cluster:  3\n",
      "test input:  113.3831555315097  cluster:  3\n",
      "test input:  111.46389757072511  cluster:  3\n",
      "test input:  112.9425048828125  cluster:  3\n",
      "output cluster  3\n",
      "test input:  115.9584929460831  cluster:  3\n",
      "test input:  116.7908231571082  cluster:  3\n",
      "test input:  113.61817263151676  cluster:  3\n",
      "test input:  113.86297607421875  cluster:  3\n",
      "output cluster  3\n",
      "test input:  115.33179917218507  cluster:  3\n",
      "test input:  115.53743317191135  cluster:  3\n",
      "test input:  111.84580046496336  cluster:  3\n",
      "test input:  112.79563903808594  cluster:  3\n",
      "output cluster  3\n",
      "test input:  113.91194139195022  cluster:  3\n",
      "test input:  115.20450328920336  cluster:  3\n",
      "test input:  113.16773682358985  cluster:  3\n",
      "test input:  113.95111083984375  cluster:  3\n",
      "output cluster  3\n",
      "test input:  113.90214098743107  cluster:  3\n",
      "test input:  116.3599695461462  cluster:  3\n",
      "test input:  113.2950257842067  cluster:  3\n",
      "test input:  115.9976577758789  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.82021102666856  cluster:  3\n",
      "test input:  117.37836260195068  cluster:  3\n",
      "test input:  114.81281971916151  cluster:  3\n",
      "test input:  116.408935546875  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.77123832100851  cluster:  3\n",
      "test input:  117.3098088655292  cluster:  3\n",
      "test input:  115.82139979929451  cluster:  3\n",
      "test input:  116.76144409179688  cluster:  3\n",
      "output cluster  3\n",
      "test input:  117.47628449481823  cluster:  3\n",
      "test input:  118.2204890981693  cluster:  3\n",
      "test input:  115.88016116904653  cluster:  3\n",
      "test input:  116.859375  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.62436952718143  cluster:  3\n",
      "test input:  116.88876145370395  cluster:  3\n",
      "test input:  114.01966453780581  cluster:  3\n",
      "test input:  115.47869110107422  cluster:  3\n",
      "output cluster  3\n",
      "test input:  117.05522776789877  cluster:  3\n",
      "test input:  117.75046872415973  cluster:  3\n",
      "test input:  112.93273824170386  cluster:  3\n",
      "test input:  117.40774536132812  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.88875024547454  cluster:  3\n",
      "test input:  119.0821869952785  cluster:  3\n",
      "test input:  116.79082289196951  cluster:  3\n",
      "test input:  118.77863311767578  cluster:  3\n",
      "output cluster  3\n",
      "test input:  117.85818007121931  cluster:  3\n",
      "test input:  118.64155414278349  cluster:  3\n",
      "test input:  116.6733322043149  cluster:  3\n",
      "test input:  117.59378814697266  cluster:  3\n",
      "output cluster  3\n",
      "test input:  117.08458546243294  cluster:  3\n",
      "test input:  118.32818361306961  cluster:  3\n",
      "test input:  116.89853246297086  cluster:  3\n",
      "test input:  117.51544189453125  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.50271521304852  cluster:  3\n",
      "test input:  116.87634675528867  cluster:  3\n",
      "test input:  110.82949141520292  cluster:  3\n",
      "test input:  111.35060119628906  cluster:  3\n",
      "output cluster  3\n",
      "test input:  113.52352544899982  cluster:  3\n",
      "test input:  113.94631386901347  cluster:  3\n",
      "test input:  111.23260197540415  cluster:  3\n",
      "test input:  113.2187271118164  cluster:  3\n",
      "output cluster  3\n",
      "test input:  110.65251749720903  cluster:  3\n",
      "test input:  116.37490609527447  cluster:  3\n",
      "test input:  110.34771911443548  cluster:  3\n",
      "test input:  115.4015121459961  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.6993657170842  cluster:  3\n",
      "test input:  117.98739234977629  cluster:  3\n",
      "test input:  114.14296621502328  cluster:  3\n",
      "test input:  116.54204559326172  cluster:  3\n",
      "output cluster  3\n",
      "test input:  117.07298725930802  cluster:  3\n",
      "test input:  117.66292270817354  cluster:  3\n",
      "test input:  115.93244639169285  cluster:  3\n",
      "test input:  116.14875030517578  cluster:  3\n",
      "output cluster  3\n",
      "test input:  115.7652922209658  cluster:  3\n",
      "test input:  117.38762033608452  cluster:  3\n",
      "test input:  114.75256832224021  cluster:  3\n",
      "test input:  117.28929901123047  cluster:  3\n",
      "output cluster  3\n",
      "test input:  118.26269118821175  cluster:  3\n",
      "test input:  120.101330692573  cluster:  3\n",
      "test input:  116.42405918528662  cluster:  3\n",
      "test input:  116.8370132446289  cluster:  3\n",
      "output cluster  3\n",
      "test input:  117.12216176246437  cluster:  3\n",
      "test input:  118.429849744653  cluster:  3\n",
      "test input:  116.14876031146906  cluster:  3\n",
      "test input:  117.70226287841797  cluster:  3\n",
      "output cluster  3\n",
      "test input:  118.20370284612696  cluster:  3\n",
      "test input:  118.8526295982356  cluster:  3\n",
      "test input:  116.30607200059802  cluster:  3\n",
      "test input:  116.61087036132812  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.24708561311698  cluster:  3\n",
      "test input:  116.33557255973454  cluster:  3\n",
      "test input:  113.14008057364323  cluster:  3\n",
      "test input:  113.3465576171875  cluster:  3\n",
      "output cluster  3\n",
      "test input:  113.07124905572665  cluster:  3\n",
      "test input:  116.99432768343188  cluster:  3\n",
      "test input:  112.73695505051217  cluster:  3\n",
      "test input:  116.6993637084961  cluster:  3\n",
      "output cluster  3\n",
      "test input:  116.13893055254357  cluster:  3\n",
      "test input:  116.35523447930362  cluster:  3\n",
      "test input:  113.4743827354878  cluster:  3\n",
      "test input:  113.87750244140625  cluster:  3\n",
      "output cluster  4\n",
      "test input:  115.43100546367818  cluster:  3\n",
      "test input:  115.70630819112931  cluster:  3\n",
      "test input:  114.23146572140966  cluster:  3\n",
      "test input:  115.5784912109375  cluster:  3\n",
      "output cluster  3\n",
      "test input:  114.87055614383104  cluster:  3\n",
      "test input:  117.96772657488931  cluster:  3\n",
      "test input:  114.49692461475543  cluster:  3\n",
      "test input:  117.46627807617188  cluster:  3\n",
      "output cluster  4\n",
      "test input:  117.59410124824689  cluster:  3\n",
      "test input:  119.57039219918884  cluster:  3\n",
      "test input:  116.84684565211819  cluster:  3\n",
      "test input:  118.73464965820312  cluster:  3\n",
      "output cluster  4\n",
      "test input:  120.52411843387392  cluster:  4\n",
      "test input:  121.05506257912789  cluster:  4\n",
      "test input:  117.98738779591704  cluster:  3\n",
      "test input:  118.04637908935547  cluster:  3\n",
      "output cluster  4\n",
      "test input:  119.45239028562871  cluster:  3\n",
      "test input:  120.44545285446344  cluster:  3\n",
      "test input:  118.51832650896431  cluster:  3\n",
      "test input:  119.04927062988281  cluster:  3\n",
      "output cluster  4\n",
      "test input:  118.24303925042986  cluster:  3\n",
      "test input:  119.74737737199894  cluster:  3\n",
      "test input:  117.75142509297922  cluster:  3\n",
      "test input:  118.44951629638672  cluster:  3\n",
      "output cluster  4\n",
      "test input:  118.92145332737842  cluster:  3\n",
      "test input:  120.22914869461998  cluster:  3\n",
      "test input:  118.43967358734486  cluster:  3\n",
      "test input:  119.65887451171875  cluster:  4\n",
      "output cluster  4\n",
      "test input:  120.219318456948  cluster:  4\n",
      "test input:  120.44546426190853  cluster:  3\n",
      "test input:  117.21064232155918  cluster:  3\n",
      "test input:  118.77397918701172  cluster:  3\n",
      "output cluster  4\n",
      "test input:  119.26558923989818  cluster:  3\n",
      "test input:  120.93707425751703  cluster:  4\n",
      "test input:  118.15453652100344  cluster:  3\n",
      "test input:  120.81908416748047  cluster:  4\n",
      "output cluster  4\n",
      "test input:  121.93996994438385  cluster:  4\n",
      "test input:  124.10307669600402  cluster:  4\n",
      "test input:  120.87808908601252  cluster:  4\n",
      "test input:  120.93708038330078  cluster:  4\n",
      "output cluster  4\n",
      "test input:  120.92724561025983  cluster:  4\n",
      "test input:  122.70689392089844  cluster:  4\n",
      "test input:  120.89774996171076  cluster:  4\n",
      "test input:  122.70689392089844  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.88676123170333  cluster:  4\n",
      "test input:  125.22395227050964  cluster:  4\n",
      "test input:  122.98219302940387  cluster:  4\n",
      "test input:  124.7126693725586  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.41771058750356  cluster:  4\n",
      "test input:  125.13546304919115  cluster:  4\n",
      "test input:  123.89660078619805  cluster:  4\n",
      "test input:  124.89949035644531  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.55825615149087  cluster:  4\n",
      "test input:  126.98393424543838  cluster:  4\n",
      "test input:  125.08631074859163  cluster:  4\n",
      "test input:  126.28585052490234  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.17769573716699  cluster:  4\n",
      "test input:  129.46167481978577  cluster:  4\n",
      "test input:  126.16786885471865  cluster:  4\n",
      "test input:  129.09788513183594  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.49811886179504  cluster:  4\n",
      "test input:  129.6386673786617  cluster:  4\n",
      "test input:  127.3182478111525  cluster:  4\n",
      "test input:  128.812744140625  cluster:  4\n",
      "output cluster  4\n",
      "test input:  130.77920651156137  cluster:  4\n",
      "test input:  133.0504767601541  cluster:  4\n",
      "test input:  129.34370142251362  cluster:  4\n",
      "test input:  131.85093688964844  cluster:  4\n",
      "output cluster  4\n",
      "test input:  131.94922430625925  cluster:  4\n",
      "test input:  133.23725087578447  cluster:  4\n",
      "test input:  128.80289699847398  cluster:  4\n",
      "test input:  129.20602416992188  cluster:  4\n",
      "output cluster  4\n",
      "test input:  129.08802215155023  cluster:  4\n",
      "test input:  129.18635097146097  cluster:  4\n",
      "test input:  126.88560061311607  cluster:  4\n",
      "test input:  128.37026977539062  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.4981252023258  cluster:  4\n",
      "test input:  128.9995662978012  cluster:  4\n",
      "test input:  127.93767779896346  cluster:  4\n",
      "test input:  128.34080505371094  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.38705742185483  cluster:  4\n",
      "test input:  127.78035774751314  cluster:  4\n",
      "test input:  125.26328817335677  cluster:  4\n",
      "test input:  126.00070190429688  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.61032218019211  cluster:  4\n",
      "test input:  129.33385397968271  cluster:  4\n",
      "test input:  126.36451508618849  cluster:  4\n",
      "test input:  128.812744140625  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.43620678982707  cluster:  4\n",
      "test input:  128.1932966998054  cluster:  4\n",
      "test input:  126.51196988725874  cluster:  4\n",
      "test input:  127.7213363647461  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.507926712545  cluster:  4\n",
      "test input:  129.14703406402748  cluster:  4\n",
      "test input:  126.8462686027115  cluster:  4\n",
      "test input:  129.10769653320312  cluster:  4\n",
      "output cluster  4\n",
      "test input:  129.6288189640089  cluster:  4\n",
      "test input:  130.1695975441542  cluster:  4\n",
      "test input:  127.77051802705405  cluster:  4\n",
      "test input:  128.163818359375  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.3407698898114  cluster:  4\n",
      "test input:  128.57675004807788  cluster:  4\n",
      "test input:  126.62994749883934  cluster:  4\n",
      "test input:  127.52468872070312  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.11465372050372  cluster:  4\n",
      "test input:  128.2818007353729  cluster:  4\n",
      "test input:  126.87577642943121  cluster:  4\n",
      "test input:  128.17364501953125  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.60338149476176  cluster:  4\n",
      "test input:  129.05855533671058  cluster:  4\n",
      "test input:  127.32807874095725  cluster:  4\n",
      "test input:  128.50794982910156  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.6623599533233  cluster:  4\n",
      "test input:  130.65138241226603  cluster:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  127.43622164321116  cluster:  4\n",
      "test input:  130.64154052734375  cluster:  4\n",
      "output cluster  4\n",
      "test input:  131.27079277993008  cluster:  4\n",
      "test input:  131.27079277993008  cluster:  4\n",
      "test input:  128.38011444794026  cluster:  4\n",
      "test input:  129.32400512695312  cluster:  4\n",
      "output cluster  4\n",
      "test input:  129.78612199873643  cluster:  4\n",
      "test input:  130.07125157459134  cluster:  4\n",
      "test input:  127.93764818753249  cluster:  4\n",
      "test input:  128.2817840576172  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.95037262554857  cluster:  4\n",
      "test input:  130.8185152101212  cluster:  4\n",
      "test input:  128.05564636436628  cluster:  4\n",
      "test input:  128.2326202392578  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.8294948841607  cluster:  4\n",
      "test input:  128.57675792970883  cluster:  4\n",
      "test input:  126.8856041989773  cluster:  4\n",
      "test input:  128.094970703125  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.88850709919315  cluster:  4\n",
      "test input:  128.43911252484853  cluster:  4\n",
      "test input:  126.55131606422756  cluster:  4\n",
      "test input:  127.07242584228516  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.21008605622697  cluster:  4\n",
      "test input:  128.6062684836031  cluster:  4\n",
      "test input:  126.83645449014263  cluster:  4\n",
      "test input:  128.12448120117188  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.10479298120543  cluster:  4\n",
      "test input:  128.61607583565043  cluster:  4\n",
      "test input:  127.16090232993777  cluster:  4\n",
      "test input:  127.86882781982422  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.62592760000837  cluster:  4\n",
      "test input:  128.82257025055546  cluster:  4\n",
      "test input:  127.14124333220197  cluster:  4\n",
      "test input:  127.69184875488281  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.2887291988085  cluster:  4\n",
      "test input:  129.26501247706608  cluster:  4\n",
      "test input:  127.2887291988085  cluster:  4\n",
      "test input:  128.27195739746094  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.1932965135712  cluster:  4\n",
      "test input:  128.4685992071867  cluster:  4\n",
      "test input:  127.072416974459  cluster:  4\n",
      "test input:  127.74100494384766  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.10479615993012  cluster:  4\n",
      "test input:  129.48132464791973  cluster:  4\n",
      "test input:  127.5148682389675  cluster:  4\n",
      "test input:  129.3731689453125  cluster:  4\n",
      "output cluster  5\n",
      "test input:  129.44201418912397  cluster:  4\n",
      "test input:  129.82547266894977  cluster:  4\n",
      "test input:  127.57388621107515  cluster:  4\n",
      "test input:  127.91802215576172  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.222811473599  cluster:  4\n",
      "test input:  131.33964351235483  cluster:  4\n",
      "test input:  128.0261688060917  cluster:  4\n",
      "test input:  130.31707763671875  cluster:  4\n",
      "output cluster  4\n",
      "test input:  130.80868568411924  cluster:  4\n",
      "test input:  131.0446658758067  cluster:  4\n",
      "test input:  129.60916096760914  cluster:  4\n",
      "test input:  129.63865661621094  cluster:  4\n",
      "output cluster  4\n",
      "test input:  130.39573156645633  cluster:  4\n",
      "test input:  130.39573156645633  cluster:  4\n",
      "test input:  129.22568749598324  cluster:  4\n",
      "test input:  129.62881469726562  cluster:  4\n",
      "output cluster  4\n",
      "test input:  130.30725681168443  cluster:  4\n",
      "test input:  132.8439878482079  cluster:  4\n",
      "test input:  129.91397145838795  cluster:  4\n",
      "test input:  132.16555786132812  cluster:  4\n",
      "output cluster  4\n",
      "test input:  132.38184900676927  cluster:  4\n",
      "test input:  132.57849165326388  cluster:  4\n",
      "test input:  131.0544848879043  cluster:  4\n",
      "test input:  132.558837890625  cluster:  4\n",
      "output cluster  4\n",
      "test input:  133.05045065993966  cluster:  4\n",
      "test input:  135.6265038095189  cluster:  5\n",
      "test input:  132.73581042643914  cluster:  5\n",
      "test input:  134.97756958007812  cluster:  5\n",
      "output cluster  4\n",
      "test input:  135.49868552683313  cluster:  5\n",
      "test input:  135.49868552683313  cluster:  5\n",
      "test input:  129.67797596712  cluster:  4\n",
      "test input:  131.02499389648438  cluster:  4\n",
      "output cluster  4\n",
      "test input:  131.8509251649317  cluster:  4\n",
      "test input:  131.89024769690033  cluster:  4\n",
      "test input:  126.44316934538809  cluster:  4\n",
      "test input:  128.1048126220703  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.6496356262907  cluster:  4\n",
      "test input:  127.30839679060644  cluster:  4\n",
      "test input:  124.06374788343896  cluster:  4\n",
      "test input:  124.31938934326172  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.05970252451341  cluster:  4\n",
      "test input:  127.74101445695631  cluster:  4\n",
      "test input:  124.8798241050189  cluster:  4\n",
      "test input:  127.02326202392578  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.37856507709994  cluster:  4\n",
      "test input:  127.37856507709994  cluster:  4\n",
      "test input:  123.09511151737557  cluster:  4\n",
      "test input:  123.28263854980469  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.4374015006882  cluster:  4\n",
      "test input:  125.1480223737881  cluster:  4\n",
      "test input:  123.11485542464185  cluster:  4\n",
      "test input:  124.06234741210938  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.5854400772681  cluster:  4\n",
      "test input:  126.48041638997361  cluster:  4\n",
      "test input:  124.5854400772681  cluster:  4\n",
      "test input:  125.33553314208984  cluster:  4\n",
      "output cluster  3\n",
      "test input:  126.34224824111872  cluster:  4\n",
      "test input:  127.21078819994013  cluster:  4\n",
      "test input:  125.63163490662423  cluster:  4\n",
      "test input:  126.49030303955078  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.4310904420175  cluster:  4\n",
      "test input:  128.16815534497633  cluster:  4\n",
      "test input:  125.48359091131643  cluster:  4\n",
      "test input:  125.64151000976562  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.80573545681976  cluster:  4\n",
      "test input:  123.80573545681976  cluster:  4\n",
      "test input:  121.97983174358966  cluster:  4\n",
      "test input:  122.81876373291016  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.37146379579615  cluster:  4\n",
      "test input:  123.85507782547663  cluster:  4\n",
      "test input:  120.20328550911968  cluster:  4\n",
      "test input:  120.85468292236328  cluster:  4\n",
      "output cluster  4\n",
      "test input:  118.74256370983923  cluster:  3\n",
      "test input:  121.2297366293302  cluster:  4\n",
      "test input:  118.13064607043798  cluster:  3\n",
      "test input:  120.45989990234375  cluster:  4\n",
      "output cluster  4\n",
      "test input:  120.51912110309394  cluster:  4\n",
      "test input:  121.74296396579349  cluster:  4\n",
      "test input:  118.69322486995414  cluster:  3\n",
      "test input:  121.7133560180664  cluster:  4\n",
      "output cluster  4\n",
      "test input:  122.10815082402121  cluster:  4\n",
      "test input:  122.10815082402121  cluster:  4\n",
      "test input:  118.04182434640043  cluster:  3\n",
      "test input:  118.17013549804688  cluster:  3\n",
      "output cluster  4\n",
      "test input:  118.01220876068403  cluster:  3\n",
      "test input:  120.67702940400933  cluster:  4\n",
      "test input:  117.6963781101418  cluster:  3\n",
      "test input:  119.71967315673828  cluster:  4\n",
      "output cluster  4\n",
      "test input:  119.57163226987387  cluster:  3\n",
      "test input:  122.4930678257135  cluster:  4\n",
      "test input:  119.11762615612822  cluster:  3\n",
      "test input:  122.41410827636719  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.22027025831392  cluster:  4\n",
      "test input:  124.69401250135054  cluster:  4\n",
      "test input:  122.36476600142564  cluster:  4\n",
      "test input:  123.73665618896484  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.68730878966576  cluster:  4\n",
      "test input:  124.71376039111497  cluster:  4\n",
      "test input:  116.47254715957274  cluster:  3\n",
      "test input:  119.79863739013672  cluster:  4\n",
      "output cluster  4\n",
      "test input:  120.48951573126409  cluster:  4\n",
      "test input:  122.79902606331302  cluster:  4\n",
      "test input:  119.71967895391445  cluster:  4\n",
      "test input:  121.1113052368164  cluster:  4\n",
      "output cluster  4\n",
      "test input:  122.3252780140924  cluster:  4\n",
      "test input:  122.94706749008424  cluster:  4\n",
      "test input:  121.26921856947327  cluster:  4\n",
      "test input:  122.30553436279297  cluster:  4\n",
      "output cluster  4\n",
      "test input:  121.06196374874368  cluster:  4\n",
      "test input:  123.04577163115705  cluster:  4\n",
      "test input:  120.66717352552804  cluster:  4\n",
      "test input:  121.93049621582031  cluster:  4\n",
      "output cluster  4\n",
      "test input:  122.57203056497873  cluster:  4\n",
      "test input:  123.36160348899908  cluster:  4\n",
      "test input:  121.10143715762085  cluster:  4\n",
      "test input:  123.24317169189453  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.36158862067342  cluster:  4\n",
      "test input:  124.15116897952576  cluster:  4\n",
      "test input:  121.48634091589633  cluster:  4\n",
      "test input:  121.96009063720703  cluster:  4\n",
      "output cluster  4\n",
      "test input:  121.77256739069796  cluster:  4\n",
      "test input:  123.17407294769967  cluster:  4\n",
      "test input:  120.58820434562256  cluster:  4\n",
      "test input:  121.3777847290039  cluster:  4\n",
      "output cluster  4\n",
      "test input:  122.12787306784708  cluster:  4\n",
      "test input:  123.26289200113487  cluster:  4\n",
      "test input:  121.71334677116691  cluster:  4\n",
      "test input:  122.97666931152344  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.37817894478002  cluster:  4\n",
      "test input:  124.70388143556232  cluster:  4\n",
      "test input:  123.09512016381478  cluster:  4\n",
      "test input:  123.4306869506836  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.17090878570775  cluster:  4\n",
      "test input:  125.66123818053008  cluster:  4\n",
      "test input:  123.61820703610333  cluster:  4\n",
      "test input:  124.73348236083984  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.21710392174032  cluster:  4\n",
      "test input:  125.28619164044088  cluster:  4\n",
      "test input:  123.70703087586264  cluster:  4\n",
      "test input:  124.73348236083984  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.64150749750296  cluster:  4\n",
      "test input:  126.6087356011744  cluster:  4\n",
      "test input:  125.35528478478474  cluster:  4\n",
      "test input:  125.98694610595703  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.8519256422511  cluster:  4\n",
      "test input:  126.76665323561268  cluster:  4\n",
      "test input:  124.50648703777784  cluster:  4\n",
      "test input:  126.73704528808594  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.98378441259635  cluster:  4\n",
      "test input:  128.20761970028312  cluster:  4\n",
      "test input:  126.21394015002477  cluster:  4\n",
      "test input:  127.1910400390625  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.02011075015423  cluster:  4\n",
      "test input:  128.40502912553774  cluster:  4\n",
      "test input:  125.73032908941593  cluster:  4\n",
      "test input:  125.81916046142578  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.84877248593205  cluster:  4\n",
      "test input:  129.37226140320752  cluster:  4\n",
      "test input:  125.84877248593205  cluster:  4\n",
      "test input:  127.30949401855469  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.77020646128366  cluster:  4\n",
      "test input:  132.29368780587936  cluster:  4\n",
      "test input:  126.33238501440923  cluster:  4\n",
      "test input:  130.64544677734375  cluster:  4\n",
      "output cluster  3\n",
      "test input:  131.43501616812173  cluster:  4\n",
      "test input:  131.43501616812173  cluster:  4\n",
      "test input:  128.28657411489993  cluster:  4\n",
      "test input:  128.3951416015625  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.8590239586106  cluster:  4\n",
      "test input:  128.8590239586106  cluster:  4\n",
      "test input:  125.76980521925239  cluster:  4\n",
      "test input:  127.43778228759766  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.0955130691105  cluster:  4\n",
      "test input:  126.6975589098762  cluster:  4\n",
      "test input:  124.92101427532829  cluster:  4\n",
      "test input:  125.720458984375  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.07576619267988  cluster:  4\n",
      "test input:  126.62847547973337  cluster:  4\n",
      "test input:  123.44055349100262  cluster:  4\n",
      "test input:  123.47016143798828  cluster:  4\n",
      "output cluster  4\n",
      "test input:  122.13776084828989  cluster:  4\n",
      "test input:  122.7595503745367  cluster:  4\n",
      "test input:  119.44332450789244  cluster:  4\n",
      "test input:  120.14408111572266  cluster:  4\n",
      "output cluster  4\n",
      "test input:  120.14407452963401  cluster:  4\n",
      "test input:  122.07853825746635  cluster:  4\n",
      "test input:  119.1768389007194  cluster:  4\n",
      "test input:  120.42042541503906  cluster:  4\n",
      "output cluster  4\n",
      "test input:  119.48279163628253  cluster:  3\n",
      "test input:  121.37778302377582  cluster:  4\n",
      "test input:  118.19973294380921  cluster:  3\n",
      "test input:  119.41370391845703  cluster:  3\n",
      "output cluster  4\n",
      "test input:  120.85468736545687  cluster:  4\n",
      "test input:  123.26290083688511  cluster:  4\n",
      "test input:  120.66716785399096  cluster:  4\n",
      "test input:  121.57518005371094  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.45042193145366  cluster:  4\n",
      "test input:  125.31579784036543  cluster:  4\n",
      "test input:  122.55227407086834  cluster:  4\n",
      "test input:  123.28263854980469  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.39791804235841  cluster:  4\n",
      "test input:  129.8163907442718  cluster:  4\n",
      "test input:  124.38804621663635  cluster:  4\n",
      "test input:  127.61544799804688  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.87207661949223  cluster:  4\n",
      "test input:  132.1061944930005  cluster:  4\n",
      "test input:  127.87207661949223  cluster:  4\n",
      "test input:  131.4745330810547  cluster:  4\n",
      "output cluster  4\n",
      "test input:  131.48437377815648  cluster:  4\n",
      "test input:  132.22460256835328  cluster:  4\n",
      "test input:  130.0927400381881  cluster:  4\n",
      "test input:  131.46463012695312  cluster:  4\n",
      "output cluster  4\n",
      "test input:  137.68256392618738  cluster:  5\n",
      "test input:  137.68256392618738  cluster:  5\n",
      "test input:  127.56610313591196  cluster:  4\n",
      "test input:  127.99049377441406  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.58584322306737  cluster:  4\n",
      "test input:  128.2865847368248  cluster:  4\n",
      "test input:  124.40779296125396  cluster:  4\n",
      "test input:  125.47371673583984  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.92772516546135  cluster:  4\n",
      "test input:  129.6091407296296  cluster:  4\n",
      "test input:  125.86850926855683  cluster:  4\n",
      "test input:  128.09906005859375  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.57280607513448  cluster:  4\n",
      "test input:  128.58267037042188  cluster:  4\n",
      "test input:  124.81243882162676  cluster:  4\n",
      "test input:  125.19735717773438  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.7895396572793  cluster:  4\n",
      "test input:  126.53964778471872  cluster:  4\n",
      "test input:  123.67742083000263  cluster:  4\n",
      "test input:  124.18077850341797  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.91114145867243  cluster:  4\n",
      "test input:  124.91114145867243  cluster:  4\n",
      "test input:  122.51279982055806  cluster:  4\n",
      "test input:  123.89456176757812  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.24987094358569  cluster:  4\n",
      "test input:  124.40779003536404  cluster:  4\n",
      "test input:  122.04892819440128  cluster:  4\n",
      "test input:  122.71019744873047  cluster:  4\n",
      "output cluster  4\n",
      "test input:  122.41409348796316  cluster:  4\n",
      "test input:  122.54240462264937  cluster:  4\n",
      "test input:  120.63754902227166  cluster:  4\n",
      "test input:  121.13103485107422  cluster:  4\n",
      "output cluster  4\n",
      "test input:  122.48320039721523  cluster:  4\n",
      "test input:  125.0493256031284  cluster:  4\n",
      "test input:  121.25935745839462  cluster:  4\n",
      "test input:  123.13460540771484  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.55900343361571  cluster:  4\n",
      "test input:  125.7106022828814  cluster:  4\n",
      "test input:  123.03590957856443  cluster:  4\n",
      "test input:  124.68415069580078  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.14801758637611  cluster:  4\n",
      "test input:  125.80928683410461  cluster:  4\n",
      "test input:  123.21354638138456  cluster:  4\n",
      "test input:  124.3683090209961  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.48674549513636  cluster:  4\n",
      "test input:  126.0560345106114  cluster:  4\n",
      "test input:  124.40779347705976  cluster:  4\n",
      "test input:  125.61189270019531  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.53293662088686  cluster:  4\n",
      "test input:  126.52977264557747  cluster:  4\n",
      "test input:  125.38488935553778  cluster:  4\n",
      "test input:  125.67111206054688  cluster:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output cluster  4\n",
      "test input:  125.31580465978924  cluster:  4\n",
      "test input:  125.84877030990926  cluster:  4\n",
      "test input:  124.6347917407475  cluster:  4\n",
      "test input:  125.46385192871094  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.36515355315213  cluster:  4\n",
      "test input:  126.60874011794877  cluster:  4\n",
      "test input:  124.78284381098372  cluster:  4\n",
      "test input:  126.32251739501953  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.67112490971718  cluster:  4\n",
      "test input:  128.70112059634536  cluster:  4\n",
      "test input:  125.67112490971718  cluster:  4\n",
      "test input:  128.21751403808594  cluster:  4\n",
      "output cluster  4\n",
      "test input:  128.0201058480406  cluster:  4\n",
      "test input:  128.30632101467643  cluster:  4\n",
      "test input:  126.57912053947886  cluster:  4\n",
      "test input:  127.6746597290039  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.69321397598378  cluster:  4\n",
      "test input:  125.86163531879284  cluster:  4\n",
      "test input:  122.12659990104062  cluster:  4\n",
      "test input:  123.74148559570312  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.70186565245588  cluster:  4\n",
      "test input:  125.82201554594131  cluster:  4\n",
      "test input:  123.52353493437634  cluster:  4\n",
      "test input:  124.13778686523438  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.29630147977348  cluster:  4\n",
      "test input:  127.76384497299333  cluster:  4\n",
      "test input:  124.2863921178301  cluster:  4\n",
      "test input:  127.36754608154297  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.30810817574616  cluster:  4\n",
      "test input:  128.00161235636492  cluster:  4\n",
      "test input:  126.11924170650583  cluster:  4\n",
      "test input:  127.45671081542969  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.69447337154152  cluster:  4\n",
      "test input:  128.45733542857738  cluster:  4\n",
      "test input:  122.92909120014275  cluster:  4\n",
      "test input:  124.93035125732422  cluster:  4\n",
      "output cluster  4\n",
      "test input:  124.58360304892561  cluster:  4\n",
      "test input:  125.18794558490684  cluster:  4\n",
      "test input:  123.47398891299017  cluster:  4\n",
      "test input:  123.83065032958984  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.40463636974444  cluster:  4\n",
      "test input:  124.80156148706202  cluster:  4\n",
      "test input:  122.85974245169633  cluster:  4\n",
      "test input:  124.50434112548828  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.54459944493837  cluster:  4\n",
      "test input:  126.91180397915399  cluster:  4\n",
      "test input:  122.75075688882171  cluster:  4\n",
      "test input:  122.88945770263672  cluster:  4\n",
      "output cluster  4\n",
      "test input:  123.63250288271223  cluster:  4\n",
      "test input:  127.17929060776761  cluster:  4\n",
      "test input:  123.49380206680307  cluster:  4\n",
      "test input:  126.10931396484375  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.71366416078469  cluster:  4\n",
      "test input:  127.11985727241003  cluster:  4\n",
      "test input:  125.53469959540621  cluster:  4\n",
      "test input:  125.92108154296875  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.65421604332315  cluster:  4\n",
      "test input:  128.26910181063616  cluster:  4\n",
      "test input:  126.11923146664151  cluster:  4\n",
      "test input:  127.30809783935547  cluster:  4\n",
      "output cluster  4\n",
      "test input:  127.00097249504299  cluster:  4\n",
      "test input:  128.43751995611177  cluster:  4\n",
      "test input:  126.76319317953107  cluster:  4\n",
      "test input:  127.40717315673828  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.63440421106277  cluster:  4\n",
      "test input:  127.37745513837375  cluster:  4\n",
      "test input:  123.12723860384385  cluster:  4\n",
      "test input:  126.86227416992188  cluster:  4\n",
      "output cluster  4\n",
      "test input:  125.85172456796622  cluster:  4\n",
      "test input:  129.17065749319715  cluster:  4\n",
      "test input:  125.56441357295617  cluster:  4\n",
      "test input:  128.69509887695312  cluster:  4\n",
      "output cluster  4\n",
      "test input:  129.27964758991047  cluster:  4\n",
      "test input:  129.52732871901557  cluster:  4\n",
      "test input:  126.75329704958716  cluster:  4\n",
      "test input:  126.76319885253906  cluster:  4\n",
      "output cluster  4\n",
      "test input:  126.79291596323438  cluster:  4\n",
      "test input:  127.54586864696103  cluster:  4\n",
      "test input:  126.40652648133484  cluster:  4\n",
      "test input:  127.42697143554688  cluster:  4\n",
      "output cluster  5\n",
      "test input:  127.88271621573789  cluster:  4\n",
      "test input:  128.021417036646  cluster:  4\n",
      "test input:  126.73347220406744  cluster:  4\n",
      "test input:  127.65485382080078  cluster:  4\n",
      "output cluster  5\n",
      "test input:  128.44742561377345  cluster:  4\n",
      "test input:  128.66538621355386  cluster:  4\n",
      "test input:  127.7043822374101  cluster:  4\n",
      "test input:  127.9421615600586  cluster:  4\n",
      "output cluster  5\n",
      "test input:  128.5762304043589  cluster:  4\n",
      "test input:  129.31927381405458  cluster:  4\n",
      "test input:  128.259206410529  cluster:  4\n",
      "test input:  128.93289184570312  cluster:  4\n",
      "output cluster  5\n",
      "test input:  128.79418326800393  cluster:  4\n",
      "test input:  131.6375577072449  cluster:  4\n",
      "test input:  128.27900230210025  cluster:  4\n",
      "test input:  131.50877380371094  cluster:  4\n",
      "output cluster  5\n",
      "test input:  132.48956963648268  cluster:  4\n",
      "test input:  132.68771149281838  cluster:  4\n",
      "test input:  129.48767591709597  cluster:  4\n",
      "test input:  130.7855224609375  cluster:  4\n",
      "output cluster  5\n",
      "test input:  131.0629346166964  cluster:  4\n",
      "test input:  131.80597797561407  cluster:  4\n",
      "test input:  130.31989125777875  cluster:  4\n",
      "test input:  130.74591064453125  cluster:  4\n",
      "output cluster  5\n",
      "test input:  131.12239117041628  cluster:  4\n",
      "test input:  135.22398991904186  cluster:  5\n",
      "test input:  130.69637178240802  cluster:  4\n",
      "test input:  134.1440887451172  cluster:  5\n",
      "output cluster  5\n",
      "test input:  133.68836452275607  cluster:  5\n",
      "test input:  135.61037244382732  cluster:  5\n",
      "test input:  133.42086467877812  cluster:  5\n",
      "test input:  135.53111267089844  cluster:  5\n",
      "output cluster  5\n",
      "test input:  134.17379251203863  cluster:  5\n",
      "test input:  137.84938653083464  cluster:  5\n",
      "test input:  134.17379251203863  cluster:  5\n",
      "test input:  137.52244567871094  cluster:  5\n",
      "output cluster  5\n",
      "test input:  136.92802738946776  cluster:  5\n",
      "test input:  140.5540672417956  cluster:  5\n",
      "test input:  136.71996861172738  cluster:  5\n",
      "test input:  139.5930633544922  cluster:  5\n",
      "output cluster  5\n",
      "test input:  139.6822558867676  cluster:  5\n",
      "test input:  141.35656763150425  cluster:  5\n",
      "test input:  139.55345686130457  cluster:  5\n",
      "test input:  140.60362243652344  cluster:  5\n",
      "output cluster  5\n",
      "test input:  140.75223249823182  cluster:  5\n",
      "test input:  142.16896123192578  cluster:  5\n",
      "test input:  140.68287452915303  cluster:  5\n",
      "test input:  141.1683349609375  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.8915620869331  cluster:  5\n",
      "test input:  141.94110133468172  cluster:  5\n",
      "test input:  139.48409372510503  cluster:  5\n",
      "test input:  140.81167602539062  cluster:  5\n",
      "output cluster  5\n",
      "test input:  140.12806636882394  cluster:  5\n",
      "test input:  141.1980505716535  cluster:  5\n",
      "test input:  138.08717645347042  cluster:  5\n",
      "test input:  138.7410430908203  cluster:  5\n",
      "output cluster  5\n",
      "test input:  140.8909360744884  cluster:  5\n",
      "test input:  141.6736017683292  cluster:  5\n",
      "test input:  138.9392076239638  cluster:  5\n",
      "test input:  140.94046020507812  cluster:  5\n",
      "output cluster  5\n",
      "test input:  142.05008363158586  cluster:  5\n",
      "test input:  142.96154835741288  cluster:  5\n",
      "test input:  140.18751673427286  cluster:  5\n",
      "test input:  142.33738708496094  cluster:  5\n",
      "output cluster  5\n",
      "test input:  142.7534757482125  cluster:  5\n",
      "test input:  143.06059789470035  cluster:  5\n",
      "test input:  139.1472395222418  cluster:  5\n",
      "test input:  140.0884246826172  cluster:  5\n",
      "output cluster  5\n",
      "test input:  139.9794486133257  cluster:  5\n",
      "test input:  140.21722791967218  cluster:  5\n",
      "test input:  137.9286568961373  cluster:  5\n",
      "test input:  139.11752319335938  cluster:  5\n",
      "output cluster  5\n",
      "test input:  139.2364026348016  cluster:  5\n",
      "test input:  141.49526820891327  cluster:  5\n",
      "test input:  138.42401647546075  cluster:  5\n",
      "test input:  140.98008728027344  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.40610349704804  cluster:  5\n",
      "test input:  141.98072552048842  cluster:  5\n",
      "test input:  139.18689029452642  cluster:  5\n",
      "test input:  139.82095336914062  cluster:  5\n",
      "output cluster  5\n",
      "test input:  139.18689859491727  cluster:  5\n",
      "test input:  142.3175767090658  cluster:  5\n",
      "test input:  136.2741659756511  cluster:  5\n",
      "test input:  139.8903045654297  cluster:  5\n",
      "output cluster  5\n",
      "test input:  140.0587090385049  cluster:  5\n",
      "test input:  142.0401579155796  cluster:  5\n",
      "test input:  137.67107463074385  cluster:  5\n",
      "test input:  137.74041748046875  cluster:  5\n",
      "output cluster  5\n",
      "test input:  136.8190566562894  cluster:  5\n",
      "test input:  136.8190566562894  cluster:  5\n",
      "test input:  132.965139035994  cluster:  5\n",
      "test input:  134.0153045654297  cluster:  5\n",
      "output cluster  5\n",
      "test input:  135.26361675726284  cluster:  5\n",
      "test input:  137.78006548979283  cluster:  5\n",
      "test input:  134.24317171669358  cluster:  5\n",
      "test input:  137.32432556152344  cluster:  5\n",
      "output cluster  5\n",
      "test input:  137.83949929022816  cluster:  5\n",
      "test input:  141.78257841771983  cluster:  5\n",
      "test input:  137.32431833695236  cluster:  5\n",
      "test input:  141.28721618652344  cluster:  5\n",
      "output cluster  5\n",
      "test input:  140.96026697864275  cluster:  5\n",
      "test input:  141.77266824612954  cluster:  5\n",
      "test input:  139.71195967193043  cluster:  5\n",
      "test input:  140.8413848876953  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.33674892020397  cluster:  5\n",
      "test input:  144.0513241470272  cluster:  5\n",
      "test input:  140.97017060627704  cluster:  5\n",
      "test input:  142.23831176757812  cluster:  5\n",
      "output cluster  5\n",
      "test input:  142.4860123620226  cluster:  5\n",
      "test input:  143.17951652515177  cluster:  5\n",
      "test input:  140.6333471695655  cluster:  5\n",
      "test input:  141.2674102783203  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.7726725795299  cluster:  5\n",
      "test input:  142.5057989857874  cluster:  5\n",
      "test input:  140.6036098862127  cluster:  5\n",
      "test input:  141.12869262695312  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.31695345412828  cluster:  5\n",
      "test input:  142.63461895929723  cluster:  5\n",
      "test input:  140.69279213134894  cluster:  5\n",
      "test input:  141.8024139404297  cluster:  5\n",
      "output cluster  5\n",
      "test input:  142.66432099513824  cluster:  5\n",
      "test input:  143.0507029264765  cluster:  5\n",
      "test input:  139.83084845957234  cluster:  5\n",
      "test input:  141.1485137939453  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.71323739043729  cluster:  5\n",
      "test input:  141.91139440040936  cluster:  5\n",
      "test input:  140.28660669253722  cluster:  5\n",
      "test input:  141.04945373535156  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.18813947533468  cluster:  5\n",
      "test input:  142.20858447509795  cluster:  5\n",
      "test input:  140.51445408868761  cluster:  5\n",
      "test input:  140.6729736328125  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.72315070306962  cluster:  5\n",
      "test input:  142.85257609177162  cluster:  5\n",
      "test input:  140.0785443126199  cluster:  5\n",
      "test input:  142.65443420410156  cluster:  5\n",
      "output cluster  5\n",
      "test input:  141.89154957411992  cluster:  5\n",
      "test input:  143.7640180827474  cluster:  5\n",
      "test input:  141.67358899705178  cluster:  5\n",
      "test input:  143.34791564941406  cluster:  5\n",
      "output cluster  5\n",
      "test input:  142.94173780804107  cluster:  5\n",
      "test input:  144.1207024490834  cluster:  5\n",
      "test input:  142.29777289319367  cluster:  5\n",
      "test input:  143.5361785888672  cluster:  5\n",
      "output cluster  5\n",
      "test input:  143.84329232499175  cluster:  5\n",
      "test input:  144.47735539920492  cluster:  5\n",
      "test input:  142.96154812620694  cluster:  5\n",
      "test input:  143.09033203125  cluster:  5\n",
      "output cluster  5\n",
      "test input:  142.10952230022465  cluster:  5\n",
      "test input:  142.10952230022465  cluster:  5\n",
      "test input:  138.71132946160643  cluster:  5\n",
      "test input:  140.306396484375  cluster:  5\n",
      "output cluster  5\n",
      "test input:  139.80114646323477  cluster:  5\n",
      "test input:  140.07854813699777  cluster:  5\n",
      "test input:  137.57201615225947  cluster:  5\n",
      "test input:  139.0382843017578  cluster:  5\n",
      "output cluster  5\n",
      "test input:  138.5131864165644  cluster:  5\n",
      "test input:  140.90083602920714  cluster:  5\n",
      "test input:  137.13608000114803  cluster:  5\n",
      "test input:  140.6729736328125  cluster:  5\n",
      "output cluster  5\n",
      "test input:  140.76213273777978  cluster:  5\n",
      "test input:  142.21849889970704  cluster:  5\n",
      "test input:  138.87974719814827  cluster:  5\n",
      "test input:  139.01846313476562  cluster:  5\n",
      "output cluster  5\n",
      "test input:  139.14724689663583  cluster:  5\n",
      "test input:  139.672329649218  cluster:  5\n",
      "test input:  136.52183313372507  cluster:  5\n",
      "test input:  137.0072784423828  cluster:  5\n",
      "output cluster  5\n",
      "test input:  138.38440314159146  cluster:  5\n",
      "test input:  141.52501338751335  cluster:  5\n",
      "test input:  138.10700146644024  cluster:  5\n",
      "test input:  140.55409240722656  cluster:  5\n",
      "output cluster  5\n",
      "test input:  140.2667784567097  cluster:  5\n",
      "test input:  140.89093973783156  cluster:  5\n",
      "test input:  137.84940822464142  cluster:  5\n",
      "test input:  139.3354949951172  cluster:  5\n",
      "output cluster  5\n",
      "test input:  138.80051107919985  cluster:  5\n",
      "test input:  139.64261784951302  cluster:  5\n",
      "test input:  135.2834360153156  cluster:  5\n",
      "test input:  135.44195556640625  cluster:  5\n",
      "output cluster  5\n",
      "test input:  136.35340750325418  cluster:  5\n",
      "test input:  138.85002217080066  cluster:  5\n",
      "test input:  134.31251760572195  cluster:  5\n",
      "test input:  136.719970703125  cluster:  5\n",
      "output cluster  5\n",
      "test input:  137.76024641643238  cluster:  5\n",
      "test input:  143.7640345403644  cluster:  5\n",
      "test input:  137.21534491138357  cluster:  5\n",
      "test input:  143.3578338623047  cluster:  5\n",
      "output cluster  5\n",
      "test input:  143.54607835919808  cluster:  5\n",
      "test input:  146.15168874351457  cluster:  5\n",
      "test input:  142.52563328979608  cluster:  5\n",
      "test input:  143.64515686035156  cluster:  5\n",
      "output cluster  5\n",
      "test input:  143.51635885339533  cluster:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  148.15294248903484  cluster:  6\n",
      "test input:  143.51635885339533  cluster:  5\n",
      "test input:  145.2897491455078  cluster:  5\n",
      "output cluster  5\n",
      "test input:  145.7157447481852  cluster:  5\n",
      "test input:  145.94360712451117  cluster:  5\n",
      "test input:  143.10023296950536  cluster:  5\n",
      "test input:  143.20921325683594  cluster:  5\n",
      "output cluster  5\n",
      "test input:  144.04425621511345  cluster:  5\n",
      "test input:  144.04425621511345  cluster:  5\n",
      "test input:  141.90695956410482  cluster:  5\n",
      "test input:  143.24899291992188  cluster:  5\n",
      "output cluster  6\n",
      "test input:  143.70626548679576  cluster:  5\n",
      "test input:  144.23313423729115  cluster:  5\n",
      "test input:  142.2250747299473  cluster:  5\n",
      "test input:  143.5670928955078  cluster:  5\n",
      "output cluster  6\n",
      "test input:  143.43786562208763  cluster:  5\n",
      "test input:  145.19741685084335  cluster:  5\n",
      "test input:  142.2549060993592  cluster:  5\n",
      "test input:  145.12783813476562  cluster:  5\n",
      "output cluster  6\n",
      "test input:  145.19741288290476  cluster:  5\n",
      "test input:  146.21139332906642  cluster:  5\n",
      "test input:  143.6267420486309  cluster:  5\n",
      "test input:  144.61090087890625  cluster:  5\n",
      "output cluster  6\n",
      "test input:  144.10391517234098  cluster:  5\n",
      "test input:  144.9091291214807  cluster:  5\n",
      "test input:  141.50932846473785  cluster:  5\n",
      "test input:  143.16946411132812  cluster:  5\n",
      "output cluster  6\n",
      "test input:  143.20922231410523  cluster:  5\n",
      "test input:  145.0284167018612  cluster:  5\n",
      "test input:  142.0262476710829  cluster:  5\n",
      "test input:  144.0840301513672  cluster:  5\n",
      "output cluster  6\n",
      "test input:  144.1436829463722  cluster:  5\n",
      "test input:  145.96287745483306  cluster:  5\n",
      "test input:  142.9408220903263  cluster:  5\n",
      "test input:  144.8793182373047  cluster:  5\n",
      "output cluster  6\n",
      "test input:  144.87930462883264  cluster:  5\n",
      "test input:  147.31483256094006  cluster:  6\n",
      "test input:  143.90508132104983  cluster:  5\n",
      "test input:  146.2511444091797  cluster:  6\n",
      "output cluster  6\n",
      "test input:  144.98865819542837  cluster:  5\n",
      "test input:  148.0703413917665  cluster:  6\n",
      "test input:  144.98865819542837  cluster:  5\n",
      "test input:  146.69850158691406  cluster:  6\n",
      "output cluster  6\n",
      "test input:  146.84761133170846  cluster:  6\n",
      "test input:  147.73235465269778  cluster:  6\n",
      "test input:  145.91316026194272  cluster:  6\n",
      "test input:  146.4599151611328  cluster:  6\n",
      "output cluster  6\n",
      "test input:  146.6488086336652  cluster:  6\n",
      "test input:  146.6488086336652  cluster:  5\n",
      "test input:  144.66061985402263  cluster:  5\n",
      "test input:  145.7044219970703  cluster:  6\n",
      "output cluster  6\n",
      "test input:  145.80379519757304  cluster:  5\n",
      "test input:  149.90940911736695  cluster:  6\n",
      "test input:  145.4658068084232  cluster:  6\n",
      "test input:  149.8298797607422  cluster:  6\n",
      "output cluster  6\n",
      "test input:  148.94514324222982  cluster:  6\n",
      "test input:  150.56552172310174  cluster:  6\n",
      "test input:  148.269151264771  cluster:  6\n",
      "test input:  149.9491729736328  cluster:  6\n",
      "output cluster  6\n",
      "test input:  149.7205501497957  cluster:  6\n",
      "test input:  149.9690737364484  cluster:  6\n",
      "test input:  146.27104155356224  cluster:  6\n",
      "test input:  146.57920837402344  cluster:  6\n",
      "output cluster  6\n",
      "test input:  146.42014771934825  cluster:  6\n",
      "test input:  148.2989854030747  cluster:  6\n",
      "test input:  146.14180251943884  cluster:  6\n",
      "test input:  146.5891571044922  cluster:  6\n",
      "output cluster  6\n",
      "test input:  147.2949412614942  cluster:  6\n",
      "test input:  150.62516302258484  cluster:  6\n",
      "test input:  146.81778027501014  cluster:  6\n",
      "test input:  149.95912170410156  cluster:  6\n",
      "output cluster  7\n",
      "test input:  150.1082418926275  cluster:  6\n",
      "test input:  151.4999678691949  cluster:  6\n",
      "test input:  149.8199612148655  cluster:  6\n",
      "test input:  151.20175170898438  cluster:  6\n",
      "output cluster  7\n",
      "test input:  150.8736947980747  cluster:  6\n",
      "test input:  152.07654039577267  cluster:  6\n",
      "test input:  150.44622636521726  cluster:  6\n",
      "test input:  151.75843811035156  cluster:  6\n",
      "output cluster  7\n",
      "test input:  151.7186715497909  cluster:  6\n",
      "test input:  151.78826543374478  cluster:  6\n",
      "test input:  149.17379249601868  cluster:  6\n",
      "test input:  149.88954162597656  cluster:  6\n",
      "output cluster  7\n",
      "test input:  150.9929790196095  cluster:  6\n",
      "test input:  152.81217336546922  cluster:  6\n",
      "test input:  150.65499060615136  cluster:  6\n",
      "test input:  152.6133575439453  cluster:  6\n",
      "output cluster  7\n",
      "test input:  153.29929342507285  cluster:  6\n",
      "test input:  155.43659016879732  cluster:  6\n",
      "test input:  152.90164659155215  cluster:  6\n",
      "test input:  155.17813110351562  cluster:  6\n",
      "output cluster  7\n",
      "test input:  155.4564782270026  cluster:  6\n",
      "test input:  156.3113999688104  cluster:  6\n",
      "test input:  154.77055070327967  cluster:  6\n",
      "test input:  155.16818237304688  cluster:  6\n",
      "output cluster  7\n",
      "test input:  155.46641581821504  cluster:  6\n",
      "test input:  157.09672995625309  cluster:  6\n",
      "test input:  154.8500821711141  cluster:  6\n",
      "test input:  156.997314453125  cluster:  7\n",
      "output cluster  7\n",
      "test input:  155.99327484959036  cluster:  6\n",
      "test input:  157.78264761316032  cluster:  7\n",
      "test input:  155.8441667729075  cluster:  7\n",
      "test input:  156.5102081298828  cluster:  7\n",
      "output cluster  7\n",
      "test input:  156.79847624530842  cluster:  6\n",
      "test input:  160.1784056766632  cluster:  7\n",
      "test input:  156.79847624530842  cluster:  7\n",
      "test input:  159.1047821044922  cluster:  7\n",
      "output cluster  7\n",
      "test input:  159.9696460101044  cluster:  7\n",
      "test input:  160.55615798123017  cluster:  7\n",
      "test input:  158.68727109284006  cluster:  7\n",
      "test input:  159.2240753173828  cluster:  7\n",
      "output cluster  7\n",
      "test input:  158.92585881385054  cluster:  6\n",
      "test input:  158.95568043084396  cluster:  7\n",
      "test input:  156.53010295954937  cluster:  7\n",
      "test input:  157.6931915283203  cluster:  7\n",
      "output cluster  7\n",
      "test input:  157.98146279423565  cluster:  6\n",
      "test input:  160.30763979305564  cluster:  7\n",
      "test input:  157.8820624664107  cluster:  7\n",
      "test input:  158.73696899414062  cluster:  7\n",
      "output cluster  7\n",
      "test input:  159.48255004484375  cluster:  6\n",
      "test input:  161.03334997987616  cluster:  7\n",
      "test input:  156.1622785406012  cluster:  7\n",
      "test input:  158.37911987304688  cluster:  7\n",
      "output cluster  7\n",
      "test input:  159.4427747197187  cluster:  6\n",
      "test input:  161.3812554560855  cluster:  7\n",
      "test input:  158.3393295053754  cluster:  7\n",
      "test input:  158.7767333984375  cluster:  7\n",
      "output cluster  7\n",
      "test input:  159.26385044645778  cluster:  6\n",
      "test input:  162.30577650048258  cluster:  7\n",
      "test input:  158.61768006660637  cluster:  7\n",
      "test input:  161.510498046875  cluster:  7\n",
      "output cluster  7\n",
      "test input:  161.84849619797595  cluster:  7\n",
      "test input:  161.8783178145215  cluster:  7\n",
      "test input:  158.6375757442738  cluster:  7\n",
      "test input:  159.0849151611328  cluster:  7\n",
      "output cluster  7\n",
      "test input:  158.84632732681453  cluster:  6\n",
      "test input:  159.91995103028432  cluster:  7\n",
      "test input:  157.7627681407048  cluster:  7\n",
      "test input:  159.85037231445312  cluster:  7\n",
      "output cluster  7\n",
      "test input:  160.21818094536462  cluster:  7\n",
      "test input:  160.51641227735428  cluster:  7\n",
      "test input:  157.77271739413587  cluster:  7\n",
      "test input:  158.7071533203125  cluster:  7\n",
      "output cluster  7\n",
      "test input:  159.8702412468642  cluster:  7\n",
      "test input:  161.03332967497613  cluster:  7\n",
      "test input:  158.45861409273775  cluster:  7\n",
      "test input:  160.9339141845703  cluster:  7\n",
      "output cluster  7\n",
      "test input:  160.61582005994057  cluster:  7\n",
      "test input:  161.361390769752  cluster:  7\n",
      "test input:  159.5322457668217  cluster:  7\n",
      "test input:  160.5859832763672  cluster:  7\n",
      "output cluster  7\n",
      "test input:  161.1227979657746  cluster:  7\n",
      "test input:  162.65369643756057  cluster:  7\n",
      "test input:  160.06906048707233  cluster:  7\n",
      "test input:  161.53038024902344  cluster:  7\n",
      "output cluster  7\n",
      "test input:  161.55025707181994  cluster:  7\n",
      "test input:  162.69347460273653  cluster:  7\n",
      "test input:  158.86620553144957  cluster:  7\n",
      "test input:  162.5741729736328  cluster:  7\n",
      "output cluster  7\n",
      "test input:  163.00163947934544  cluster:  7\n",
      "test input:  163.2799846628414  cluster:  7\n",
      "test input:  161.27190998018511  cluster:  7\n",
      "test input:  162.58412170410156  cluster:  7\n",
      "output cluster  7\n",
      "test input:  163.06129205235035  cluster:  7\n",
      "test input:  163.06129205235035  cluster:  7\n",
      "test input:  161.17251888916098  cluster:  7\n",
      "test input:  162.61395263671875  cluster:  7\n",
      "output cluster  7\n",
      "test input:  162.88235158984605  cluster:  7\n",
      "test input:  163.94602456700514  cluster:  7\n",
      "test input:  162.5145263966408  cluster:  7\n",
      "test input:  163.58815002441406  cluster:  7\n",
      "output cluster  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  164.77113005922683  cluster:  7\n",
      "test input:  165.80498145596957  cluster:  7\n",
      "test input:  162.46482400458305  cluster:  7\n",
      "test input:  162.56423950195312  cluster:  7\n",
      "output cluster  7\n",
      "test input:  160.35735298110308  cluster:  7\n",
      "test input:  160.90410789305065  cluster:  7\n",
      "test input:  158.1802839845054  cluster:  7\n",
      "test input:  158.78668212890625  cluster:  7\n",
      "output cluster  7\n",
      "test input:  157.93175680289178  cluster:  6\n",
      "test input:  159.46267052144242  cluster:  7\n",
      "test input:  155.7944601224405  cluster:  7\n",
      "test input:  157.42477416992188  cluster:  7\n",
      "output cluster  7\n",
      "test input:  157.82240685434348  cluster:  6\n",
      "test input:  160.86434817806722  cluster:  7\n",
      "test input:  157.82240685434348  cluster:  7\n",
      "test input:  159.94976806640625  cluster:  7\n",
      "output cluster  7\n",
      "test input:  160.75499937764556  cluster:  7\n",
      "test input:  163.96591978833536  cluster:  7\n",
      "test input:  160.42694643136323  cluster:  7\n",
      "test input:  163.38934326171875  cluster:  7\n",
      "output cluster  7\n",
      "test input:  163.23028313262344  cluster:  7\n",
      "test input:  163.89632450197718  cluster:  7\n",
      "test input:  162.14672397212303  cluster:  7\n",
      "test input:  162.78294372558594  cluster:  7\n",
      "output cluster  7\n",
      "test input:  163.14081004902948  cluster:  7\n",
      "test input:  163.55832781909842  cluster:  7\n",
      "test input:  160.91403343998712  cluster:  7\n",
      "test input:  160.98362731933594  cluster:  7\n",
      "output cluster  7\n",
      "test input:  159.293684715559  cluster:  6\n",
      "test input:  160.2281206664544  cluster:  7\n",
      "test input:  158.4984061987742  cluster:  7\n",
      "test input:  159.9895477294922  cluster:  7\n",
      "output cluster  7\n",
      "test input:  160.55616342212102  cluster:  7\n",
      "test input:  163.55833242711233  cluster:  7\n",
      "test input:  160.29770436727512  cluster:  7\n",
      "test input:  162.49465942382812  cluster:  7\n",
      "output cluster  7\n",
      "test input:  161.93794903312065  cluster:  7\n",
      "test input:  163.86649432625438  cluster:  7\n",
      "test input:  161.9180780693484  cluster:  7\n",
      "test input:  162.9022216796875  cluster:  7\n",
      "output cluster  7\n",
      "test input:  163.36945315050724  cluster:  7\n",
      "test input:  165.02958880647986  cluster:  7\n",
      "test input:  163.36945315050724  cluster:  7\n",
      "test input:  163.94602966308594  cluster:  7\n",
      "output cluster  7\n",
      "test input:  164.63195573582124  cluster:  7\n",
      "test input:  165.17871062826643  cluster:  7\n",
      "test input:  162.84258298267113  cluster:  7\n",
      "test input:  163.33963012695312  cluster:  7\n",
      "output cluster  8\n",
      "test input:  163.69750804309757  cluster:  7\n",
      "test input:  165.39741598570794  cluster:  7\n",
      "test input:  163.65775094495467  cluster:  7\n",
      "test input:  164.472900390625  cluster:  7\n",
      "output cluster  7\n",
      "test input:  164.73137657299608  cluster:  7\n",
      "test input:  165.20853759974807  cluster:  7\n",
      "test input:  163.95596904759523  cluster:  7\n",
      "test input:  164.99977111816406  cluster:  7\n",
      "output cluster  7\n",
      "test input:  166.16285684243897  cluster:  7\n",
      "test input:  166.85873499016375  cluster:  7\n",
      "test input:  165.12900544051905  cluster:  7\n",
      "test input:  166.47103881835938  cluster:  7\n",
      "output cluster  7\n",
      "test input:  167.20665918844387  cluster:  7\n",
      "test input:  167.66394924329242  cluster:  7\n",
      "test input:  163.29987584792667  cluster:  7\n",
      "test input:  163.4788055419922  cluster:  7\n",
      "output cluster  7\n",
      "test input:  164.6120575234482  cluster:  7\n",
      "test input:  166.351722400777  cluster:  7\n",
      "test input:  164.0255455767162  cluster:  7\n",
      "test input:  165.85467529296875  cluster:  7\n",
      "output cluster  8\n",
      "test input:  165.904401085466  cluster:  7\n",
      "test input:  167.75341713440557  cluster:  7\n",
      "test input:  165.25824584249258  cluster:  7\n",
      "test input:  167.06748962402344  cluster:  7\n",
      "output cluster  8\n",
      "test input:  167.6838211934984  cluster:  7\n",
      "test input:  169.39366462288095  cluster:  7\n",
      "test input:  166.6201481678371  cluster:  7\n",
      "test input:  169.22467041015625  cluster:  8\n",
      "output cluster  8\n",
      "test input:  169.90066617369422  cluster:  7\n",
      "test input:  169.99013102322425  cluster:  7\n",
      "test input:  167.63413230687863  cluster:  7\n",
      "test input:  167.90252685546875  cluster:  7\n",
      "output cluster  8\n",
      "test input:  168.4492699431548  cluster:  7\n",
      "test input:  169.34396388165203  cluster:  7\n",
      "test input:  167.79316408865844  cluster:  7\n",
      "test input:  167.96217346191406  cluster:  7\n",
      "output cluster  8\n",
      "test input:  168.40952693413595  cluster:  7\n",
      "test input:  168.53874888452205  cluster:  7\n",
      "test input:  167.43530355281217  cluster:  7\n",
      "test input:  168.12123107910156  cluster:  7\n",
      "output cluster  8\n",
      "test input:  169.09855622234835  cluster:  7\n",
      "test input:  169.09855622234835  cluster:  7\n",
      "test input:  167.62258816180614  cluster:  7\n",
      "test input:  167.90182495117188  cluster:  7\n",
      "output cluster  8\n",
      "test input:  169.79665759439408  cluster:  7\n",
      "test input:  172.5591237177392  cluster:  8\n",
      "test input:  169.47753633913933  cluster:  8\n",
      "test input:  172.47933959960938  cluster:  8\n",
      "output cluster  8\n",
      "test input:  172.02060214511602  cluster:  8\n",
      "test input:  174.6933016590056  cluster:  8\n",
      "test input:  171.04325809845662  cluster:  8\n",
      "test input:  174.68333435058594  cluster:  8\n",
      "output cluster  8\n",
      "test input:  175.12213223206143  cluster:  8\n",
      "test input:  177.0668225028629  cluster:  8\n",
      "test input:  174.59357577941446  cluster:  8\n",
      "test input:  175.81024169921875  cluster:  8\n",
      "output cluster  8\n",
      "test input:  175.7603907206823  cluster:  8\n",
      "test input:  177.89456637401443  cluster:  8\n",
      "test input:  175.24180157374934  cluster:  8\n",
      "test input:  176.86737060546875  cluster:  8\n",
      "output cluster  8\n",
      "test input:  177.60534956817068  cluster:  8\n",
      "test input:  180.03871188758438  cluster:  8\n",
      "test input:  176.16926589000755  cluster:  8\n",
      "test input:  179.30072021484375  cluster:  8\n",
      "output cluster  8\n",
      "test input:  177.76490847894786  cluster:  8\n",
      "test input:  178.31341474631878  cluster:  8\n",
      "test input:  174.78304001979575  cluster:  8\n",
      "test input:  175.3215789794922  cluster:  8\n",
      "output cluster  8\n",
      "test input:  176.33881469651217  cluster:  8\n",
      "test input:  178.7921116051398  cluster:  8\n",
      "test input:  175.41133765744738  cluster:  8\n",
      "test input:  178.29347229003906  cluster:  8\n",
      "output cluster  8\n",
      "test input:  178.4430539008776  cluster:  8\n",
      "test input:  179.2508623552967  cluster:  8\n",
      "test input:  177.77487906005462  cluster:  8\n",
      "test input:  178.21368408203125  cluster:  8\n",
      "output cluster  8\n",
      "test input:  178.51287106589533  cluster:  8\n",
      "test input:  179.14116145928298  cluster:  8\n",
      "test input:  177.1266544076496  cluster:  8\n",
      "test input:  177.4757080078125  cluster:  8\n",
      "output cluster  8\n",
      "test input:  178.4131442342196  cluster:  8\n",
      "test input:  178.81206482421192  cluster:  8\n",
      "test input:  176.86737450195105  cluster:  8\n",
      "test input:  177.31614685058594  cluster:  8\n",
      "output cluster  8\n",
      "test input:  178.10399264914054  cluster:  8\n",
      "test input:  178.44306374218115  cluster:  8\n",
      "test input:  176.69782608314512  cluster:  8\n",
      "test input:  177.58541870117188  cluster:  8\n",
      "output cluster  8\n",
      "test input:  178.02420525487094  cluster:  8\n",
      "test input:  178.22367315747428  cluster:  8\n",
      "test input:  176.49837014699511  cluster:  8\n",
      "test input:  176.62802124023438  cluster:  8\n",
      "output cluster  8\n",
      "test input:  177.19645649455026  cluster:  8\n",
      "test input:  177.81477958179494  cluster:  8\n",
      "test input:  176.16926074146312  cluster:  8\n",
      "test input:  176.3687286376953  cluster:  8\n",
      "output cluster  8\n",
      "test input:  176.06953792119882  cluster:  8\n",
      "test input:  176.22910614757285  cluster:  8\n",
      "test input:  174.70325590660875  cluster:  8\n",
      "test input:  175.3215789794922  cluster:  8\n",
      "output cluster  8\n",
      "test input:  177.40588788399975  cluster:  8\n",
      "test input:  177.40588788399975  cluster:  8\n",
      "test input:  175.32157928166149  cluster:  8\n",
      "test input:  175.5509490966797  cluster:  8\n",
      "output cluster  8\n",
      "test input:  176.01968562160263  cluster:  8\n",
      "test input:  177.56547060677508  cluster:  8\n",
      "test input:  175.46121200000186  cluster:  8\n",
      "test input:  177.39593505859375  cluster:  8\n",
      "output cluster  8\n",
      "test input:  177.79483912815132  cluster:  8\n",
      "test input:  177.9244902240891  cluster:  8\n",
      "test input:  175.21189103868096  cluster:  8\n",
      "test input:  175.88006591796875  cluster:  8\n",
      "output cluster  8\n",
      "test input:  176.5781476865649  cluster:  8\n",
      "test input:  176.76763305662053  cluster:  8\n",
      "test input:  174.79302567597568  cluster:  8\n",
      "test input:  175.68060302734375  cluster:  8\n",
      "output cluster  8\n",
      "test input:  173.8854990003732  cluster:  8\n",
      "test input:  174.8927449179806  cluster:  8\n",
      "test input:  173.0976555942864  cluster:  8\n",
      "test input:  173.60626220703125  cluster:  8\n",
      "output cluster  8\n",
      "test input:  173.9353721865714  cluster:  8\n",
      "test input:  175.43129015458726  cluster:  8\n",
      "test input:  173.7658366429347  cluster:  8\n",
      "test input:  175.2916717529297  cluster:  8\n",
      "output cluster  8\n",
      "test input:  175.30163881244164  cluster:  8\n",
      "test input:  180.4974672429076  cluster:  8\n",
      "test input:  175.30163881244164  cluster:  8\n",
      "test input:  179.16110229492188  cluster:  8\n",
      "output cluster  9\n",
      "test input:  179.61985910384627  cluster:  8\n",
      "test input:  180.50743649782456  cluster:  8\n",
      "test input:  177.88458876648065  cluster:  8\n",
      "test input:  178.60263061523438  cluster:  8\n",
      "output cluster  9\n",
      "test input:  178.88186544516478  cluster:  8\n",
      "test input:  178.88186544516478  cluster:  8\n",
      "test input:  175.77036094644592  cluster:  8\n",
      "test input:  177.5953826904297  cluster:  8\n",
      "output cluster  9\n",
      "test input:  177.2662736934026  cluster:  8\n",
      "test input:  179.01151126844314  cluster:  8\n",
      "test input:  176.74768455312807  cluster:  8\n",
      "test input:  178.163818359375  cluster:  8\n",
      "output cluster  9\n",
      "test input:  178.00426788990023  cluster:  8\n",
      "test input:  179.73952296454564  cluster:  8\n",
      "test input:  177.5953800000472  cluster:  8\n",
      "test input:  178.06410217285156  cluster:  8\n",
      "output cluster  9\n",
      "test input:  177.20644671042078  cluster:  8\n",
      "test input:  178.14389108124658  cluster:  8\n",
      "test input:  175.45122653789085  cluster:  8\n",
      "test input:  176.66790771484375  cluster:  8\n",
      "output cluster  9\n",
      "test input:  177.28622779476294  cluster:  8\n",
      "test input:  182.222754010988  cluster:  8\n",
      "test input:  176.13934823033773  cluster:  8\n",
      "test input:  180.40769958496094  cluster:  8\n",
      "output cluster  9\n",
      "test input:  180.8464973210673  cluster:  8\n",
      "test input:  186.5210149788226  cluster:  9\n",
      "test input:  180.8464973210673  cluster:  8\n",
      "test input:  185.77305603027344  cluster:  9\n",
      "output cluster  9\n",
      "test input:  187.0495768346238  cluster:  9\n",
      "test input:  187.69781707249513  cluster:  9\n",
      "test input:  184.62619707543968  cluster:  9\n",
      "test input:  184.8356170654297  cluster:  9\n",
      "output cluster  9\n",
      "test input:  185.5835700106464  cluster:  9\n",
      "test input:  187.96706524296863  cluster:  9\n",
      "test input:  185.16471482700032  cluster:  9\n",
      "test input:  187.2490234375  cluster:  9\n",
      "output cluster  9\n",
      "test input:  186.6008068277143  cluster:  9\n",
      "test input:  187.0396118638147  cluster:  9\n",
      "test input:  183.94804199475422  cluster:  9\n",
      "test input:  186.07225036621094  cluster:  9\n",
      "output cluster  9\n",
      "test input:  185.42401426377967  cluster:  9\n",
      "test input:  187.5681725167725  cluster:  9\n",
      "test input:  184.73590476971577  cluster:  9\n",
      "test input:  185.18467712402344  cluster:  9\n",
      "output cluster  9\n",
      "test input:  185.26445305444952  cluster:  9\n",
      "test input:  185.55365715796054  cluster:  9\n",
      "test input:  183.64885134617995  cluster:  9\n",
      "test input:  185.0251007080078  cluster:  9\n",
      "output cluster  9\n",
      "test input:  185.3841231339796  cluster:  9\n",
      "test input:  187.0196594715367  cluster:  9\n",
      "test input:  184.04777342760357  cluster:  9\n",
      "test input:  186.17196655273438  cluster:  9\n",
      "output cluster  9\n",
      "test input:  186.0423294282474  cluster:  9\n",
      "test input:  187.63796608837768  cluster:  9\n",
      "test input:  185.28438793871624  cluster:  9\n",
      "test input:  186.22183227539062  cluster:  9\n",
      "output cluster  9\n",
      "test input:  187.7875699357906  cluster:  9\n",
      "test input:  188.42582765323436  cluster:  9\n",
      "test input:  186.52102180903375  cluster:  9\n",
      "test input:  187.91720581054688  cluster:  9\n",
      "output cluster  9\n",
      "test input:  188.67514431837148  cluster:  9\n",
      "test input:  189.0241827045798  cluster:  9\n",
      "test input:  187.20914353141  cluster:  9\n",
      "test input:  188.15655517578125  cluster:  9\n",
      "output cluster  9\n",
      "test input:  187.61803233985728  cluster:  9\n",
      "test input:  189.93171083378562  cluster:  9\n",
      "test input:  187.14931016935301  cluster:  9\n",
      "test input:  188.8446807861328  cluster:  9\n",
      "output cluster  9\n",
      "test input:  189.48293422287406  cluster:  9\n",
      "test input:  190.17105889244564  cluster:  9\n",
      "test input:  186.99970502773826  cluster:  9\n",
      "test input:  188.16651916503906  cluster:  9\n",
      "output cluster  9\n",
      "test input:  188.82472876843326  cluster:  9\n",
      "test input:  189.7920902395799  cluster:  9\n",
      "test input:  187.0495740562241  cluster:  9\n",
      "test input:  188.2064208984375  cluster:  9\n",
      "output cluster  9\n",
      "test input:  188.30615277777653  cluster:  9\n",
      "test input:  188.51557276235513  cluster:  9\n",
      "test input:  187.34875862505436  cluster:  9\n",
      "test input:  188.16651916503906  cluster:  9\n",
      "output cluster  9\n",
      "test input:  188.26625470351945  cluster:  9\n",
      "test input:  189.53280279854948  cluster:  9\n",
      "test input:  187.16924214605032  cluster:  9\n",
      "test input:  188.34603881835938  cluster:  9\n",
      "output cluster  9\n",
      "test input:  188.8147616194381  cluster:  9\n",
      "test input:  189.8718745144227  cluster:  9\n",
      "test input:  188.17650391582868  cluster:  9\n",
      "test input:  188.80479431152344  cluster:  9\n",
      "output cluster  9\n",
      "test input:  189.4031573285035  cluster:  9\n",
      "test input:  190.3505689922792  cluster:  9\n",
      "test input:  187.29889879112636  cluster:  9\n",
      "test input:  189.57269287109375  cluster:  9\n",
      "output cluster  9\n",
      "test input:  189.68238674537452  cluster:  9\n",
      "test input:  190.94893482866794  cluster:  9\n",
      "test input:  189.4829340687549  cluster:  9\n",
      "test input:  190.47024536132812  cluster:  9\n",
      "output cluster  9\n",
      "test input:  190.7794061474417  cluster:  9\n",
      "test input:  191.7567349500782  cluster:  9\n",
      "test input:  189.49290818508288  cluster:  9\n",
      "test input:  191.64703369140625  cluster:  9\n",
      "output cluster  9\n",
      "test input:  191.2082318010347  cluster:  9\n",
      "test input:  191.31793306151067  cluster:  9\n",
      "test input:  188.97433735827326  cluster:  9\n",
      "test input:  189.4729766845703  cluster:  9\n",
      "output cluster  9\n",
      "test input:  189.67243132226528  cluster:  9\n",
      "test input:  189.67243132226528  cluster:  9\n",
      "test input:  186.2417902872978  cluster:  9\n",
      "test input:  186.38140869140625  cluster:  9\n",
      "output cluster  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input:  184.0078735866732  cluster:  9\n",
      "test input:  188.95438226135917  cluster:  9\n",
      "test input:  182.9108762297336  cluster:  9\n",
      "test input:  187.50833129882812  cluster:  9\n",
      "output cluster  9\n",
      "test input:  188.02690408581765  cluster:  9\n",
      "test input:  189.25356774332522  cluster:  9\n",
      "test input:  186.7902883376016  cluster:  9\n",
      "test input:  188.15655517578125  cluster:  9\n",
      "output cluster  9\n",
      "test input:  188.7748707916347  cluster:  9\n",
      "test input:  191.08856458633528  cluster:  9\n",
      "test input:  188.7748707916347  cluster:  9\n",
      "test input:  190.02146911621094  cluster:  9\n",
      "output cluster  9\n",
      "test input:  190.83924602215973  cluster:  9\n",
      "test input:  191.4775037593336  cluster:  9\n",
      "test input:  190.2209381191283  cluster:  9\n",
      "test input:  190.34060668945312  cluster:  9\n",
      "output cluster  9\n",
      "test input:  190.39046343114532  cluster:  9\n",
      "test input:  191.56724488878424  cluster:  9\n",
      "test input:  189.5228206911386  cluster:  9\n",
      "test input:  191.10850524902344  cluster:  9\n",
      "output cluster  9\n",
      "test input:  190.77940084448542  cluster:  9\n",
      "test input:  191.28800745659203  cluster:  9\n",
      "test input:  189.45301846914361  cluster:  9\n",
      "test input:  190.64974975585938  cluster:  9\n",
      "output cluster  9\n",
      "test input:  190.6896492110566  cluster:  9\n",
      "test input:  192.98337783419942  cluster:  9\n",
      "test input:  190.6896492110566  cluster:  9\n",
      "test input:  192.95346069335938  cluster:  9\n",
      "output cluster  9\n",
      "test input:  193.83107957406142  cluster:  9\n",
      "test input:  195.14747948282846  cluster:  9\n",
      "test input:  193.06317075054295  cluster:  9\n",
      "test input:  193.57179260253906  cluster:  9\n",
      "output cluster  9\n",
      "test input:  194.12027792780975  cluster:  9\n",
      "test input:  195.65609552927558  cluster:  9\n",
      "test input:  193.44213576828966  cluster:  9\n",
      "test input:  195.24720764160156  cluster:  9\n",
      "output cluster  9\n",
      "test input:  196.04503055885766  cluster:  9\n",
      "test input:  197.85010240431896  cluster:  9\n",
      "test input:  194.04050603527747  cluster:  9\n",
      "test input:  197.42127990722656  cluster:  9\n",
      "output cluster  9\n",
      "test input:  197.9697722227201  cluster:  9\n",
      "test input:  198.38862741460414  cluster:  9\n",
      "test input:  195.50649282831358  cluster:  9\n",
      "test input:  197.3714141845703  cluster:  9\n",
      "output cluster  9\n",
      "test input:  197.51104133976258  cluster:  9\n",
      "test input:  199.12662789684745  cluster:  9\n",
      "test input:  197.28167150916448  cluster:  9\n",
      "test input:  197.98973083496094  cluster:  9\n",
      "output cluster  9\n",
      "test input:  199.1465716513535  cluster:  9\n",
      "test input:  199.1465716513535  cluster:  9\n",
      "test input:  194.52916673439134  cluster:  9\n",
      "test input:  195.93533325195312  cluster:  9\n",
      "output cluster  9\n",
      "test input:  195.76579107308106  cluster:  9\n",
      "test input:  198.0794694985081  cluster:  9\n",
      "test input:  195.76579107308106  cluster:  9\n",
      "test input:  197.88998413085938  cluster:  9\n",
      "output cluster  9\n",
      "test input:  197.86000061035156  cluster:  9\n",
      "test input:  199.8800048828125  cluster:  9\n",
      "test input:  197.52000427246094  cluster:  9\n",
      "test input:  197.94000244140625  cluster:  9\n",
      "output cluster  9\n",
      "test input:  198.63999938964844  cluster:  9\n",
      "test input:  198.7899932861328  cluster:  9\n",
      "test input:  195.9600067138672  cluster:  9\n",
      "test input:  196.0399932861328  cluster:  9\n",
      "output cluster  9\n",
      "test input:  196.64999389648438  cluster:  9\n",
      "test input:  198.0  cluster:  9\n",
      "test input:  192.97000122070312  cluster:  9\n",
      "test input:  194.32000732421875  cluster:  9\n",
      "output cluster  9\n",
      "test input:  194.5800018310547  cluster:  9\n",
      "test input:  196.57000732421875  cluster:  9\n",
      "test input:  194.5800018310547  cluster:  9\n",
      "test input:  195.5500030517578  cluster:  9\n",
      "output cluster  9\n",
      "test input:  195.58999633789062  cluster:  9\n",
      "test input:  197.13999938964844  cluster:  9\n",
      "test input:  194.5  cluster:  9\n",
      "test input:  195.83999633789062  cluster:  9\n",
      "output cluster  9\n",
      "test input:  196.0  cluster:  9\n",
      "test input:  196.4600067138672  cluster:  9\n",
      "test input:  194.55999755859375  cluster:  9\n",
      "test input:  195.42999267578125  cluster:  9\n",
      "output cluster  9\n",
      "test input:  194.86000061035156  cluster:  9\n",
      "test input:  194.91000366210938  cluster:  9\n",
      "test input:  191.0  cluster:  9\n",
      "test input:  192.89999389648438  cluster:  9\n",
      "output cluster  9\n",
      "test input:  189.6699981689453  cluster:  9\n",
      "test input:  192.11000061035156  cluster:  9\n",
      "test input:  188.50999450683594  cluster:  9\n",
      "test input:  190.97999572753906  cluster:  9\n",
      "output cluster  9\n",
      "\n",
      "predicted vs actual output\n",
      "  76.32    70.58\n",
      "  76.32    69.91\n",
      "  76.32    69.38\n",
      "  76.32    69.16\n",
      "  76.32    69.72\n",
      "  76.32    69.62\n",
      "  76.32    68.07\n",
      "  76.32    68.05\n",
      "  76.32    68.58\n",
      "  76.32    68.55\n",
      "  76.32    67.60\n",
      "  76.32    67.46\n",
      "  76.32    67.51\n",
      "  76.32    67.57\n",
      "  76.32    67.80\n",
      "  76.32    67.58\n",
      "  76.32    68.29\n",
      "  76.32    67.57\n",
      "  76.32    67.17\n",
      "  76.32    67.21\n",
      "  76.32    67.88\n",
      "  76.32    68.81\n",
      "  76.32    68.66\n",
      "  76.32    70.38\n",
      "  76.32    70.90\n",
      "  76.32    70.86\n",
      "  76.32    70.90\n",
      "  76.32    70.88\n",
      "  76.32    71.76\n",
      "  76.32    72.08\n",
      "  76.32    72.02\n",
      "  76.32    72.09\n",
      "  76.32    72.08\n",
      "  76.32    73.11\n",
      "  76.32    73.32\n",
      "  76.32    73.88\n",
      "  76.32    73.97\n",
      "  76.32    73.66\n",
      "  76.32    73.27\n",
      "  76.32    73.09\n",
      "  76.32    72.60\n",
      "  76.32    73.52\n",
      "  76.32    73.93\n",
      "  76.32    73.98\n",
      "  76.32    72.99\n",
      "  76.32    72.65\n",
      "  76.32    72.69\n",
      "  76.32    72.18\n",
      "  76.32    71.38\n",
      "  76.32    70.38\n",
      "  76.32    70.71\n",
      "  76.32    71.36\n",
      "  76.32    71.40\n",
      "  76.32    71.59\n",
      "  76.32    71.90\n",
      "  76.32    72.05\n",
      "  76.32    71.97\n",
      "  76.32    72.83\n",
      "  76.32    73.80\n",
      "  76.32    74.28\n",
      "  76.32    74.99\n",
      "  76.32    75.18\n",
      "  76.32    76.18\n",
      "  76.32    75.46\n",
      "  76.32    76.37\n",
      "  76.32    75.42\n",
      "  76.32    75.46\n",
      "  76.32    74.87\n",
      "  76.32    75.09\n",
      "  76.32    75.62\n",
      "  76.32    75.22\n",
      "  76.32    76.12\n",
      "  76.32    76.13\n",
      "  76.32    76.30\n",
      "  76.32    76.57\n",
      "  76.32    76.76\n",
      "  76.32    75.88\n",
      "  76.32    76.31\n",
      "  76.32    75.34\n",
      "  76.32    72.65\n",
      "  76.32    72.89\n",
      "  76.32    72.46\n",
      "  76.32    70.53\n",
      "  76.32    71.38\n",
      "  76.32    72.74\n",
      "  76.32    73.62\n",
      "  76.32    74.80\n",
      "  76.32    75.38\n",
      "  76.32    74.11\n",
      "  76.32    73.90\n",
      "  76.32    74.20\n",
      "  76.32    73.34\n",
      "  76.32    75.48\n",
      "  76.32    76.58\n",
      "  76.32    76.61\n",
      "  76.32    75.73\n",
      "  76.32    74.65\n",
      "  76.32    75.58\n",
      "  76.32    76.68\n",
      "  76.32    78.69\n",
      "  76.32    78.73\n",
      "  76.32    79.58\n",
      "  76.32    81.15\n",
      "  76.32    80.55\n",
      "  76.32    79.95\n",
      "  76.32    79.12\n",
      "  76.32    79.21\n",
      "  76.32    79.10\n",
      "  76.32    78.77\n",
      "  86.79    79.27\n",
      "  76.32    79.33\n",
      "  76.32    77.27\n",
      "  76.32    76.04\n",
      "  76.32    78.66\n",
      "  76.32    77.17\n",
      "  76.32    78.65\n",
      "  76.32    81.22\n",
      "  76.32    80.57\n",
      "  76.32    81.63\n",
      "  76.32    81.22\n",
      "  76.32    81.31\n",
      "  76.32    80.26\n",
      "  76.32    80.35\n",
      "  86.79    80.97\n",
      "  76.32    80.78\n",
      "  86.79    81.60\n",
      "  86.79    80.95\n",
      "  86.79    81.00\n",
      "  76.32    80.92\n",
      "  86.79    80.69\n",
      "  86.79    81.90\n",
      "  86.79    82.35\n",
      "  86.79    81.91\n",
      "  86.79    81.25\n",
      "  86.79    82.70\n",
      "  86.79    83.05\n",
      "  86.79    83.65\n",
      "  86.79    83.20\n",
      "  86.79    83.85\n",
      "  86.79    82.82\n",
      "  86.79    81.03\n",
      "  86.79    82.62\n",
      "  86.79    83.52\n",
      "  86.79    83.24\n",
      "  86.79    84.87\n",
      "  86.79    85.13\n",
      "  86.79    85.29\n",
      "  86.79    85.16\n",
      "  86.79    84.74\n",
      "  86.79    85.01\n",
      "  86.79    85.32\n",
      "  86.79    84.85\n",
      "  86.79    85.92\n",
      "  86.79    86.21\n",
      "  86.79    86.57\n",
      "  86.79    87.24\n",
      "  86.79    87.40\n",
      "  86.79    86.86\n",
      "  86.79    88.03\n",
      "  86.79    86.54\n",
      "  86.79    86.75\n",
      "  86.79    87.71\n",
      "  86.79    87.89\n",
      "  86.79    89.37\n",
      "  86.79    89.71\n",
      "  86.79    89.62\n",
      "  86.79    89.60\n",
      "  86.79    89.80\n",
      "  86.79    89.79\n",
      "  86.79    89.69\n",
      "  86.79    89.83\n",
      "  86.79    89.16\n",
      "  86.79    88.95\n",
      "  86.79    88.86\n",
      "  86.79    89.09\n",
      "  86.79    88.59\n",
      "  86.79    86.95\n",
      "  86.79    86.74\n",
      "  86.79    86.24\n",
      "  86.79    86.65\n",
      "  86.79    86.38\n",
      "  86.79    86.76\n",
      "  86.79    85.31\n",
      "  86.79    85.49\n",
      "  86.79    85.28\n",
      "  86.79    86.29\n",
      "  86.79    85.90\n",
      "  86.79    86.48\n",
      "  86.79    88.37\n",
      "  86.79    88.12\n",
      "  86.79    88.86\n",
      "  86.79    89.39\n",
      "  86.79    90.47\n",
      "  86.79    89.91\n",
      "  86.79    89.91\n",
      "  86.79    90.39\n",
      "  86.79    90.13\n",
      "  86.79    89.07\n",
      "  86.79    89.02\n",
      "  86.79    90.55\n",
      "  86.79    87.55\n",
      "  86.79    86.50\n",
      "  86.79    86.49\n",
      "  86.79    86.83\n",
      "  86.79    86.59\n",
      "  86.79    87.01\n",
      "  86.79    88.35\n",
      "  86.79    87.98\n",
      "  86.79    87.85\n",
      "  86.79    87.18\n",
      "  86.79    87.07\n",
      "  86.79    87.60\n",
      "  86.79    87.17\n",
      "  86.79    87.72\n",
      "  86.79    88.06\n",
      "  86.79    88.17\n",
      "  86.79    87.57\n",
      "  86.79    87.88\n",
      "  86.79    88.31\n",
      "  86.79    89.65\n",
      "  86.79    89.93\n",
      "  86.79    90.00\n",
      "  86.79    89.77\n",
      "  86.79    89.44\n",
      "  86.79    90.33\n",
      "  86.79    91.56\n",
      "  86.79    89.44\n",
      "  86.79    88.09\n",
      "  86.79    88.16\n",
      "  86.79    88.40\n",
      "  86.79    88.74\n",
      "  86.79    86.62\n",
      "  94.64    87.35\n",
      "  86.79    86.28\n",
      "  86.79    84.75\n",
      "  86.79    85.68\n",
      "  86.79    85.56\n",
      "  86.79    85.45\n",
      "  86.79    86.11\n",
      "  86.79    85.48\n",
      "  86.79    83.38\n",
      "  86.79    81.71\n",
      "  86.79    82.21\n",
      "  86.79    81.60\n",
      "  86.79    82.86\n",
      "  86.79    81.71\n",
      "  86.79    81.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  86.79    81.62\n",
      "  86.79    81.34\n",
      "  86.79    80.78\n",
      "  86.79    80.31\n",
      "  86.79    77.95\n",
      "  86.79    75.75\n",
      "  86.79    76.10\n",
      "  86.79    76.09\n",
      "  86.79    77.92\n",
      "  86.79    76.68\n",
      "  76.32    76.04\n",
      "  76.32    76.76\n",
      "  76.32    77.04\n",
      "  76.32    77.65\n",
      "  76.32    77.50\n",
      "  76.32    79.49\n",
      "  76.32    79.42\n",
      "  76.32    79.96\n",
      "  76.32    81.62\n",
      "  76.32    82.46\n",
      "  76.32    82.74\n",
      "  76.32    82.74\n",
      "  76.32    84.41\n",
      "  76.32    85.22\n",
      "  76.32    86.31\n",
      "  76.32    86.86\n",
      "  86.79    85.97\n",
      "  86.79    84.26\n",
      "  86.79    84.31\n",
      "  86.79    81.68\n",
      "  86.79    83.76\n",
      "  86.79    84.39\n",
      "  86.79    84.63\n",
      "  86.79    83.15\n",
      "  86.79    82.98\n",
      "  86.79    83.55\n",
      "  86.79    85.05\n",
      "  86.79    85.08\n",
      "  86.79    85.52\n",
      "  86.79    85.96\n",
      "  86.79    86.84\n",
      "  86.79    88.11\n",
      "  86.79    85.97\n",
      "  86.79    85.48\n",
      "  86.79    83.08\n",
      "  86.79    82.83\n",
      "  86.79    83.03\n",
      "  86.79    83.20\n",
      "  86.79    83.17\n",
      "  86.79    82.72\n",
      "  86.79    81.48\n",
      "  86.79    80.04\n",
      "  86.79    79.34\n",
      "  86.79    77.43\n",
      "  86.79    76.00\n",
      "  86.79    73.36\n",
      "  86.79    75.77\n",
      "  86.79    77.12\n",
      "  76.32    76.97\n",
      "  76.32    77.96\n",
      "  76.32    77.42\n",
      "  76.32    75.34\n",
      "  76.32    78.33\n",
      "  76.32    76.28\n",
      "  76.32    76.06\n",
      "  76.32    76.44\n",
      "  76.32    76.99\n",
      "  76.32    77.13\n",
      "  76.32    76.97\n",
      "  76.32    77.46\n",
      "  76.32    79.29\n",
      "  76.32    78.80\n",
      "  76.32    79.47\n",
      "  76.32    79.71\n",
      "  76.32    80.99\n",
      "  76.32    81.23\n",
      "  76.32    81.90\n",
      "  76.32    82.27\n",
      "  76.32    82.02\n",
      "  76.32    82.86\n",
      "  76.32    84.15\n",
      "  86.79    83.52\n",
      "  86.79    83.12\n",
      "  86.79    82.97\n",
      "  86.79    83.09\n",
      "  86.79    82.98\n",
      "  86.79    83.21\n",
      "  86.79    82.87\n",
      "  86.79    83.70\n",
      "  86.79    84.10\n",
      "  86.79    83.31\n",
      "  86.79    83.88\n",
      "  86.79    83.94\n",
      "  86.79    84.19\n",
      "  86.79    84.18\n",
      "  86.79    85.10\n",
      "  86.79    86.16\n",
      "  86.79    87.07\n",
      "  86.79    86.79\n",
      "  86.79    87.52\n",
      "  86.79    87.92\n",
      "  86.79    86.17\n",
      "  86.79    84.82\n",
      "  86.79    83.80\n",
      "  86.79    82.17\n",
      "  86.79    79.75\n",
      "  86.79    80.31\n",
      "  86.79    80.12\n",
      "  86.79    81.29\n",
      "  86.79    80.70\n",
      "  86.79    80.27\n",
      "  86.79    80.94\n",
      "  76.32    80.84\n",
      "  86.79    80.09\n",
      "  76.32    81.04\n",
      "  86.79    80.60\n",
      "  86.79    81.58\n",
      "  86.79    82.45\n",
      "  86.79    82.72\n",
      "  86.79    83.34\n",
      "  86.79    84.06\n",
      "  86.79    84.93\n",
      "  86.79    85.52\n",
      "  86.79    85.80\n",
      "  86.79    85.68\n",
      "  86.79    85.11\n",
      "  86.79    85.28\n",
      "  86.79    84.26\n",
      "  86.79    84.07\n",
      "  86.79    83.62\n",
      "  86.79    84.36\n",
      "  86.79    85.00\n",
      "  86.79    86.23\n",
      "  86.79    86.66\n",
      "  86.79    86.46\n",
      "  86.79    86.21\n",
      "  86.79    86.13\n",
      "  86.79    85.68\n",
      "  86.79    85.93\n",
      "  86.79    86.33\n",
      "  86.79    87.86\n",
      "  86.79    88.58\n",
      "  86.79    88.70\n",
      "  86.79    88.64\n",
      "  86.79    88.51\n",
      "  86.79    89.09\n",
      "  86.79    87.33\n",
      "  86.79    87.42\n",
      "  86.79    87.58\n",
      "  86.79    88.88\n",
      "  86.79    87.33\n",
      "  86.79    87.59\n",
      "  86.79    87.20\n",
      "  86.79    87.36\n",
      "  86.79    86.76\n",
      "  86.79    86.72\n",
      "  86.79    87.70\n",
      "  86.79    86.82\n",
      "  86.79    86.49\n",
      "  86.79    86.50\n",
      "  86.79    86.44\n",
      "  86.79    86.80\n",
      "  86.79    87.09\n",
      "  86.79    87.08\n",
      "  86.79    87.15\n",
      "  86.79    89.12\n",
      "  86.79    92.41\n",
      "  86.79    92.13\n",
      "  86.79    92.39\n",
      "  86.79    92.88\n",
      "  86.79    91.52\n",
      "  86.79    91.71\n",
      "  86.79    92.15\n",
      "  94.64    92.41\n",
      "  94.64    91.89\n",
      "  94.64    92.60\n",
      "  94.64    93.18\n",
      "  94.64    94.37\n",
      "  94.64    94.90\n",
      "  94.64    93.53\n",
      "  94.64    94.62\n",
      "  94.64    91.35\n",
      "  94.64    92.85\n",
      "  94.64    92.85\n",
      "  94.64    93.80\n",
      "  94.64    96.22\n",
      "  94.64    97.92\n",
      "  94.64    97.57\n",
      "  94.64    97.36\n",
      "  94.64    98.11\n",
      "  94.64    99.47\n",
      "  94.64    100.42\n",
      "  94.64    100.69\n",
      "  94.64    100.63\n",
      "  94.64    99.73\n",
      "  94.64    99.10\n",
      "  94.64    99.58\n",
      "  94.64    98.22\n",
      "  94.64    98.27\n",
      "  94.64    97.38\n",
      "  94.64    94.83\n",
      "  94.64    94.25\n",
      "  94.64    94.68\n",
      "  94.64    93.34\n",
      "  94.64    93.46\n",
      "  94.64    93.05\n",
      "  94.64    94.28\n",
      "  94.64    94.57\n",
      "  94.64    91.11\n",
      "  94.64    92.55\n",
      "  94.64    92.81\n",
      "  94.64    94.87\n",
      "  94.64    95.14\n",
      "  94.64    93.25\n",
      "  94.64    94.55\n",
      "  94.64    92.03\n",
      "  94.64    93.64\n",
      "  86.79    94.17\n",
      "  94.64    95.99\n",
      "  94.64    95.50\n",
      "  94.64    95.90\n",
      "  94.64    96.68\n",
      "  94.64    94.16\n",
      "  94.64    95.27\n",
      "  94.64    94.88\n",
      "  94.64    95.13\n",
      "  94.64    96.33\n",
      "  94.64    96.40\n",
      "  94.64    96.10\n",
      "  94.64    96.47\n",
      "  94.64    98.50\n",
      "  94.64    100.67\n",
      "  94.64    99.29\n",
      "  94.64    94.77\n",
      "  94.64    94.80\n",
      "  94.64    96.05\n",
      "  94.64    96.55\n",
      "  94.64    96.32\n",
      "  94.64    99.67\n",
      "  94.64    99.56\n",
      "  94.64    98.65\n",
      "  94.64    97.68\n",
      "  94.64    97.26\n",
      "  94.64    98.35\n",
      "  94.64    99.69\n",
      "  94.64    98.78\n",
      "  94.64    97.09\n",
      "  94.64    96.39\n",
      "  94.64    95.65\n",
      "  94.64    92.88\n",
      "  94.64    94.24\n",
      "  94.64    96.27\n",
      "  94.64    96.06\n",
      "  94.64    94.18\n",
      "  94.64    94.43\n",
      "  94.64    95.62\n",
      "  94.64    96.35\n",
      "  94.64    95.42\n",
      "  94.64    95.00\n",
      "  94.64    95.13\n",
      "  94.64    95.40\n",
      "  94.64    95.68\n",
      "  94.64    95.23\n",
      "  94.64    94.94\n",
      "  94.64    98.29\n",
      "  94.64    97.98\n",
      "  94.64    95.49\n",
      "  94.64    95.78\n",
      "  94.64    95.70\n",
      "  94.64    97.08\n",
      "  94.64    96.79\n",
      "  94.64    96.27\n",
      "  94.64    95.65\n",
      "  94.64    95.48\n",
      "  94.64    96.94\n",
      "  94.64    97.53\n",
      "  94.64    97.66\n",
      "  94.64    99.47\n",
      "  94.64    99.39\n",
      "  94.64    100.19\n",
      "  94.64    100.18\n",
      "  94.64    100.50\n",
      "  94.64    101.48\n",
      "  94.64    101.94\n",
      "  94.64    102.55\n",
      "  94.64    101.62\n",
      "  94.64    101.26\n",
      "  94.64    101.52\n",
      "  94.64    101.70\n",
      "  94.64    101.14\n",
      "  94.64    101.67\n",
      "  94.64    101.34\n",
      "  94.64    101.36\n",
      "  94.64    102.07\n",
      "  94.64    101.55\n",
      "  94.64    102.09\n",
      "  94.64    101.52\n",
      "  94.64    101.49\n",
      "  94.64    100.79\n",
      "  94.64    101.48\n",
      "  94.64    101.82\n",
      "  94.64    102.53\n",
      "  94.64    103.31\n",
      "  94.64    103.23\n",
      "  94.64    104.30\n",
      "  94.64    104.86\n",
      "  94.64    104.45\n",
      "  94.64    103.98\n",
      "  94.64    105.05\n",
      "  94.64    105.24\n",
      "  94.64    104.30\n",
      "  94.64    104.38\n",
      "  112.95    105.08\n",
      "  112.95    105.53\n",
      "  112.95    105.46\n",
      "  112.95    103.71\n",
      "  112.95    103.14\n",
      "  112.95    104.62\n",
      "  112.95    104.12\n",
      "  112.95    104.37\n",
      "  112.95    103.84\n",
      "  112.95    105.12\n",
      "  112.95    105.56\n",
      "  94.64    106.53\n",
      "  112.95    106.47\n",
      "  112.95    106.37\n",
      "  112.95    106.84\n",
      "  94.64    107.41\n",
      "  112.95    106.99\n",
      "  112.95    108.31\n",
      "  112.95    112.41\n",
      "  112.95    113.01\n",
      "  112.95    113.50\n",
      "  112.95    114.80\n",
      "  112.95    115.65\n",
      "  112.95    113.51\n",
      "  112.95    112.91\n",
      "  112.95    111.42\n",
      "  112.95    112.79\n",
      "  112.95    111.88\n",
      "  112.95    111.16\n",
      "  112.95    111.49\n",
      "  112.95    113.25\n",
      "  112.95    112.73\n",
      "  112.95    112.34\n",
      "  112.95    111.58\n",
      "  112.95    112.25\n",
      "  112.95    111.82\n",
      "  112.95    109.55\n",
      "  112.95    110.15\n",
      "  112.95    104.72\n",
      "  112.95    99.94\n",
      "  112.95    107.32\n",
      "  112.95    107.27\n",
      "  112.95    113.41\n",
      "  112.95    111.20\n",
      "  112.95    107.69\n",
      "  112.95    103.03\n",
      "  94.64    102.04\n",
      "  112.95    96.80\n",
      "  112.95    86.79\n",
      "  112.95    94.05\n",
      "  112.95    83.54\n",
      "  112.95    93.05\n",
      "  112.95    89.67\n",
      "  112.95    86.17\n",
      "  94.64    78.83\n",
      "  86.79    71.35\n",
      "  86.79    81.26\n",
      "  86.79    85.15\n",
      "  94.64    91.87\n",
      "  94.64    90.85\n",
      "  86.79    97.37\n",
      "  76.32    92.98\n",
      "  76.32    90.35\n",
      "  86.79    92.01\n",
      "  86.79    93.24\n",
      "  94.64    99.48\n",
      "  94.64    98.84\n",
      "  94.64    101.97\n",
      "  94.64    105.68\n",
      "  86.79    101.14\n",
      "  94.64    105.32\n",
      "  94.64    103.80\n",
      "  94.64    106.06\n",
      "  112.95    108.93\n",
      "  94.64    107.50\n",
      "  112.95    103.08\n",
      "  112.95    102.46\n",
      "  112.95    101.69\n",
      "  112.95    103.43\n",
      "  112.95    109.31\n",
      "  112.95    108.90\n",
      "  112.95    109.28\n",
      "  112.95    107.39\n",
      "  112.95    104.40\n",
      "  112.95    103.92\n",
      "  94.64    106.57\n",
      "  112.95    103.43\n",
      "  112.95    105.10\n",
      "  112.95    105.35\n",
      "  112.95    106.97\n",
      "  112.95    106.24\n",
      "  94.64    106.63\n",
      "  112.95    107.20\n",
      "  112.95    109.75\n",
      "  112.95    112.55\n",
      "  112.95    110.29\n",
      "  112.95    112.33\n",
      "  112.95    111.62\n",
      "  112.95    112.94\n",
      "  112.95    113.86\n",
      "  112.95    112.80\n",
      "  112.95    113.95\n",
      "  112.95    116.00\n",
      "  112.95    116.41\n",
      "  112.95    116.76\n",
      "  112.95    116.86\n",
      "  112.95    115.48\n",
      "  112.95    117.41\n",
      "  112.95    118.78\n",
      "  112.95    117.59\n",
      "  112.95    117.52\n",
      "  112.95    111.35\n",
      "  112.95    113.22\n",
      "  112.95    115.40\n",
      "  112.95    116.54\n",
      "  112.95    116.15\n",
      "  112.95    117.29\n",
      "  112.95    116.84\n",
      "  112.95    117.70\n",
      "  112.95    116.61\n",
      "  112.95    113.35\n",
      "  112.95    116.70\n",
      "  112.95    113.88\n",
      "  112.95    115.58\n",
      "  112.95    117.47\n",
      "  112.95    118.73\n",
      "  112.95    118.05\n",
      "  112.95    119.05\n",
      "  112.95    118.45\n",
      "  112.95    119.66\n",
      "  112.95    118.77\n",
      "  112.95    120.82\n",
      "  112.95    120.94\n",
      "  112.95    122.71\n",
      "  112.95    124.71\n",
      "  112.95    124.90\n",
      "  112.95    126.29\n",
      "  112.95    129.10\n",
      "  128.65    128.81\n",
      "  128.65    131.85\n",
      "  128.65    129.21\n",
      "  128.65    128.37\n",
      "  128.65    128.34\n",
      "  128.65    126.00\n",
      "  128.65    128.81\n",
      "  128.65    127.72\n",
      "  128.65    129.11\n",
      "  128.65    128.16\n",
      "  128.65    127.52\n",
      "  128.65    128.17\n",
      "  128.65    128.51\n",
      "  128.65    130.64\n",
      "  128.65    129.32\n",
      "  128.65    128.28\n",
      "  128.65    128.23\n",
      "  128.65    128.09\n",
      "  128.65    127.07\n",
      "  128.65    128.12\n",
      "  128.65    127.87\n",
      "  128.65    127.69\n",
      "  128.65    128.27\n",
      "  128.65    127.74\n",
      "  128.65    129.37\n",
      "  128.65    127.92\n",
      "  128.65    130.32\n",
      "  128.65    129.64\n",
      "  128.65    129.63\n",
      "  128.65    132.17\n",
      "  128.65    132.56\n",
      "  128.65    134.98\n",
      "  128.65    131.02\n",
      "  128.65    128.10\n",
      "  128.65    124.32\n",
      "  128.65    127.02\n",
      "  128.65    123.28\n",
      "  128.65    124.06\n",
      "  141.74    125.34\n",
      "  128.65    126.49\n",
      "  128.65    125.64\n",
      "  128.65    122.82\n",
      "  128.65    120.85\n",
      "  128.65    120.46\n",
      "  128.65    121.71\n",
      "  128.65    118.17\n",
      "  128.65    119.72\n",
      "  128.65    122.41\n",
      "  128.65    123.74\n",
      "  128.65    119.80\n",
      "  128.65    121.11\n",
      "  112.95    122.31\n",
      "  112.95    121.93\n",
      "  128.65    123.24\n",
      "  128.65    121.96\n",
      "  128.65    121.38\n",
      "  112.95    122.98\n",
      "  128.65    123.43\n",
      "  128.65    124.73\n",
      "  128.65    124.73\n",
      "  128.65    125.99\n",
      "  128.65    126.74\n",
      "  128.65    127.19\n",
      "  128.65    125.82\n",
      "  128.65    127.31\n",
      "  128.65    130.65\n",
      "  128.65    128.40\n",
      "  128.65    127.44\n",
      "  128.65    125.72\n",
      "  128.65    123.47\n",
      "  128.65    120.14\n",
      "  128.65    120.42\n",
      "  128.65    119.41\n",
      "  128.65    121.58\n",
      "  128.65    123.28\n",
      "  128.65    127.62\n",
      "  128.65    131.47\n",
      "  128.65    131.46\n",
      "  128.65    127.99\n",
      "  128.65    125.47\n",
      "  128.65    128.10\n",
      "  128.65    125.20\n",
      "  128.65    124.18\n",
      "  128.65    123.89\n",
      "  128.65    122.71\n",
      "  128.65    121.13\n",
      "  128.65    123.13\n",
      "  128.65    124.68\n",
      "  128.65    124.37\n",
      "  128.65    125.61\n",
      "  128.65    125.67\n",
      "  128.65    125.46\n",
      "  128.65    126.32\n",
      "  128.65    128.22\n",
      "  128.65    127.67\n",
      "  128.65    123.74\n",
      "  128.65    124.14\n",
      "  128.65    127.37\n",
      "  128.65    127.46\n",
      "  128.65    124.93\n",
      "  128.65    123.83\n",
      "  128.65    124.50\n",
      "  128.65    122.89\n",
      "  128.65    126.11\n",
      "  128.65    125.92\n",
      "  128.65    127.31\n",
      "  128.65    127.41\n",
      "  128.65    126.86\n",
      "  128.65    128.70\n",
      "  128.65    126.76\n",
      "  128.65    127.43\n",
      "  128.65    127.65\n",
      "  128.65    127.94\n",
      "  128.65    128.93\n",
      "  128.65    131.51\n",
      "  128.65    130.79\n",
      "  128.65    130.75\n",
      "  128.65    134.14\n",
      "  128.65    135.53\n",
      "  128.65    137.52\n",
      "  128.65    139.59\n",
      "  128.65    140.60\n",
      "  128.65    141.17\n",
      "  128.65    140.81\n",
      "  141.74    138.74\n",
      "  141.74    140.94\n",
      "  141.74    142.34\n",
      "  141.74    140.09\n",
      "  141.74    139.12\n",
      "  141.74    140.98\n",
      "  141.74    139.82\n",
      "  141.74    139.89\n",
      "  141.74    137.74\n",
      "  141.74    134.02\n",
      "  141.74    137.32\n",
      "  141.74    141.29\n",
      "  141.74    140.84\n",
      "  141.74    142.24\n",
      "  141.74    141.27\n",
      "  141.74    141.13\n",
      "  141.74    141.80\n",
      "  141.74    141.15\n",
      "  141.74    141.05\n",
      "  141.74    140.67\n",
      "  141.74    142.65\n",
      "  141.74    143.35\n",
      "  141.74    143.54\n",
      "  141.74    143.09\n",
      "  141.74    140.31\n",
      "  141.74    139.04\n",
      "  141.74    140.67\n",
      "  141.74    139.02\n",
      "  141.74    137.01\n",
      "  141.74    140.55\n",
      "  141.74    139.34\n",
      "  141.74    135.44\n",
      "  141.74    136.72\n",
      "  141.74    143.36\n",
      "  141.74    143.65\n",
      "  141.74    145.29\n",
      "  141.74    143.21\n",
      "  141.74    143.25\n",
      "  141.74    143.57\n",
      "  141.74    145.13\n",
      "  141.74    144.61\n",
      "  141.74    143.17\n",
      "  146.97    144.08\n",
      "  141.74    144.88\n",
      "  141.74    146.25\n",
      "  141.74    146.70\n",
      "  141.74    146.46\n",
      "  141.74    145.70\n",
      "  141.74    149.83\n",
      "  141.74    149.95\n",
      "  141.74    146.58\n",
      "  146.97    146.59\n",
      "  146.97    149.96\n",
      "  146.97    151.20\n",
      "  146.97    151.76\n",
      "  146.97    149.89\n",
      "  146.97    152.61\n",
      "  146.97    155.18\n",
      "  146.97    155.17\n",
      "  146.97    157.00\n",
      "  146.97    156.51\n",
      "  146.97    159.10\n",
      "  146.97    159.22\n",
      "  146.97    157.69\n",
      "  146.97    158.74\n",
      "  146.97    158.38\n",
      "  146.97    158.78\n",
      "  160.05    161.51\n",
      "  160.05    159.08\n",
      "  160.05    159.85\n",
      "  160.05    158.71\n",
      "  160.05    160.93\n",
      "  160.05    160.59\n",
      "  160.05    161.53\n",
      "  160.05    162.57\n",
      "  160.05    162.58\n",
      "  160.05    162.61\n",
      "  160.05    163.59\n",
      "  160.05    162.56\n",
      "  160.05    158.79\n",
      "  160.05    157.42\n",
      "  160.05    159.95\n",
      "  160.05    163.39\n",
      "  160.05    162.78\n",
      "  160.05    160.98\n",
      "  160.05    159.99\n",
      "  160.05    162.49\n",
      "  160.05    162.90\n",
      "  160.05    163.95\n",
      "  160.05    163.34\n",
      "  160.05    164.47\n",
      "  160.05    165.00\n",
      "  160.05    166.47\n",
      "  160.05    163.48\n",
      "  160.05    165.85\n",
      "  160.05    167.07\n",
      "  160.05    169.22\n",
      "  160.05    167.90\n",
      "  160.05    167.96\n",
      "  160.05    168.12\n",
      "  160.05    167.90\n",
      "  160.05    172.48\n",
      "  160.05    174.68\n",
      "  160.05    175.81\n",
      "  160.05    176.87\n",
      "  160.05    179.30\n",
      "  160.05    175.32\n",
      "  160.05    178.29\n",
      "  175.75    178.21\n",
      "  175.75    177.48\n",
      "  175.75    177.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  175.75    177.59\n",
      "  175.75    176.63\n",
      "  175.75    176.37\n",
      "  175.75    175.32\n",
      "  175.75    175.55\n",
      "  175.75    177.40\n",
      "  175.75    175.88\n",
      "  175.75    175.68\n",
      "  175.75    173.61\n",
      "  175.75    175.29\n",
      "  175.75    179.16\n",
      "  175.75    178.60\n",
      "  175.75    177.60\n",
      "  175.75    178.16\n",
      "  175.75    178.06\n",
      "  175.75    176.67\n",
      "  175.75    180.41\n",
      "  175.75    185.77\n",
      "  175.75    184.84\n",
      "  175.75    187.25\n",
      "  175.75    186.07\n",
      "  175.75    185.18\n",
      "  175.75    185.03\n",
      "  175.75    186.17\n",
      "  188.83    186.22\n",
      "  188.83    187.92\n",
      "  188.83    188.16\n",
      "  188.83    188.84\n",
      "  188.83    188.17\n",
      "  188.83    188.21\n",
      "  188.83    188.17\n",
      "  188.83    188.35\n",
      "  188.83    188.80\n",
      "  188.83    189.57\n",
      "  188.83    190.47\n",
      "  188.83    191.65\n",
      "  188.83    189.47\n",
      "  188.83    186.38\n",
      "  188.83    187.51\n",
      "  188.83    188.16\n",
      "  188.83    190.02\n",
      "  188.83    190.34\n",
      "  188.83    191.11\n",
      "  188.83    190.65\n",
      "  188.83    192.95\n",
      "  188.83    193.57\n",
      "  188.83    195.25\n",
      "  188.83    197.42\n",
      "  188.83    197.37\n",
      "  188.83    197.99\n",
      "  188.83    195.94\n",
      "  188.83    197.89\n",
      "  188.83    197.94\n",
      "  188.83    196.04\n",
      "  188.83    194.32\n",
      "  188.83    195.55\n",
      "  188.83    195.84\n",
      "  188.83    195.43\n",
      "  188.83    192.90\n",
      "  188.83    190.98\n",
      "  188.83    191.90\n",
      "  188.83    194.50\n",
      "  188.83    195.58\n",
      "  188.83    196.78\n",
      "  188.83    195.78\n",
      "  188.83    190.96\n",
      "  188.83    193.99\n",
      "RMSE =  29.533341478754803\n",
      "Testing Set R-Square= 0.972248166333808\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## here\n",
    "fuzzyinput_col_names=['var1cluster1','var1cluster2','var1cluster3','var1cluster4','var1cluster5','var1cluster6','var1cluster7','var1cluster8','var1cluster9','var1cluster10',\n",
    "                      'var2cluster1','var2cluster2','var2cluster3','var2cluster4','var2cluster5','var2cluster6','var2cluster7','var2cluster8','var2cluster9','var2cluster10',\n",
    "                      'var3cluster1','var3cluster2','var3cluster3','var3cluster4','var3cluster5','var3cluster6','var3cluster7','var3cluster8','var3cluster9','var3cluster10',\n",
    "                      'var4cluster1','var4cluster2','var4cluster3','var4cluster4','var4cluster5','var4cluster6','var4cluster7','var4cluster8','var4cluster9','var4cluster10',\n",
    "                     'outputvalue']\n",
    "x=[]\n",
    "f = open(\"cluster_dct.txt\", \"w\")\n",
    "f.write(str(num_input))\n",
    "f.write(str(output_cluster))\n",
    "f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "fd = open(\"mf_dct.txt\", \"w\")\n",
    "fd.close()\n",
    "\n",
    "for i in range(num_var):\n",
    "    initNN(i)\n",
    "\n",
    "with open('mf_dct.txt', 'r') as f:\n",
    "    i = f.read().split()\n",
    "    for elem in i:\n",
    "        try:\n",
    "            x.append(float(elem))\n",
    "        except ValueError:\n",
    "            pass\n",
    "print(len(x))\n",
    "\n",
    "ruleCount=0\n",
    "rules=[[-1 for i in range(num_var+1)] for j in range(pow(output_cluster,num_var))]\n",
    "\n",
    "Outmf = [[0 for i in range(discreteSamplePoints)] for j in range(output_cluster+1)]\n",
    "\n",
    "\n",
    "# Create fuzzytrain_ltsm\n",
    "temp = np.array([[0.0 for i in range(train_num_line)] for j in range(num_input*output_cluster+1)]).T\n",
    "# Array to dataframe :\n",
    "fuzzytrain_ltsm = pd.DataFrame(temp,columns=fuzzyinput_col_names)\n",
    "\n",
    "# Create fuzzytest_ltsm\n",
    "temp = np.array([[0.0 for i in range(test_num_line)] for j in range(num_input*output_cluster+1)]).T\n",
    "# Array to dataframe :\n",
    "fuzzytest_ltsm = pd.DataFrame(temp,columns=fuzzyinput_col_names)\n",
    "\n",
    "\n",
    "initNN1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76.323938,\n",
       " 86.789813,\n",
       " 94.639219,\n",
       " 112.954499,\n",
       " 128.653311,\n",
       " 141.735655,\n",
       " 146.968592,\n",
       " 160.050935,\n",
       " 175.749747,\n",
       " 188.832091]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LTSM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX=[]\n",
    "trainY=[]\n",
    "\n",
    "n_future=step\n",
    "n_past=10\n",
    "\n",
    "for i in range(n_past, len(data_train.values) - n_future +1):\n",
    "    trainX.append(data_train.values[i - n_past:i, 0:num_input])\n",
    "    trainY.append(data_train.values[i-1:i, num_var-1])\n",
    "trainX, trainY = np.array(trainX, dtype=np.float), np.array(trainY, dtype=np.float)\n",
    "# trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testX=[]\n",
    "testY=[]\n",
    "\n",
    "n_future=step\n",
    "n_past=10\n",
    "\n",
    "for i in range(n_past, len(data_test.values) - n_future +1):\n",
    "    testX.append(data_test.values[i - n_past:i, 0:num_input])\n",
    "    testY.append(data_test.values[i-1:i, num_var-1])\n",
    "\n",
    "testX, testY = np.array(testX, dtype=np.float), np.array(testY, dtype=np.float)\n",
    "# testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 200)           164000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 805,801\n",
      "Trainable params: 805,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# softplus- Nadam // selu - Adagrad,Adam\n",
    "model.add(LSTM(200,activation='relu',input_shape=(trainX.shape[1],trainX.shape[2]),return_sequences=True))\n",
    "model.add(LSTM(200,activation='relu',return_sequences=True))\n",
    "model.add(LSTM(200,activation='relu',return_sequences=False))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer='Adam',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 22s 86ms/step - loss: 2324.5839 - val_loss: 18.8123\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 30.6368 - val_loss: 33.4904\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 29.6950 - val_loss: 43.3773\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 31.2835 - val_loss: 15.1008\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 25.1615 - val_loss: 35.7838\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 29.0871 - val_loss: 27.6508\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 33.4976 - val_loss: 28.5039\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 35.9119 - val_loss: 86.7834\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 31.0915 - val_loss: 48.0351\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 27.6252 - val_loss: 28.0547\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 27.1610 - val_loss: 15.9314\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 28.4587 - val_loss: 16.6465\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 26.7629 - val_loss: 52.3517\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 27.2540 - val_loss: 33.3624\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 22.4424 - val_loss: 15.1405\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 25.0215 - val_loss: 13.8234\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 19.09 - 1s 30ms/step - loss: 19.3717 - val_loss: 16.2988\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 30.1929 - val_loss: 35.3486\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 31.5572 - val_loss: 37.3914\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 25.9573 - val_loss: 51.4240\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 27.7138 - val_loss: 21.3832\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 25.8387 - val_loss: 17.3053\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 21.5192 - val_loss: 38.2550\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 18.9893 - val_loss: 87.3209\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 25.2875 - val_loss: 14.1191\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 25.0074 - val_loss: 22.6882\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 22.0056 - val_loss: 216.6458\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 39.7909 - val_loss: 157.5737\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 35.1204 - val_loss: 12.8999\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 23.5379 - val_loss: 22.0805\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 21.9019 - val_loss: 13.1768\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 18.5541 - val_loss: 58.7006\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 34.4577 - val_loss: 181.1221\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 29.8516 - val_loss: 89.2489\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 24.1682 - val_loss: 28.0955\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 22.5030 - val_loss: 14.9625\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 24.0903 - val_loss: 15.8100\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 23.3911 - val_loss: 19.9768\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 20.7764 - val_loss: 15.6668\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 19.5001 - val_loss: 13.6001\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 18.8488 - val_loss: 72.4615\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 25.2292 - val_loss: 43.4870\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 21.2176 - val_loss: 17.8399\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 20.6382 - val_loss: 26.9148\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 20.8543 - val_loss: 16.5090\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 28.7281 - val_loss: 13.7050\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 26.3725 - val_loss: 13.8447\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 19.4820 - val_loss: 15.3006\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 23.6435 - val_loss: 14.6413\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 19.6506 - val_loss: 13.1424\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 20.1959 - val_loss: 83.9441\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 33.0114 - val_loss: 12.8323\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 20.2226 - val_loss: 18.9862\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 21.1128 - val_loss: 20.1242\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 23.5278 - val_loss: 15.3083\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 28.6193 - val_loss: 35.9368\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 25.8089 - val_loss: 13.3308\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 26.1893 - val_loss: 20.6114\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 18.3276 - val_loss: 20.8863\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 17.7261 - val_loss: 15.1673\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 21.4498 - val_loss: 34.1314\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 15.7049 - val_loss: 13.2854\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 19.5389 - val_loss: 38.8244\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 17.6975 - val_loss: 32.9738\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 19.5499 - val_loss: 14.1510\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 18.8930 - val_loss: 26.2841\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 20.9091 - val_loss: 105.9175\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 20.4881 - val_loss: 24.9037\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 18.8601 - val_loss: 24.3926\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 15.7665 - val_loss: 164.8119\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 30.7917 - val_loss: 14.1167\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 20.6901 - val_loss: 21.1784\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 16.0547 - val_loss: 19.9201\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 19.2246 - val_loss: 24.6624\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 13.2100 - val_loss: 17.3653\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 16.3063 - val_loss: 14.1112\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 16.4677 - val_loss: 16.8418\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 17.8973 - val_loss: 42.2621\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 17.2813 - val_loss: 13.7544\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 29ms/step - loss: 16.4044 - val_loss: 24.0826\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 18.9791 - val_loss: 13.8477\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 18.7671 - val_loss: 22.1303\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 15.2716 - val_loss: 14.5536\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 16.5340 - val_loss: 30.6621\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 24.5020 - val_loss: 15.1068\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 20.4001 - val_loss: 35.3686\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 17.7100 - val_loss: 32.9541\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 18.6629 - val_loss: 18.1202\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 16.0478 - val_loss: 17.5448\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 18.7123 - val_loss: 15.0818\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 19.3841 - val_loss: 20.2569\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 29.0739 - val_loss: 21.5409\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 21.1630 - val_loss: 30.1288\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 21.2932 - val_loss: 20.0619\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 15.3945 - val_loss: 18.0912\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 16.6157 - val_loss: 31.4163\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 19.7557 - val_loss: 22.1465\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 17.6472 - val_loss: 16.7320\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 20.9937 - val_loss: 14.3038\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 15.7168 - val_loss: 20.8971\n"
     ]
    }
   ],
   "source": [
    "##TRAINING DATA\n",
    "history=model.fit(trainX,trainY, epochs=100, batch_size=32,validation_split=0.1,verbose=1)\n",
    "forecast = model.predict(testX) #forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predicted vs actual output\n",
      "  71.54    68.55\n",
      "  71.34    67.60\n",
      "  71.82    67.46\n",
      "  72.35    67.51\n",
      "  71.92    67.57\n",
      "  70.61    67.80\n",
      "  70.49    67.58\n",
      "  70.81    68.29\n",
      "  70.40    67.57\n",
      "  69.88    67.17\n",
      "  69.71    67.21\n",
      "  70.08    67.88\n",
      "  70.07    68.81\n",
      "  70.37    68.66\n",
      "  70.44    70.38\n",
      "  70.33    70.90\n",
      "  69.86    70.86\n",
      "  69.87    70.90\n",
      "  69.98    70.88\n",
      "  70.48    71.76\n",
      "  70.88    72.08\n",
      "  71.78    72.02\n",
      "  72.67    72.09\n",
      "  73.13    72.08\n",
      "  73.18    73.11\n",
      "  73.22    73.32\n",
      "  73.78    73.88\n",
      "  74.25    73.97\n",
      "  74.43    73.66\n",
      "  74.37    73.27\n",
      "  74.55    73.09\n",
      "  74.36    72.60\n",
      "  75.11    73.52\n",
      "  75.40    73.93\n",
      "  75.49    73.98\n",
      "  75.60    72.99\n",
      "  75.00    72.65\n",
      "  74.84    72.69\n",
      "  74.23    72.18\n",
      "  74.71    71.38\n",
      "  75.81    70.38\n",
      "  75.77    70.71\n",
      "  75.29    71.36\n",
      "  74.85    71.40\n",
      "  74.65    71.59\n",
      "  74.31    71.90\n",
      "  73.79    72.05\n",
      "  73.06    71.97\n",
      "  72.57    72.83\n",
      "  72.75    73.80\n",
      "  73.08    74.28\n",
      "  73.54    74.99\n",
      "  73.68    75.18\n",
      "  73.94    76.18\n",
      "  74.12    75.46\n",
      "  74.48    76.37\n",
      "  75.19    75.42\n",
      "  75.57    75.46\n",
      "  76.24    74.87\n",
      "  76.68    75.09\n",
      "  77.11    75.62\n",
      "  77.11    75.22\n",
      "  77.49    76.12\n",
      "  77.72    76.13\n",
      "  77.40    76.30\n",
      "  76.47    76.57\n",
      "  76.64    76.76\n",
      "  76.90    75.88\n",
      "  76.82    76.31\n",
      "  77.26    75.34\n",
      "  77.81    72.65\n",
      "  77.69    72.89\n",
      "  78.20    72.46\n",
      "  78.01    70.53\n",
      "  78.02    71.38\n",
      "  77.54    72.74\n",
      "  77.21    73.62\n",
      "  75.63    74.80\n",
      "  72.87    75.38\n",
      "  73.98    74.11\n",
      "  72.94    73.90\n",
      "  72.56    74.20\n",
      "  74.57    73.34\n",
      "  75.76    75.48\n",
      "  76.86    76.58\n",
      "  77.99    76.61\n",
      "  78.57    75.73\n",
      "  77.97    74.65\n",
      "  77.19    75.58\n",
      "  76.65    76.68\n",
      "  76.85    78.69\n",
      "  77.86    78.73\n",
      "  78.62    79.58\n",
      "  78.62    81.15\n",
      "  77.48    80.55\n",
      "  77.14    79.95\n",
      "  77.93    79.12\n",
      "  79.60    79.21\n",
      "  80.11    79.10\n",
      "  80.62    78.77\n",
      "  81.82    79.27\n",
      "  82.23    79.33\n",
      "  82.21    77.27\n",
      "  81.49    76.04\n",
      "  80.96    78.66\n",
      "  80.78    77.17\n",
      "  80.27    78.65\n",
      "  80.46    81.22\n",
      "  80.76    80.57\n",
      "  79.58    81.63\n",
      "  78.17    81.22\n",
      "  78.89    81.31\n",
      "  79.08    80.26\n",
      "  79.58    80.35\n",
      "  81.30    80.97\n",
      "  81.86    80.78\n",
      "  82.38    81.60\n",
      "  82.55    80.95\n",
      "  83.18    81.00\n",
      "  82.45    80.92\n",
      "  82.72    80.69\n",
      "  82.82    81.90\n",
      "  82.62    82.35\n",
      "  82.85    81.91\n",
      "  82.64    81.25\n",
      "  82.58    82.70\n",
      "  82.43    83.05\n",
      "  82.16    83.65\n",
      "  82.72    83.20\n",
      "  83.36    83.85\n",
      "  83.14    82.82\n",
      "  82.86    81.03\n",
      "  83.11    82.62\n",
      "  83.79    83.52\n",
      "  84.20    83.24\n",
      "  84.70    84.87\n",
      "  84.50    85.13\n",
      "  84.35    85.29\n",
      "  82.70    85.16\n",
      "  82.95    84.74\n",
      "  84.11    85.01\n",
      "  84.56    85.32\n",
      "  85.13    84.85\n",
      "  86.22    85.92\n",
      "  86.46    86.21\n",
      "  86.69    86.57\n",
      "  86.69    87.24\n",
      "  86.46    87.40\n",
      "  86.29    86.86\n",
      "  86.04    88.03\n",
      "  86.50    86.54\n",
      "  87.03    86.75\n",
      "  87.03    87.71\n",
      "  87.49    87.89\n",
      "  88.10    89.37\n",
      "  87.84    89.71\n",
      "  88.73    89.62\n",
      "  88.15    89.60\n",
      "  87.80    89.80\n",
      "  88.27    89.79\n",
      "  88.69    89.69\n",
      "  89.46    89.83\n",
      "  90.41    89.16\n",
      "  89.71    88.95\n",
      "  90.72    88.86\n",
      "  90.54    89.09\n",
      "  90.98    88.59\n",
      "  90.73    86.95\n",
      "  90.35    86.74\n",
      "  90.19    86.24\n",
      "  89.52    86.65\n",
      "  89.79    86.38\n",
      "  89.66    86.76\n",
      "  89.43    85.31\n",
      "  88.13    85.49\n",
      "  87.49    85.28\n",
      "  87.32    86.29\n",
      "  86.97    85.90\n",
      "  87.38    86.48\n",
      "  87.43    88.37\n",
      "  87.13    88.12\n",
      "  86.50    88.86\n",
      "  86.18    89.39\n",
      "  87.02    90.47\n",
      "  86.99    89.91\n",
      "  87.10    89.91\n",
      "  88.54    90.39\n",
      "  89.10    90.13\n",
      "  89.65    89.07\n",
      "  90.00    89.02\n",
      "  90.51    90.55\n",
      "  90.87    87.55\n",
      "  90.50    86.50\n",
      "  90.86    86.49\n",
      "  91.00    86.83\n",
      "  89.44    86.59\n",
      "  89.86    87.01\n",
      "  90.71    88.35\n",
      "  89.68    87.98\n",
      "  87.81    87.85\n",
      "  87.50    87.18\n",
      "  86.91    87.07\n",
      "  86.98    87.60\n",
      "  87.40    87.17\n",
      "  88.73    87.72\n",
      "  89.25    88.06\n",
      "  89.38    88.17\n",
      "  89.17    87.57\n",
      "  88.62    87.88\n",
      "  88.35    88.31\n",
      "  88.18    89.65\n",
      "  88.37    89.93\n",
      "  88.51    90.00\n",
      "  88.96    89.77\n",
      "  88.79    89.44\n",
      "  88.60    90.33\n",
      "  89.13    91.56\n",
      "  89.84    89.44\n",
      "  90.66    88.09\n",
      "  90.88    88.16\n",
      "  90.62    88.40\n",
      "  90.25    88.74\n",
      "  90.42    86.62\n",
      "  91.58    87.35\n",
      "  91.05    86.28\n",
      "  89.74    84.75\n",
      "  88.97    85.68\n",
      "  89.08    85.56\n",
      "  89.07    85.45\n",
      "  88.23    86.11\n",
      "  87.68    85.48\n",
      "  87.49    83.38\n",
      "  86.17    81.71\n",
      "  86.04    82.21\n",
      "  85.92    81.60\n",
      "  86.28    82.86\n",
      "  86.70    81.71\n",
      "  86.67    81.56\n",
      "  85.54    81.62\n",
      "  83.48    81.34\n",
      "  82.77    80.78\n",
      "  82.45    80.31\n",
      "  82.96    77.95\n",
      "  82.86    75.75\n",
      "  82.59    76.10\n",
      "  82.86    76.09\n",
      "  82.69    77.92\n",
      "  82.09    76.68\n",
      "  81.32    76.04\n",
      "  79.99    76.76\n",
      "  77.50    77.04\n",
      "  77.42    77.65\n",
      "  77.30    77.50\n",
      "  78.22    79.49\n",
      "  77.96    79.42\n",
      "  78.04    79.96\n",
      "  78.25    81.62\n",
      "  79.08    82.46\n",
      "  79.27    82.74\n",
      "  79.71    82.74\n",
      "  80.63    84.41\n",
      "  80.68    85.22\n",
      "  81.55    86.31\n",
      "  82.35    86.86\n",
      "  83.67    85.97\n",
      "  84.00    84.26\n",
      "  84.49    84.31\n",
      "  85.62    81.68\n",
      "  86.44    83.76\n",
      "  87.18    84.39\n",
      "  87.45    84.63\n",
      "  87.23    83.15\n",
      "  86.33    82.98\n",
      "  85.45    83.55\n",
      "  84.14    85.05\n",
      "  83.55    85.08\n",
      "  84.49    85.52\n",
      "  85.38    85.96\n",
      "  84.30    86.84\n",
      "  84.41    88.11\n",
      "  84.30    85.97\n",
      "  85.95    85.48\n",
      "  86.47    83.08\n",
      "  87.04    82.83\n",
      "  87.28    83.03\n",
      "  87.40    83.20\n",
      "  88.48    83.17\n",
      "  87.99    82.72\n",
      "  86.38    81.48\n",
      "  85.06    80.04\n",
      "  82.88    79.34\n",
      "  84.20    77.43\n",
      "  84.42    76.00\n",
      "  84.15    73.36\n",
      "  83.92    75.77\n",
      "  83.10    77.12\n",
      "  82.29    76.97\n",
      "  80.99    77.96\n",
      "  79.26    77.42\n",
      "  78.02    75.34\n",
      "  75.06    78.33\n",
      "  74.85    76.28\n",
      "  77.06    76.06\n",
      "  78.42    76.44\n",
      "  79.62    76.99\n",
      "  80.25    77.13\n",
      "  79.22    76.97\n",
      "  80.00    77.46\n",
      "  79.42    79.29\n",
      "  78.82    78.80\n",
      "  79.07    79.47\n",
      "  78.61    79.71\n",
      "  78.72    80.99\n",
      "  78.85    81.23\n",
      "  79.37    81.90\n",
      "  80.85    82.27\n",
      "  81.14    82.02\n",
      "  81.02    82.86\n",
      "  81.18    84.15\n",
      "  81.72    83.52\n",
      "  82.26    83.12\n",
      "  82.89    82.97\n",
      "  83.01    83.09\n",
      "  83.35    82.98\n",
      "  83.67    83.21\n",
      "  84.44    82.87\n",
      "  84.80    83.70\n",
      "  84.19    84.10\n",
      "  83.99    83.31\n",
      "  83.99    83.88\n",
      "  83.80    83.94\n",
      "  84.12    84.19\n",
      "  84.51    84.18\n",
      "  85.31    85.10\n",
      "  85.27    86.16\n",
      "  84.91    87.07\n",
      "  84.51    86.79\n",
      "  84.72    87.52\n",
      "  84.72    87.92\n",
      "  84.97    86.17\n",
      "  85.57    84.82\n",
      "  86.71    83.80\n",
      "  87.48    82.17\n",
      "  87.87    79.75\n",
      "  88.17    80.31\n",
      "  88.47    80.12\n",
      "  87.71    81.29\n",
      "  86.23    80.70\n",
      "  84.79    80.27\n",
      "  83.27    80.94\n",
      "  80.26    80.84\n",
      "  80.29    80.09\n",
      "  80.53    81.04\n",
      "  81.77    80.60\n",
      "  82.10    81.58\n",
      "  82.06    82.45\n",
      "  82.16    82.72\n",
      "  82.52    83.34\n",
      "  82.03    84.06\n",
      "  82.08    84.93\n",
      "  81.63    85.52\n",
      "  82.37    85.80\n",
      "  83.34    85.68\n",
      "  83.48    85.11\n",
      "  84.05    85.28\n",
      "  84.86    84.26\n",
      "  85.71    84.07\n",
      "  86.17    83.62\n",
      "  86.76    84.36\n",
      "  86.55    85.00\n",
      "  86.28    86.23\n",
      "  86.05    86.66\n",
      "  85.44    86.46\n",
      "  84.79    86.21\n",
      "  84.40    86.13\n",
      "  84.69    85.68\n",
      "  85.33    85.93\n",
      "  86.45    86.33\n",
      "  87.30    87.86\n",
      "  87.57    88.58\n",
      "  87.24    88.70\n",
      "  87.11    88.64\n",
      "  86.80    88.51\n",
      "  86.39    89.09\n",
      "  86.59    87.33\n",
      "  87.94    87.42\n",
      "  88.90    87.58\n",
      "  89.42    88.88\n",
      "  89.62    87.33\n",
      "  89.70    87.59\n",
      "  89.60    87.20\n",
      "  89.13    87.36\n",
      "  88.27    86.76\n",
      "  87.82    86.72\n",
      "  88.78    87.70\n",
      "  88.13    86.82\n",
      "  88.75    86.49\n",
      "  88.30    86.50\n",
      "  88.11    86.44\n",
      "  88.05    86.80\n",
      "  87.65    87.09\n",
      "  88.46    87.08\n",
      "  88.10    87.15\n",
      "  87.41    89.12\n",
      "  87.50    92.41\n",
      "  87.75    92.13\n",
      "  87.32    92.39\n",
      "  87.93    92.88\n",
      "  87.66    91.52\n",
      "  87.95    91.71\n",
      "  89.10    92.15\n",
      "  91.35    92.41\n",
      "  92.33    91.89\n",
      "  92.70    92.60\n",
      "  93.34    93.18\n",
      "  92.94    94.37\n",
      "  92.44    94.90\n",
      "  92.37    93.53\n",
      "  93.10    94.62\n",
      "  93.19    91.35\n",
      "  93.53    92.85\n",
      "  93.66    92.85\n",
      "  94.64    93.80\n",
      "  95.38    96.22\n",
      "  94.91    97.92\n",
      "  94.81    97.57\n",
      "  93.46    97.36\n",
      "  93.21    98.11\n",
      "  93.52    99.47\n",
      "  94.25    100.42\n",
      "  95.89    100.69\n",
      "  97.67    100.63\n",
      "  98.01    99.73\n",
      "  98.27    99.10\n",
      "  98.41    99.58\n",
      "  99.75    98.22\n",
      "  100.15    98.27\n",
      "  100.94    97.38\n",
      "  101.20    94.83\n",
      "  101.37    94.25\n",
      "  100.45    94.68\n",
      "  100.01    93.34\n",
      "  99.60    93.46\n",
      "  98.22    93.05\n",
      "  98.48    94.28\n",
      "  95.26    94.57\n",
      "  94.73    91.11\n",
      "  94.58    92.55\n",
      "  94.16    92.81\n",
      "  93.67    94.87\n",
      "  93.64    95.14\n",
      "  94.83    93.25\n",
      "  95.49    94.55\n",
      "  93.32    92.03\n",
      "  92.93    93.64\n",
      "  92.49    94.17\n",
      "  94.50    95.99\n",
      "  95.60    95.50\n",
      "  94.94    95.90\n",
      "  95.11    96.68\n",
      "  94.15    94.16\n",
      "  93.94    95.27\n",
      "  95.07    94.88\n",
      "  96.33    95.13\n",
      "  96.75    96.33\n",
      "  96.75    96.40\n",
      "  97.44    96.10\n",
      "  96.41    96.47\n",
      "  95.82    98.50\n",
      "  95.89    100.67\n",
      "  95.52    99.29\n",
      "  96.42    94.77\n",
      "  97.27    94.80\n",
      "  97.00    96.05\n",
      "  97.17    96.55\n",
      "  98.52    96.32\n",
      "  100.26    99.67\n",
      "  100.41    99.56\n",
      "  97.48    98.65\n",
      "  95.01    97.68\n",
      "  96.18    97.26\n",
      "  96.25    98.35\n",
      "  97.02    99.69\n",
      "  99.03    98.78\n",
      "  100.43    97.09\n",
      "  100.42    96.39\n",
      "  99.64    95.65\n",
      "  99.15    92.88\n",
      "  99.18    94.24\n",
      "  99.90    96.27\n",
      "  99.67    96.06\n",
      "  99.18    94.18\n",
      "  97.93    94.43\n",
      "  96.35    95.62\n",
      "  94.19    96.35\n",
      "  93.57    95.42\n",
      "  95.77    95.00\n",
      "  96.84    95.13\n",
      "  95.80    95.40\n",
      "  95.62    95.68\n",
      "  96.18    95.23\n",
      "  96.86    94.94\n",
      "  96.85    98.29\n",
      "  96.45    97.98\n",
      "  95.59    95.49\n",
      "  96.07    95.78\n",
      "  96.21    95.70\n",
      "  96.25    97.08\n",
      "  95.70    96.79\n",
      "  97.66    96.27\n",
      "  98.77    95.65\n",
      "  96.94    95.48\n",
      "  96.62    96.94\n",
      "  96.79    97.53\n",
      "  97.03    97.66\n",
      "  97.35    99.47\n",
      "  97.38    99.39\n",
      "  97.24    100.19\n",
      "  96.64    100.18\n",
      "  97.12    100.50\n",
      "  97.93    101.48\n",
      "  98.55    101.94\n",
      "  99.43    102.55\n",
      "  99.84    101.62\n",
      "  100.15    101.26\n",
      "  100.57    101.52\n",
      "  100.97    101.70\n",
      "  101.68    101.14\n",
      "  102.19    101.67\n",
      "  102.89    101.34\n",
      "  102.95    101.36\n",
      "  102.27    102.07\n",
      "  102.32    101.55\n",
      "  102.57    102.09\n",
      "  102.28    101.52\n",
      "  102.22    101.49\n",
      "  102.04    100.79\n",
      "  102.33    101.48\n",
      "  102.74    101.82\n",
      "  102.70    102.53\n",
      "  102.88    103.31\n",
      "  102.54    103.23\n",
      "  102.35    104.30\n",
      "  102.15    104.86\n",
      "  102.10    104.45\n",
      "  102.28    103.98\n",
      "  103.78    105.05\n",
      "  103.83    105.24\n",
      "  104.20    104.30\n",
      "  104.76    104.38\n",
      "  105.28    105.08\n",
      "  105.42    105.53\n",
      "  105.06    105.46\n",
      "  105.50    103.71\n",
      "  106.00    103.14\n",
      "  105.69    104.62\n",
      "  105.37    104.12\n",
      "  105.76    104.37\n",
      "  105.99    103.84\n",
      "  105.92    105.12\n",
      "  105.46    105.56\n",
      "  104.33    106.53\n",
      "  105.11    106.47\n",
      "  105.38    106.37\n",
      "  105.41    106.84\n",
      "  105.13    107.41\n",
      "  105.76    106.99\n",
      "  106.48    108.31\n",
      "  106.97    112.41\n",
      "  107.65    113.01\n",
      "  107.14    113.50\n",
      "  107.44    114.80\n",
      "  107.88    115.65\n",
      "  107.82    113.51\n",
      "  108.71    112.91\n",
      "  110.63    111.42\n",
      "  112.12    112.79\n",
      "  113.02    111.88\n",
      "  114.40    111.16\n",
      "  115.43    111.49\n",
      "  115.02    113.25\n",
      "  114.45    112.73\n",
      "  113.36    112.34\n",
      "  113.45    111.58\n",
      "  114.00    112.25\n",
      "  112.25    111.82\n",
      "  112.76    109.55\n",
      "  114.10    110.15\n",
      "  113.57    104.72\n",
      "  114.55    99.94\n",
      "  113.08    107.32\n",
      "  113.42    107.27\n",
      "  112.58    113.41\n",
      "  111.71    111.20\n",
      "  111.75    107.69\n",
      "  107.40    103.03\n",
      "  99.36    102.04\n",
      "  103.66    96.80\n",
      "  108.41    86.79\n",
      "  111.96    94.05\n",
      "  112.27    83.54\n",
      "  108.93    93.05\n",
      "  104.59    89.67\n",
      "  102.46    86.17\n",
      "  96.65    78.83\n",
      "  91.15    71.35\n",
      "  91.60    81.26\n",
      "  88.10    85.15\n",
      "  94.16    91.87\n",
      "  91.59    90.85\n",
      "  88.06    97.37\n",
      "  84.52    92.98\n",
      "  80.40    90.35\n",
      "  84.81    92.01\n",
      "  91.09    93.24\n",
      "  96.18    99.48\n",
      "  96.52    98.84\n",
      "  98.29    101.97\n",
      "  98.43    105.68\n",
      "  96.52    101.14\n",
      "  97.37    105.32\n",
      "  99.25    103.80\n",
      "  102.31    106.06\n",
      "  105.24    108.93\n",
      "  104.83    107.50\n",
      "  105.79    103.08\n",
      "  105.42    102.46\n",
      "  104.90    101.69\n",
      "  104.59    103.43\n",
      "  105.71    109.31\n",
      "  108.21    108.90\n",
      "  109.22    109.28\n",
      "  106.59    107.39\n",
      "  104.55    104.40\n",
      "  103.40    103.92\n",
      "  102.93    106.57\n",
      "  108.06    103.43\n",
      "  110.45    105.10\n",
      "  110.62    105.35\n",
      "  109.29    106.97\n",
      "  105.99    106.24\n",
      "  104.22    106.63\n",
      "  106.35    107.20\n",
      "  106.05    109.75\n",
      "  106.61    112.55\n",
      "  107.31    110.29\n",
      "  107.63    112.33\n",
      "  108.26    111.62\n",
      "  107.86    112.94\n",
      "  107.58    113.86\n",
      "  109.22    112.80\n",
      "  112.41    113.95\n",
      "  112.50    116.00\n",
      "  112.83    116.41\n",
      "  112.72    116.76\n",
      "  113.63    116.86\n",
      "  115.20    115.48\n",
      "  114.62    117.41\n",
      "  115.16    118.78\n",
      "  116.25    117.59\n",
      "  117.34    117.52\n",
      "  117.77    111.35\n",
      "  118.03    113.22\n",
      "  116.97    115.40\n",
      "  116.97    116.54\n",
      "  119.42    116.15\n",
      "  119.02    117.29\n",
      "  119.27    116.84\n",
      "  114.96    117.70\n",
      "  113.36    116.61\n",
      "  114.32    113.35\n",
      "  117.17    116.70\n",
      "  118.14    113.88\n",
      "  118.32    115.58\n",
      "  119.78    117.47\n",
      "  119.09    118.73\n",
      "  119.06    118.05\n",
      "  116.56    119.05\n",
      "  116.69    118.45\n",
      "  116.33    119.66\n",
      "  116.39    118.77\n",
      "  118.06    120.82\n",
      "  119.82    120.94\n",
      "  120.73    122.71\n",
      "  121.00    124.71\n",
      "  120.40    124.90\n",
      "  120.87    126.29\n",
      "  120.47    129.10\n",
      "  121.11    128.81\n",
      "  123.01    131.85\n",
      "  123.46    129.21\n",
      "  125.05    128.37\n",
      "  125.70    128.34\n",
      "  126.58    126.00\n",
      "  128.05    128.81\n",
      "  128.72    127.72\n",
      "  130.52    129.11\n",
      "  131.18    128.16\n",
      "  129.90    127.52\n",
      "  130.26    128.17\n",
      "  128.66    128.51\n",
      "  129.98    130.64\n",
      "  129.70    129.32\n",
      "  130.63    128.28\n",
      "  131.47    128.23\n",
      "  130.38    128.09\n",
      "  130.35    127.07\n",
      "  130.67    128.12\n",
      "  131.44    127.87\n",
      "  131.84    127.69\n",
      "  131.28    128.27\n",
      "  131.45    127.74\n",
      "  130.28    129.37\n",
      "  129.75    127.92\n",
      "  130.05    130.32\n",
      "  130.24    129.64\n",
      "  130.45    129.63\n",
      "  130.88    132.17\n",
      "  130.33    132.56\n",
      "  131.06    134.98\n",
      "  131.04    131.02\n",
      "  131.73    128.10\n",
      "  132.17    124.32\n",
      "  131.98    127.02\n",
      "  133.26    123.28\n",
      "  133.76    124.06\n",
      "  135.32    125.34\n",
      "  134.42    126.49\n",
      "  131.42    125.64\n",
      "  126.81    122.82\n",
      "  127.44    120.85\n",
      "  125.67    120.46\n",
      "  124.92    121.71\n",
      "  127.21    118.17\n",
      "  128.85    119.72\n",
      "  129.34    122.41\n",
      "  125.22    123.74\n",
      "  123.65    119.80\n",
      "  121.00    121.11\n",
      "  121.37    122.31\n",
      "  121.07    121.93\n",
      "  120.66    123.24\n",
      "  122.95    121.96\n",
      "  125.56    121.38\n",
      "  122.60    122.98\n",
      "  123.29    123.43\n",
      "  123.80    124.73\n",
      "  124.04    124.73\n",
      "  124.08    125.99\n",
      "  124.61    126.74\n",
      "  123.91    127.19\n",
      "  124.60    125.82\n",
      "  125.72    127.31\n",
      "  126.74    130.65\n",
      "  126.38    128.40\n",
      "  127.47    127.44\n",
      "  127.61    125.72\n",
      "  128.54    123.47\n",
      "  128.40    120.14\n",
      "  129.01    120.42\n",
      "  130.31    119.41\n",
      "  130.85    121.58\n",
      "  129.23    123.28\n",
      "  128.18    127.62\n",
      "  126.71    131.47\n",
      "  121.62    131.46\n",
      "  120.66    127.99\n",
      "  120.02    125.47\n",
      "  123.23    128.10\n",
      "  126.11    125.20\n",
      "  128.80    124.18\n",
      "  130.43    123.89\n",
      "  130.88    122.71\n",
      "  131.35    121.13\n",
      "  128.84    123.13\n",
      "  128.67    124.68\n",
      "  128.27    124.37\n",
      "  126.44    125.61\n",
      "  125.15    125.67\n",
      "  124.75    125.46\n",
      "  122.49    126.32\n",
      "  124.60    128.22\n",
      "  127.20    127.67\n",
      "  126.82    123.74\n",
      "  127.71    124.14\n",
      "  127.94    127.37\n",
      "  127.40    127.46\n",
      "  127.65    124.93\n",
      "  128.83    123.83\n",
      "  129.11    124.50\n",
      "  126.41    122.89\n",
      "  126.80    126.11\n",
      "  128.13    125.92\n",
      "  129.10    127.31\n",
      "  127.64    127.41\n",
      "  126.60    126.86\n",
      "  126.02    128.70\n",
      "  126.75    126.76\n",
      "  127.41    127.43\n",
      "  128.26    127.65\n",
      "  129.37    127.94\n",
      "  129.82    128.93\n",
      "  127.87    131.51\n",
      "  129.71    130.79\n",
      "  129.62    130.75\n",
      "  129.27    134.14\n",
      "  129.79    135.53\n",
      "  130.45    137.52\n",
      "  130.99    139.59\n",
      "  132.28    140.60\n",
      "  132.76    141.17\n",
      "  132.97    140.81\n",
      "  134.39    138.74\n",
      "  135.25    140.94\n",
      "  136.19    142.34\n",
      "  138.02    140.09\n",
      "  139.20    139.12\n",
      "  140.67    140.98\n",
      "  141.68    139.82\n",
      "  141.57    139.89\n",
      "  142.58    137.74\n",
      "  144.16    134.02\n",
      "  143.80    137.32\n",
      "  142.55    141.29\n",
      "  143.54    140.84\n",
      "  143.78    142.24\n",
      "  142.64    141.27\n",
      "  142.67    141.13\n",
      "  137.05    141.80\n",
      "  138.88    141.15\n",
      "  142.65    141.05\n",
      "  143.57    140.67\n",
      "  144.86    142.65\n",
      "  144.82    143.35\n",
      "  144.62    143.54\n",
      "  144.88    143.09\n",
      "  144.32    140.31\n",
      "  144.03    139.04\n",
      "  144.53    140.67\n",
      "  145.14    139.02\n",
      "  146.01    137.01\n",
      "  146.44    140.55\n",
      "  146.66    139.34\n",
      "  144.14    135.44\n",
      "  142.28    136.72\n",
      "  142.46    143.36\n",
      "  143.53    143.65\n",
      "  141.14    145.29\n",
      "  143.39    143.21\n",
      "  142.96    143.25\n",
      "  140.47    143.57\n",
      "  139.56    145.13\n",
      "  143.46    144.61\n",
      "  145.61    143.17\n",
      "  146.55    144.08\n",
      "  146.32    144.88\n",
      "  145.72    146.25\n",
      "  146.31    146.70\n",
      "  146.77    146.46\n",
      "  147.59    145.70\n",
      "  146.89    149.83\n",
      "  147.61    149.95\n",
      "  148.25    146.58\n",
      "  149.11    146.59\n",
      "  149.45    149.96\n",
      "  149.59    151.20\n",
      "  149.21    151.76\n",
      "  150.89    149.89\n",
      "  151.83    152.61\n",
      "  151.12    155.18\n",
      "  150.93    155.17\n",
      "  152.12    157.00\n",
      "  153.68    156.51\n",
      "  154.20    159.10\n",
      "  153.77    159.22\n",
      "  154.92    157.69\n",
      "  156.79    158.74\n",
      "  157.47    158.38\n",
      "  157.81    158.78\n",
      "  158.76    161.51\n",
      "  160.17    159.08\n",
      "  161.12    159.85\n",
      "  160.87    158.71\n",
      "  161.81    160.93\n",
      "  162.34    160.59\n",
      "  163.49    161.53\n",
      "  164.30    162.57\n",
      "  164.25    162.58\n",
      "  163.86    162.61\n",
      "  164.02    163.59\n",
      "  164.67    162.56\n",
      "  165.00    158.79\n",
      "  165.90    157.42\n",
      "  165.79    159.95\n",
      "  166.74    163.39\n",
      "  166.72    162.78\n",
      "  167.33    160.98\n",
      "  167.60    159.99\n",
      "  165.02    162.49\n",
      "  162.87    162.90\n",
      "  164.50    163.95\n",
      "  166.87    163.34\n",
      "  167.43    164.47\n",
      "  166.91    165.00\n",
      "  165.39    166.47\n",
      "  167.07    163.48\n",
      "  167.53    165.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  167.77    167.07\n",
      "  167.93    169.22\n",
      "  168.81    167.90\n",
      "  169.38    167.96\n",
      "  170.06    168.12\n",
      "  169.52    167.90\n",
      "  169.80    172.48\n",
      "  171.01    174.68\n",
      "  172.06    175.81\n",
      "  172.32    176.87\n",
      "  172.69    179.30\n",
      "  172.83    175.32\n",
      "  173.23    178.29\n",
      "  174.77    178.21\n",
      "  175.83    177.48\n",
      "  176.94    177.32\n",
      "  178.02    177.59\n",
      "  179.19    176.63\n",
      "  179.40    176.37\n",
      "  180.54    175.32\n",
      "  181.75    175.55\n",
      "  182.52    177.40\n",
      "  183.36    175.88\n",
      "  183.91    175.68\n",
      "  184.05    173.61\n",
      "  183.94    175.29\n",
      "  182.77    179.16\n",
      "  183.07    178.60\n",
      "  183.58    177.60\n",
      "  183.40    178.16\n",
      "  182.82    178.06\n",
      "  181.42    176.67\n",
      "  181.82    180.41\n",
      "  183.51    185.77\n",
      "  183.98    184.84\n",
      "  183.16    187.25\n",
      "  183.77    186.07\n",
      "  184.24    185.18\n",
      "  183.45    185.03\n",
      "  184.75    186.17\n",
      "  186.20    186.22\n",
      "  187.75    187.92\n",
      "  188.81    188.16\n",
      "  189.00    188.84\n",
      "  189.87    188.17\n",
      "  190.56    188.21\n",
      "  191.27    188.17\n",
      "  191.83    188.35\n",
      "  193.44    188.80\n",
      "  194.58    189.57\n",
      "  194.88    190.47\n",
      "  195.04    191.65\n",
      "  195.11    189.47\n",
      "  194.99    186.38\n",
      "  195.20    187.51\n",
      "  195.88    188.16\n",
      "  196.23    190.02\n",
      "  197.05    190.34\n",
      "  197.39    191.11\n",
      "  197.25    190.65\n",
      "  195.96    192.95\n",
      "  194.75    193.57\n",
      "  196.01    195.25\n",
      "  197.14    197.42\n",
      "  197.68    197.37\n",
      "  197.60    197.99\n",
      "  198.06    195.94\n",
      "  199.00    197.89\n",
      "  198.93    197.94\n",
      "  199.24    196.04\n",
      "  200.02    194.32\n",
      "  201.32    195.55\n",
      "  202.47    195.84\n",
      "  202.81    195.43\n",
      "  203.35    192.90\n",
      "  204.48    190.98\n"
     ]
    }
   ],
   "source": [
    "time=[0]*len(forecast)\n",
    "f = open(\"result_pure_lstm.txt\", \"w\")\n",
    "    \n",
    "print(\"\\npredicted vs actual output\")\n",
    "f.write(\"predicted vs actual output\\n\")\n",
    "for i in range(len(forecast)):\n",
    "    print(\" \", '{0:.2f}'.format(forecast[i][0]),\"  \",'{0:.2f}'.format(testY[i][0]))\n",
    "    f.write(str( '{0:.2f}'.format(forecast[i][0])))\n",
    "    f.write(\"  \")\n",
    "    f.write(str('{0:.2f}'.format(testY[i][0])))\n",
    "    f.write(\"\\n\")\n",
    "    time[i]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzyvalue=[0]*len(forecast)\n",
    "for i in range(len(forecast)):\n",
    "    temp=0\n",
    "    index=0\n",
    "    for j in range(len(outputCluster)):\n",
    "        if temp == 0:\n",
    "            temp=abs(forecast[i]-outputCluster[j])\n",
    "            index=j\n",
    "        elif abs(forecast[i]-outputCluster[j]) < temp:\n",
    "            temp=abs(forecast[i]-outputCluster[j])\n",
    "            index=j\n",
    "    if j == len(outputCluster)-1:\n",
    "        fuzzyvalue[i]=outputCluster[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predicted vs actual output\n",
      "  76.32    68.55\n",
      "  76.32    67.60\n",
      "  76.32    67.46\n",
      "  76.32    67.51\n",
      "  76.32    67.57\n",
      "  76.32    67.80\n",
      "  76.32    67.58\n",
      "  76.32    68.29\n",
      "  76.32    67.57\n",
      "  76.32    67.17\n",
      "  76.32    67.21\n",
      "  76.32    67.88\n",
      "  76.32    68.81\n",
      "  76.32    68.66\n",
      "  76.32    70.38\n",
      "  76.32    70.90\n",
      "  76.32    70.86\n",
      "  76.32    70.90\n",
      "  76.32    70.88\n",
      "  76.32    71.76\n",
      "  76.32    72.08\n",
      "  76.32    72.02\n",
      "  76.32    72.09\n",
      "  76.32    72.08\n",
      "  76.32    73.11\n",
      "  76.32    73.32\n",
      "  76.32    73.88\n",
      "  76.32    73.97\n",
      "  76.32    73.66\n",
      "  76.32    73.27\n",
      "  76.32    73.09\n",
      "  76.32    72.60\n",
      "  76.32    73.52\n",
      "  76.32    73.93\n",
      "  76.32    73.98\n",
      "  76.32    72.99\n",
      "  76.32    72.65\n",
      "  76.32    72.69\n",
      "  76.32    72.18\n",
      "  76.32    71.38\n",
      "  76.32    70.38\n",
      "  76.32    70.71\n",
      "  76.32    71.36\n",
      "  76.32    71.40\n",
      "  76.32    71.59\n",
      "  76.32    71.90\n",
      "  76.32    72.05\n",
      "  76.32    71.97\n",
      "  76.32    72.83\n",
      "  76.32    73.80\n",
      "  76.32    74.28\n",
      "  76.32    74.99\n",
      "  76.32    75.18\n",
      "  76.32    76.18\n",
      "  76.32    75.46\n",
      "  76.32    76.37\n",
      "  76.32    75.42\n",
      "  76.32    75.46\n",
      "  76.32    74.87\n",
      "  76.32    75.09\n",
      "  76.32    75.62\n",
      "  76.32    75.22\n",
      "  76.32    76.12\n",
      "  76.32    76.13\n",
      "  76.32    76.30\n",
      "  76.32    76.57\n",
      "  76.32    76.76\n",
      "  76.32    75.88\n",
      "  76.32    76.31\n",
      "  76.32    75.34\n",
      "  76.32    72.65\n",
      "  76.32    72.89\n",
      "  76.32    72.46\n",
      "  76.32    70.53\n",
      "  76.32    71.38\n",
      "  76.32    72.74\n",
      "  76.32    73.62\n",
      "  76.32    74.80\n",
      "  76.32    75.38\n",
      "  76.32    74.11\n",
      "  76.32    73.90\n",
      "  76.32    74.20\n",
      "  76.32    73.34\n",
      "  76.32    75.48\n",
      "  76.32    76.58\n",
      "  76.32    76.61\n",
      "  76.32    75.73\n",
      "  76.32    74.65\n",
      "  76.32    75.58\n",
      "  76.32    76.68\n",
      "  76.32    78.69\n",
      "  76.32    78.73\n",
      "  76.32    79.58\n",
      "  76.32    81.15\n",
      "  76.32    80.55\n",
      "  76.32    79.95\n",
      "  76.32    79.12\n",
      "  76.32    79.21\n",
      "  76.32    79.10\n",
      "  76.32    78.77\n",
      "  86.79    79.27\n",
      "  86.79    79.33\n",
      "  86.79    77.27\n",
      "  76.32    76.04\n",
      "  76.32    78.66\n",
      "  76.32    77.17\n",
      "  76.32    78.65\n",
      "  76.32    81.22\n",
      "  76.32    80.57\n",
      "  76.32    81.63\n",
      "  76.32    81.22\n",
      "  76.32    81.31\n",
      "  76.32    80.26\n",
      "  76.32    80.35\n",
      "  76.32    80.97\n",
      "  86.79    80.78\n",
      "  86.79    81.60\n",
      "  86.79    80.95\n",
      "  86.79    81.00\n",
      "  86.79    80.92\n",
      "  86.79    80.69\n",
      "  86.79    81.90\n",
      "  86.79    82.35\n",
      "  86.79    81.91\n",
      "  86.79    81.25\n",
      "  86.79    82.70\n",
      "  86.79    83.05\n",
      "  86.79    83.65\n",
      "  86.79    83.20\n",
      "  86.79    83.85\n",
      "  86.79    82.82\n",
      "  86.79    81.03\n",
      "  86.79    82.62\n",
      "  86.79    83.52\n",
      "  86.79    83.24\n",
      "  86.79    84.87\n",
      "  86.79    85.13\n",
      "  86.79    85.29\n",
      "  86.79    85.16\n",
      "  86.79    84.74\n",
      "  86.79    85.01\n",
      "  86.79    85.32\n",
      "  86.79    84.85\n",
      "  86.79    85.92\n",
      "  86.79    86.21\n",
      "  86.79    86.57\n",
      "  86.79    87.24\n",
      "  86.79    87.40\n",
      "  86.79    86.86\n",
      "  86.79    88.03\n",
      "  86.79    86.54\n",
      "  86.79    86.75\n",
      "  86.79    87.71\n",
      "  86.79    87.89\n",
      "  86.79    89.37\n",
      "  86.79    89.71\n",
      "  86.79    89.62\n",
      "  86.79    89.60\n",
      "  86.79    89.80\n",
      "  86.79    89.79\n",
      "  86.79    89.69\n",
      "  86.79    89.83\n",
      "  86.79    89.16\n",
      "  86.79    88.95\n",
      "  94.64    88.86\n",
      "  86.79    89.09\n",
      "  94.64    88.59\n",
      "  94.64    86.95\n",
      "  86.79    86.74\n",
      "  86.79    86.24\n",
      "  86.79    86.65\n",
      "  86.79    86.38\n",
      "  86.79    86.76\n",
      "  86.79    85.31\n",
      "  86.79    85.49\n",
      "  86.79    85.28\n",
      "  86.79    86.29\n",
      "  86.79    85.90\n",
      "  86.79    86.48\n",
      "  86.79    88.37\n",
      "  86.79    88.12\n",
      "  86.79    88.86\n",
      "  86.79    89.39\n",
      "  86.79    90.47\n",
      "  86.79    89.91\n",
      "  86.79    89.91\n",
      "  86.79    90.39\n",
      "  86.79    90.13\n",
      "  86.79    89.07\n",
      "  86.79    89.02\n",
      "  86.79    90.55\n",
      "  94.64    87.55\n",
      "  86.79    86.50\n",
      "  94.64    86.49\n",
      "  94.64    86.83\n",
      "  86.79    86.59\n",
      "  86.79    87.01\n",
      "  86.79    88.35\n",
      "  86.79    87.98\n",
      "  86.79    87.85\n",
      "  86.79    87.18\n",
      "  86.79    87.07\n",
      "  86.79    87.60\n",
      "  86.79    87.17\n",
      "  86.79    87.72\n",
      "  86.79    88.06\n",
      "  86.79    88.17\n",
      "  86.79    87.57\n",
      "  86.79    87.88\n",
      "  86.79    88.31\n",
      "  86.79    89.65\n",
      "  86.79    89.93\n",
      "  86.79    90.00\n",
      "  86.79    89.77\n",
      "  86.79    89.44\n",
      "  86.79    90.33\n",
      "  86.79    91.56\n",
      "  86.79    89.44\n",
      "  86.79    88.09\n",
      "  94.64    88.16\n",
      "  86.79    88.40\n",
      "  86.79    88.74\n",
      "  86.79    86.62\n",
      "  94.64    87.35\n",
      "  94.64    86.28\n",
      "  86.79    84.75\n",
      "  86.79    85.68\n",
      "  86.79    85.56\n",
      "  86.79    85.45\n",
      "  86.79    86.11\n",
      "  86.79    85.48\n",
      "  86.79    83.38\n",
      "  86.79    81.71\n",
      "  86.79    82.21\n",
      "  86.79    81.60\n",
      "  86.79    82.86\n",
      "  86.79    81.71\n",
      "  86.79    81.56\n",
      "  86.79    81.62\n",
      "  86.79    81.34\n",
      "  86.79    80.78\n",
      "  86.79    80.31\n",
      "  86.79    77.95\n",
      "  86.79    75.75\n",
      "  86.79    76.10\n",
      "  86.79    76.09\n",
      "  86.79    77.92\n",
      "  86.79    76.68\n",
      "  76.32    76.04\n",
      "  76.32    76.76\n",
      "  76.32    77.04\n",
      "  76.32    77.65\n",
      "  76.32    77.50\n",
      "  76.32    79.49\n",
      "  76.32    79.42\n",
      "  76.32    79.96\n",
      "  76.32    81.62\n",
      "  76.32    82.46\n",
      "  76.32    82.74\n",
      "  76.32    82.74\n",
      "  76.32    84.41\n",
      "  76.32    85.22\n",
      "  76.32    86.31\n",
      "  86.79    86.86\n",
      "  86.79    85.97\n",
      "  86.79    84.26\n",
      "  86.79    84.31\n",
      "  86.79    81.68\n",
      "  86.79    83.76\n",
      "  86.79    84.39\n",
      "  86.79    84.63\n",
      "  86.79    83.15\n",
      "  86.79    82.98\n",
      "  86.79    83.55\n",
      "  86.79    85.05\n",
      "  86.79    85.08\n",
      "  86.79    85.52\n",
      "  86.79    85.96\n",
      "  86.79    86.84\n",
      "  86.79    88.11\n",
      "  86.79    85.97\n",
      "  86.79    85.48\n",
      "  86.79    83.08\n",
      "  86.79    82.83\n",
      "  86.79    83.03\n",
      "  86.79    83.20\n",
      "  86.79    83.17\n",
      "  86.79    82.72\n",
      "  86.79    81.48\n",
      "  86.79    80.04\n",
      "  86.79    79.34\n",
      "  86.79    77.43\n",
      "  86.79    76.00\n",
      "  86.79    73.36\n",
      "  86.79    75.77\n",
      "  86.79    77.12\n",
      "  86.79    76.97\n",
      "  76.32    77.96\n",
      "  76.32    77.42\n",
      "  76.32    75.34\n",
      "  76.32    78.33\n",
      "  76.32    76.28\n",
      "  76.32    76.06\n",
      "  76.32    76.44\n",
      "  76.32    76.99\n",
      "  76.32    77.13\n",
      "  76.32    76.97\n",
      "  76.32    77.46\n",
      "  76.32    79.29\n",
      "  76.32    78.80\n",
      "  76.32    79.47\n",
      "  76.32    79.71\n",
      "  76.32    80.99\n",
      "  76.32    81.23\n",
      "  76.32    81.90\n",
      "  76.32    82.27\n",
      "  76.32    82.02\n",
      "  76.32    82.86\n",
      "  76.32    84.15\n",
      "  86.79    83.52\n",
      "  86.79    83.12\n",
      "  86.79    82.97\n",
      "  86.79    83.09\n",
      "  86.79    82.98\n",
      "  86.79    83.21\n",
      "  86.79    82.87\n",
      "  86.79    83.70\n",
      "  86.79    84.10\n",
      "  86.79    83.31\n",
      "  86.79    83.88\n",
      "  86.79    83.94\n",
      "  86.79    84.19\n",
      "  86.79    84.18\n",
      "  86.79    85.10\n",
      "  86.79    86.16\n",
      "  86.79    87.07\n",
      "  86.79    86.79\n",
      "  86.79    87.52\n",
      "  86.79    87.92\n",
      "  86.79    86.17\n",
      "  86.79    84.82\n",
      "  86.79    83.80\n",
      "  86.79    82.17\n",
      "  86.79    79.75\n",
      "  86.79    80.31\n",
      "  86.79    80.12\n",
      "  86.79    81.29\n",
      "  86.79    80.70\n",
      "  86.79    80.27\n",
      "  86.79    80.94\n",
      "  76.32    80.84\n",
      "  76.32    80.09\n",
      "  76.32    81.04\n",
      "  86.79    80.60\n",
      "  86.79    81.58\n",
      "  86.79    82.45\n",
      "  86.79    82.72\n",
      "  86.79    83.34\n",
      "  86.79    84.06\n",
      "  86.79    84.93\n",
      "  86.79    85.52\n",
      "  86.79    85.80\n",
      "  86.79    85.68\n",
      "  86.79    85.11\n",
      "  86.79    85.28\n",
      "  86.79    84.26\n",
      "  86.79    84.07\n",
      "  86.79    83.62\n",
      "  86.79    84.36\n",
      "  86.79    85.00\n",
      "  86.79    86.23\n",
      "  86.79    86.66\n",
      "  86.79    86.46\n",
      "  86.79    86.21\n",
      "  86.79    86.13\n",
      "  86.79    85.68\n",
      "  86.79    85.93\n",
      "  86.79    86.33\n",
      "  86.79    87.86\n",
      "  86.79    88.58\n",
      "  86.79    88.70\n",
      "  86.79    88.64\n",
      "  86.79    88.51\n",
      "  86.79    89.09\n",
      "  86.79    87.33\n",
      "  86.79    87.42\n",
      "  86.79    87.58\n",
      "  86.79    88.88\n",
      "  86.79    87.33\n",
      "  86.79    87.59\n",
      "  86.79    87.20\n",
      "  86.79    87.36\n",
      "  86.79    86.76\n",
      "  86.79    86.72\n",
      "  86.79    87.70\n",
      "  86.79    86.82\n",
      "  86.79    86.49\n",
      "  86.79    86.50\n",
      "  86.79    86.44\n",
      "  86.79    86.80\n",
      "  86.79    87.09\n",
      "  86.79    87.08\n",
      "  86.79    87.15\n",
      "  86.79    89.12\n",
      "  86.79    92.41\n",
      "  86.79    92.13\n",
      "  86.79    92.39\n",
      "  86.79    92.88\n",
      "  86.79    91.52\n",
      "  86.79    91.71\n",
      "  86.79    92.15\n",
      "  94.64    92.41\n",
      "  94.64    91.89\n",
      "  94.64    92.60\n",
      "  94.64    93.18\n",
      "  94.64    94.37\n",
      "  94.64    94.90\n",
      "  94.64    93.53\n",
      "  94.64    94.62\n",
      "  94.64    91.35\n",
      "  94.64    92.85\n",
      "  94.64    92.85\n",
      "  94.64    93.80\n",
      "  94.64    96.22\n",
      "  94.64    97.92\n",
      "  94.64    97.57\n",
      "  94.64    97.36\n",
      "  94.64    98.11\n",
      "  94.64    99.47\n",
      "  94.64    100.42\n",
      "  94.64    100.69\n",
      "  94.64    100.63\n",
      "  94.64    99.73\n",
      "  94.64    99.10\n",
      "  94.64    99.58\n",
      "  94.64    98.22\n",
      "  94.64    98.27\n",
      "  94.64    97.38\n",
      "  94.64    94.83\n",
      "  94.64    94.25\n",
      "  94.64    94.68\n",
      "  94.64    93.34\n",
      "  94.64    93.46\n",
      "  94.64    93.05\n",
      "  94.64    94.28\n",
      "  94.64    94.57\n",
      "  94.64    91.11\n",
      "  94.64    92.55\n",
      "  94.64    92.81\n",
      "  94.64    94.87\n",
      "  94.64    95.14\n",
      "  94.64    93.25\n",
      "  94.64    94.55\n",
      "  94.64    92.03\n",
      "  94.64    93.64\n",
      "  94.64    94.17\n",
      "  94.64    95.99\n",
      "  94.64    95.50\n",
      "  94.64    95.90\n",
      "  94.64    96.68\n",
      "  94.64    94.16\n",
      "  94.64    95.27\n",
      "  94.64    94.88\n",
      "  94.64    95.13\n",
      "  94.64    96.33\n",
      "  94.64    96.40\n",
      "  94.64    96.10\n",
      "  94.64    96.47\n",
      "  94.64    98.50\n",
      "  94.64    100.67\n",
      "  94.64    99.29\n",
      "  94.64    94.77\n",
      "  94.64    94.80\n",
      "  94.64    96.05\n",
      "  94.64    96.55\n",
      "  94.64    96.32\n",
      "  94.64    99.67\n",
      "  94.64    99.56\n",
      "  94.64    98.65\n",
      "  94.64    97.68\n",
      "  94.64    97.26\n",
      "  94.64    98.35\n",
      "  94.64    99.69\n",
      "  94.64    98.78\n",
      "  94.64    97.09\n",
      "  94.64    96.39\n",
      "  94.64    95.65\n",
      "  94.64    92.88\n",
      "  94.64    94.24\n",
      "  94.64    96.27\n",
      "  94.64    96.06\n",
      "  94.64    94.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  94.64    94.43\n",
      "  94.64    95.62\n",
      "  94.64    96.35\n",
      "  94.64    95.42\n",
      "  94.64    95.00\n",
      "  94.64    95.13\n",
      "  94.64    95.40\n",
      "  94.64    95.68\n",
      "  94.64    95.23\n",
      "  94.64    94.94\n",
      "  94.64    98.29\n",
      "  94.64    97.98\n",
      "  94.64    95.49\n",
      "  94.64    95.78\n",
      "  94.64    95.70\n",
      "  94.64    97.08\n",
      "  94.64    96.79\n",
      "  94.64    96.27\n",
      "  94.64    95.65\n",
      "  94.64    95.48\n",
      "  94.64    96.94\n",
      "  94.64    97.53\n",
      "  94.64    97.66\n",
      "  94.64    99.47\n",
      "  94.64    99.39\n",
      "  94.64    100.19\n",
      "  94.64    100.18\n",
      "  94.64    100.50\n",
      "  94.64    101.48\n",
      "  94.64    101.94\n",
      "  94.64    102.55\n",
      "  94.64    101.62\n",
      "  94.64    101.26\n",
      "  94.64    101.52\n",
      "  94.64    101.70\n",
      "  94.64    101.14\n",
      "  94.64    101.67\n",
      "  94.64    101.34\n",
      "  94.64    101.36\n",
      "  94.64    102.07\n",
      "  94.64    101.55\n",
      "  94.64    102.09\n",
      "  94.64    101.52\n",
      "  94.64    101.49\n",
      "  94.64    100.79\n",
      "  94.64    101.48\n",
      "  94.64    101.82\n",
      "  94.64    102.53\n",
      "  94.64    103.31\n",
      "  94.64    103.23\n",
      "  94.64    104.30\n",
      "  94.64    104.86\n",
      "  94.64    104.45\n",
      "  94.64    103.98\n",
      "  94.64    105.05\n",
      "  112.95    105.24\n",
      "  112.95    104.30\n",
      "  112.95    104.38\n",
      "  112.95    105.08\n",
      "  112.95    105.53\n",
      "  112.95    105.46\n",
      "  112.95    103.71\n",
      "  112.95    103.14\n",
      "  112.95    104.62\n",
      "  112.95    104.12\n",
      "  112.95    104.37\n",
      "  112.95    103.84\n",
      "  112.95    105.12\n",
      "  112.95    105.56\n",
      "  112.95    106.53\n",
      "  112.95    106.47\n",
      "  112.95    106.37\n",
      "  112.95    106.84\n",
      "  112.95    107.41\n",
      "  112.95    106.99\n",
      "  112.95    108.31\n",
      "  112.95    112.41\n",
      "  112.95    113.01\n",
      "  112.95    113.50\n",
      "  112.95    114.80\n",
      "  112.95    115.65\n",
      "  112.95    113.51\n",
      "  112.95    112.91\n",
      "  112.95    111.42\n",
      "  112.95    112.79\n",
      "  112.95    111.88\n",
      "  112.95    111.16\n",
      "  112.95    111.49\n",
      "  112.95    113.25\n",
      "  112.95    112.73\n",
      "  112.95    112.34\n",
      "  112.95    111.58\n",
      "  112.95    112.25\n",
      "  112.95    111.82\n",
      "  112.95    109.55\n",
      "  112.95    110.15\n",
      "  112.95    104.72\n",
      "  112.95    99.94\n",
      "  112.95    107.32\n",
      "  112.95    107.27\n",
      "  112.95    113.41\n",
      "  112.95    111.20\n",
      "  112.95    107.69\n",
      "  112.95    103.03\n",
      "  94.64    102.04\n",
      "  94.64    96.80\n",
      "  112.95    86.79\n",
      "  112.95    94.05\n",
      "  112.95    83.54\n",
      "  112.95    93.05\n",
      "  112.95    89.67\n",
      "  94.64    86.17\n",
      "  94.64    78.83\n",
      "  94.64    71.35\n",
      "  94.64    81.26\n",
      "  86.79    85.15\n",
      "  94.64    91.87\n",
      "  94.64    90.85\n",
      "  86.79    97.37\n",
      "  86.79    92.98\n",
      "  76.32    90.35\n",
      "  86.79    92.01\n",
      "  94.64    93.24\n",
      "  94.64    99.48\n",
      "  94.64    98.84\n",
      "  94.64    101.97\n",
      "  94.64    105.68\n",
      "  94.64    101.14\n",
      "  94.64    105.32\n",
      "  94.64    103.80\n",
      "  94.64    106.06\n",
      "  112.95    108.93\n",
      "  112.95    107.50\n",
      "  112.95    103.08\n",
      "  112.95    102.46\n",
      "  112.95    101.69\n",
      "  112.95    103.43\n",
      "  112.95    109.31\n",
      "  112.95    108.90\n",
      "  112.95    109.28\n",
      "  112.95    107.39\n",
      "  112.95    104.40\n",
      "  94.64    103.92\n",
      "  94.64    106.57\n",
      "  112.95    103.43\n",
      "  112.95    105.10\n",
      "  112.95    105.35\n",
      "  112.95    106.97\n",
      "  112.95    106.24\n",
      "  112.95    106.63\n",
      "  112.95    107.20\n",
      "  112.95    109.75\n",
      "  112.95    112.55\n",
      "  112.95    110.29\n",
      "  112.95    112.33\n",
      "  112.95    111.62\n",
      "  112.95    112.94\n",
      "  112.95    113.86\n",
      "  112.95    112.80\n",
      "  112.95    113.95\n",
      "  112.95    116.00\n",
      "  112.95    116.41\n",
      "  112.95    116.76\n",
      "  112.95    116.86\n",
      "  112.95    115.48\n",
      "  112.95    117.41\n",
      "  112.95    118.78\n",
      "  112.95    117.59\n",
      "  112.95    117.52\n",
      "  112.95    111.35\n",
      "  112.95    113.22\n",
      "  112.95    115.40\n",
      "  112.95    116.54\n",
      "  112.95    116.15\n",
      "  112.95    117.29\n",
      "  112.95    116.84\n",
      "  112.95    117.70\n",
      "  112.95    116.61\n",
      "  112.95    113.35\n",
      "  112.95    116.70\n",
      "  112.95    113.88\n",
      "  112.95    115.58\n",
      "  112.95    117.47\n",
      "  112.95    118.73\n",
      "  112.95    118.05\n",
      "  112.95    119.05\n",
      "  112.95    118.45\n",
      "  112.95    119.66\n",
      "  112.95    118.77\n",
      "  112.95    120.82\n",
      "  112.95    120.94\n",
      "  112.95    122.71\n",
      "  128.65    124.71\n",
      "  112.95    124.90\n",
      "  128.65    126.29\n",
      "  112.95    129.10\n",
      "  128.65    128.81\n",
      "  128.65    131.85\n",
      "  128.65    129.21\n",
      "  128.65    128.37\n",
      "  128.65    128.34\n",
      "  128.65    126.00\n",
      "  128.65    128.81\n",
      "  128.65    127.72\n",
      "  128.65    129.11\n",
      "  128.65    128.16\n",
      "  128.65    127.52\n",
      "  128.65    128.17\n",
      "  128.65    128.51\n",
      "  128.65    130.64\n",
      "  128.65    129.32\n",
      "  128.65    128.28\n",
      "  128.65    128.23\n",
      "  128.65    128.09\n",
      "  128.65    127.07\n",
      "  128.65    128.12\n",
      "  128.65    127.87\n",
      "  128.65    127.69\n",
      "  128.65    128.27\n",
      "  128.65    127.74\n",
      "  128.65    129.37\n",
      "  128.65    127.92\n",
      "  128.65    130.32\n",
      "  128.65    129.64\n",
      "  128.65    129.63\n",
      "  128.65    132.17\n",
      "  128.65    132.56\n",
      "  128.65    134.98\n",
      "  128.65    131.02\n",
      "  128.65    128.10\n",
      "  128.65    124.32\n",
      "  128.65    127.02\n",
      "  128.65    123.28\n",
      "  128.65    124.06\n",
      "  141.74    125.34\n",
      "  128.65    126.49\n",
      "  128.65    125.64\n",
      "  128.65    122.82\n",
      "  128.65    120.85\n",
      "  128.65    120.46\n",
      "  128.65    121.71\n",
      "  128.65    118.17\n",
      "  128.65    119.72\n",
      "  128.65    122.41\n",
      "  128.65    123.74\n",
      "  128.65    119.80\n",
      "  128.65    121.11\n",
      "  128.65    122.31\n",
      "  128.65    121.93\n",
      "  112.95    123.24\n",
      "  128.65    121.96\n",
      "  128.65    121.38\n",
      "  128.65    122.98\n",
      "  128.65    123.43\n",
      "  128.65    124.73\n",
      "  128.65    124.73\n",
      "  128.65    125.99\n",
      "  128.65    126.74\n",
      "  128.65    127.19\n",
      "  128.65    125.82\n",
      "  128.65    127.31\n",
      "  128.65    130.65\n",
      "  128.65    128.40\n",
      "  128.65    127.44\n",
      "  128.65    125.72\n",
      "  128.65    123.47\n",
      "  128.65    120.14\n",
      "  128.65    120.42\n",
      "  128.65    119.41\n",
      "  128.65    121.58\n",
      "  128.65    123.28\n",
      "  128.65    127.62\n",
      "  128.65    131.47\n",
      "  128.65    131.46\n",
      "  112.95    127.99\n",
      "  112.95    125.47\n",
      "  128.65    128.10\n",
      "  128.65    125.20\n",
      "  128.65    124.18\n",
      "  128.65    123.89\n",
      "  128.65    122.71\n",
      "  128.65    121.13\n",
      "  128.65    123.13\n",
      "  128.65    124.68\n",
      "  128.65    124.37\n",
      "  128.65    125.61\n",
      "  128.65    125.67\n",
      "  128.65    125.46\n",
      "  128.65    126.32\n",
      "  128.65    128.22\n",
      "  128.65    127.67\n",
      "  128.65    123.74\n",
      "  128.65    124.14\n",
      "  128.65    127.37\n",
      "  128.65    127.46\n",
      "  128.65    124.93\n",
      "  128.65    123.83\n",
      "  128.65    124.50\n",
      "  128.65    122.89\n",
      "  128.65    126.11\n",
      "  128.65    125.92\n",
      "  128.65    127.31\n",
      "  128.65    127.41\n",
      "  128.65    126.86\n",
      "  128.65    128.70\n",
      "  128.65    126.76\n",
      "  128.65    127.43\n",
      "  128.65    127.65\n",
      "  128.65    127.94\n",
      "  128.65    128.93\n",
      "  128.65    131.51\n",
      "  128.65    130.79\n",
      "  128.65    130.75\n",
      "  128.65    134.14\n",
      "  128.65    135.53\n",
      "  128.65    137.52\n",
      "  128.65    139.59\n",
      "  128.65    140.60\n",
      "  128.65    141.17\n",
      "  128.65    140.81\n",
      "  128.65    138.74\n",
      "  141.74    140.94\n",
      "  141.74    142.34\n",
      "  141.74    140.09\n",
      "  141.74    139.12\n",
      "  141.74    140.98\n",
      "  141.74    139.82\n",
      "  141.74    139.89\n",
      "  141.74    137.74\n",
      "  141.74    134.02\n",
      "  141.74    137.32\n",
      "  141.74    141.29\n",
      "  141.74    140.84\n",
      "  141.74    142.24\n",
      "  141.74    141.27\n",
      "  141.74    141.13\n",
      "  141.74    141.80\n",
      "  141.74    141.15\n",
      "  141.74    141.05\n",
      "  141.74    140.67\n",
      "  146.97    142.65\n",
      "  146.97    143.35\n",
      "  146.97    143.54\n",
      "  146.97    143.09\n",
      "  141.74    140.31\n",
      "  141.74    139.04\n",
      "  146.97    140.67\n",
      "  146.97    139.02\n",
      "  146.97    137.01\n",
      "  146.97    140.55\n",
      "  146.97    139.34\n",
      "  141.74    135.44\n",
      "  141.74    136.72\n",
      "  141.74    143.36\n",
      "  141.74    143.65\n",
      "  141.74    145.29\n",
      "  141.74    143.21\n",
      "  141.74    143.25\n",
      "  141.74    143.57\n",
      "  141.74    145.13\n",
      "  141.74    144.61\n",
      "  146.97    143.17\n",
      "  146.97    144.08\n",
      "  146.97    144.88\n",
      "  146.97    146.25\n",
      "  146.97    146.70\n",
      "  146.97    146.46\n",
      "  146.97    145.70\n",
      "  146.97    149.83\n",
      "  146.97    149.95\n",
      "  146.97    146.58\n",
      "  146.97    146.59\n",
      "  146.97    149.96\n",
      "  146.97    151.20\n",
      "  146.97    151.76\n",
      "  146.97    149.89\n",
      "  146.97    152.61\n",
      "  146.97    155.18\n",
      "  146.97    155.17\n",
      "  146.97    157.00\n",
      "  160.05    156.51\n",
      "  160.05    159.10\n",
      "  160.05    159.22\n",
      "  160.05    157.69\n",
      "  160.05    158.74\n",
      "  160.05    158.38\n",
      "  160.05    158.78\n",
      "  160.05    161.51\n",
      "  160.05    159.08\n",
      "  160.05    159.85\n",
      "  160.05    158.71\n",
      "  160.05    160.93\n",
      "  160.05    160.59\n",
      "  160.05    161.53\n",
      "  160.05    162.57\n",
      "  160.05    162.58\n",
      "  160.05    162.61\n",
      "  160.05    163.59\n",
      "  160.05    162.56\n",
      "  160.05    158.79\n",
      "  160.05    157.42\n",
      "  160.05    159.95\n",
      "  160.05    163.39\n",
      "  160.05    162.78\n",
      "  160.05    160.98\n",
      "  160.05    159.99\n",
      "  160.05    162.49\n",
      "  160.05    162.90\n",
      "  160.05    163.95\n",
      "  160.05    163.34\n",
      "  160.05    164.47\n",
      "  160.05    165.00\n",
      "  160.05    166.47\n",
      "  160.05    163.48\n",
      "  160.05    165.85\n",
      "  160.05    167.07\n",
      "  175.75    169.22\n",
      "  175.75    167.90\n",
      "  175.75    167.96\n",
      "  175.75    168.12\n",
      "  175.75    167.90\n",
      "  175.75    172.48\n",
      "  175.75    174.68\n",
      "  175.75    175.81\n",
      "  175.75    176.87\n",
      "  175.75    179.30\n",
      "  175.75    175.32\n",
      "  175.75    178.29\n",
      "  175.75    178.21\n",
      "  175.75    177.48\n",
      "  175.75    177.32\n",
      "  175.75    177.59\n",
      "  175.75    176.63\n",
      "  175.75    176.37\n",
      "  175.75    175.32\n",
      "  175.75    175.55\n",
      "  188.83    177.40\n",
      "  188.83    175.88\n",
      "  188.83    175.68\n",
      "  188.83    173.61\n",
      "  188.83    175.29\n",
      "  188.83    179.16\n",
      "  188.83    178.60\n",
      "  188.83    177.60\n",
      "  188.83    178.16\n",
      "  188.83    178.06\n",
      "  175.75    176.67\n",
      "  175.75    180.41\n",
      "  188.83    185.77\n",
      "  188.83    184.84\n",
      "  188.83    187.25\n",
      "  188.83    186.07\n",
      "  188.83    185.18\n",
      "  188.83    185.03\n",
      "  188.83    186.17\n",
      "  188.83    186.22\n",
      "  188.83    187.92\n",
      "  188.83    188.16\n",
      "  188.83    188.84\n",
      "  188.83    188.17\n",
      "  188.83    188.21\n",
      "  188.83    188.17\n",
      "  188.83    188.35\n",
      "  188.83    188.80\n",
      "  188.83    189.57\n",
      "  188.83    190.47\n",
      "  188.83    191.65\n",
      "  188.83    189.47\n",
      "  188.83    186.38\n",
      "  188.83    187.51\n",
      "  188.83    188.16\n",
      "  188.83    190.02\n",
      "  188.83    190.34\n",
      "  188.83    191.11\n",
      "  188.83    190.65\n",
      "  188.83    192.95\n",
      "  188.83    193.57\n",
      "  188.83    195.25\n",
      "  188.83    197.42\n",
      "  188.83    197.37\n",
      "  188.83    197.99\n",
      "  188.83    195.94\n",
      "  188.83    197.89\n",
      "  188.83    197.94\n",
      "  188.83    196.04\n",
      "  188.83    194.32\n",
      "  188.83    195.55\n",
      "  188.83    195.84\n",
      "  188.83    195.43\n",
      "  188.83    192.90\n",
      "  188.83    190.98\n",
      "RMSE =  26.495966112171587\n",
      "Testing Set R-Square= 0.9738900246702215\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time=[0]*len(forecast)\n",
    "f = open(\"result_fuzzy_lstm.txt\", \"w\")\n",
    "    \n",
    "print(\"\\npredicted vs actual output\")\n",
    "f.write(\"predicted vs actual output\\n\")\n",
    "for i in range(len(forecast)):\n",
    "    print(\" \", '{0:.2f}'.format(fuzzyvalue[i]),\"  \",'{0:.2f}'.format(testY[i][0]))\n",
    "    f.write(str( '{0:.2f}'.format(fuzzyvalue[i])))\n",
    "    f.write(\"  \")\n",
    "    f.write(str('{0:.2f}'.format(testY[i][0])))\n",
    "    f.write(\"\\n\")\n",
    "    time[i]=i\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(time, fuzzyvalue, 'r-')\n",
    "plt.plot(time, testY, 'b-')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Normal Density\")\n",
    "    \n",
    "from sklearn.metrics import mean_squared_error\n",
    "rms = mean_squared_error(testY, fuzzyvalue)\n",
    "print(\"RMSE = \",rms)\n",
    "f.write(\"RMSE = \")\n",
    "f.write(str(rms))\n",
    "TestR2Value = r2_score(testY,fuzzyvalue)\n",
    "print(\"Testing Set R-Square=\", TestR2Value)\n",
    "f.write(\"R-Square=\")\n",
    "f.write(str(TestR2Value))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look ahead strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use ga to find best look ahead period\n",
    "predictedClose=fuzzyvalue\n",
    "actualClose=testY\n",
    "totalcash=100000\n",
    "risk=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    a=int(x[0])\n",
    "    b=int(x[1])\n",
    "    print(\"a: \",a,\" b: \",b)\n",
    "    \n",
    "    cash = totalcash\n",
    "    leverageN=0\n",
    "    leverageAmt=risk*totalcash*0.1\n",
    "    tempq=0\n",
    "    q=0\n",
    "    \n",
    "    for i in range(len(forecast)):\n",
    "#         print(i)\n",
    "        if i < (len(forecast))-a and i < (len(forecast))-b:\n",
    "\n",
    "            ## buy - if LARGE\n",
    "            if ((predictedClose[i+a]>predictedClose[i]) \n",
    "                and ((cash*risk)+leverageAmt)>actualClose[i]\n",
    "                and (cash*risk>actualClose[i])):\n",
    "                tempq = (((cash*risk)+leverageAmt)/data_train['Close'][i])\n",
    "                tempq = math.floor(tempq)\n",
    "                cash = (cash-(tempq * data_train['Close'][i]))+leverageAmt\n",
    "                q = tempq + q\n",
    "                leverageN=leverageN+1\n",
    "#                 print(\"BOUGHT\")\n",
    "\n",
    "            ## sell - if LOW\n",
    "            elif ((predictedClose[i+b]<predictedClose[i]) and q!=0):\n",
    "                cash = (q * actualClose[i][0]) + cash\n",
    "                q = 0\n",
    "#                 print(\"SOLD\")\n",
    "\n",
    "        if (i == len(forecast) - 1):\n",
    "            leverageFee=(leverageAmt*leverageN)\n",
    "            for j in range(4):\n",
    "                leverageFee=(leverageFee*1.06)\n",
    "            print(\"total assets:\", cash + (q * actualClose[i][0]) - leverageFee)\n",
    "            return -(cash + (q * actualClose[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  5  b:  2\n",
      "total assets: 509397.4986214917\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  2  b:  5\n",
      "total assets: 369229.10429280513\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  7\n",
      "total assets: 287434.26622181875\n",
      "a:  2  b:  7\n",
      "total assets: 284159.1266608178\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  3  b:  6\n",
      "total assets: 343929.9376057934\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  5  b:  6\n",
      "total assets: 322708.216141787\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  1  b:  6\n",
      "total assets: 304033.8732900805\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  1  b:  7\n",
      "total assets: 270894.03435422847\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  3  b:  4\n",
      "total assets: 507034.9976962768\n",
      "a:  6  b:  7\n",
      "total assets: 287434.26622181875\n",
      "a:  2  b:  7\n",
      "total assets: 284159.1266608178\n",
      "a:  2  b:  4\n",
      "total assets: 430023.86386769527\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  6  b:  7\n",
      "total assets: 287434.26622181875\n",
      "a:  5  b:  7\n",
      "total assets: 275326.9188998901\n",
      "a:  5  b:  7\n",
      "total assets: 275326.9188998901\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  1  b:  3\n",
      "total assets: 389745.43540166743\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  2  b:  5\n",
      "total assets: 369229.10429280513\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  3  b:  7\n",
      "total assets: 304390.91572606197\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  5  b:  2\n",
      "total assets: 509397.4986214917\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  2  b:  7\n",
      "total assets: 284159.1266608178\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  5  b:  2\n",
      "total assets: 509397.4986214917\n",
      "a:  3  b:  3\n",
      "total assets: 508243.6474036864\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  2  b:  7\n",
      "total assets: 284159.1266608178\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  2  b:  6\n",
      "total assets: 325140.1328024804\n",
      "a:  5  b:  6\n",
      "total assets: 322708.216141787\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  2  b:  7\n",
      "total assets: 284159.1266608178\n",
      "a:  1  b:  4\n",
      "total assets: 393068.1691045947\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  6  b:  6\n",
      "total assets: 329051.659501162\n",
      "a:  1  b:  3\n",
      "total assets: 389745.43540166743\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "||________________________________________________ 4.2% GA is running...a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  2  b:  5\n",
      "total assets: 369229.10429280513\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  2  b:  4\n",
      "total assets: 430023.86386769527\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  2  b:  4\n",
      "total assets: 430023.86386769527\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  7\n",
      "total assets: 275326.9188998901\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  3  b:  2\n",
      "total assets: 547926.4620295434\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  1  b:  4\n",
      "total assets: 393068.1691045947\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  4\n",
      "total assets: 479349.82322033925\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  6  b:  4\n",
      "total assets: 479349.82322033925\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  3  b:  5\n",
      "total assets: 433455.77328595205\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "||||______________________________________________ 8.3% GA is running...a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  3  b:  5\n",
      "total assets: 433455.77328595205\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  5  b:  2\n",
      "total assets: 509397.4986214917\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  3  b:  2\n",
      "total assets: 547926.4620295434\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  2  b:  7\n",
      "total assets: 284159.1266608178\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  4\n",
      "total assets: 479349.82322033925\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "||||||____________________________________________ 12.5% GA is running...a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  3  b:  3\n",
      "total assets: 508243.6474036864\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  3  b:  5\n",
      "total assets: 433455.77328595205\n",
      "a:  1  b:  5\n",
      "total assets: 345258.16023160884\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  2  b:  5\n",
      "total assets: 369229.10429280513\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  2  b:  2\n",
      "total assets: 455250.4358530907\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "||||||||__________________________________________ 16.7% GA is running...a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  2  b:  5\n",
      "total assets: 369229.10429280513\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "||||||||||________________________________________ 20.8% GA is running...a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  3  b:  2\n",
      "total assets: 547926.4620295434\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  2\n",
      "total assets: 509397.4986214917\n",
      "||||||||||||______________________________________ 25.0% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  2\n",
      "total assets: 509304.3516710375\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "|||||||||||||||___________________________________ 29.2% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "|||||||||||||||||_________________________________ 33.3% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "|||||||||||||||||||_______________________________ 37.5% GA is running...a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  2  b:  3\n",
      "total assets: 412408.4541851537\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||_____________________________ 41.7% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "|||||||||||||||||||||||___________________________ 45.8% GA is running...a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "|||||||||||||||||||||||||_________________________ 50.0% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  4\n",
      "total assets: 479349.82322033925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  2\n",
      "total assets: 509397.4986214917\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "|||||||||||||||||||||||||||_______________________ 54.2% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "|||||||||||||||||||||||||||||_____________________ 58.3% GA is running...a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "|||||||||||||||||||||||||||||||___________________ 62.5% GA is running...a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  5  b:  7\n",
      "total assets: 275326.9188998901\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "|||||||||||||||||||||||||||||||||_________________ 66.7% GA is running...a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  6  b:  4\n",
      "total assets: 479349.82322033925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "|||||||||||||||||||||||||||||||||||_______________ 70.8% GA is running...a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "||||||||||||||||||||||||||||||||||||||____________ 75.0% GA is running...a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  6  b:  3\n",
      "total assets: 490081.1647147826\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  6\n",
      "total assets: 322708.216141787\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  4\n",
      "total assets: 479349.82322033925\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "||||||||||||||||||||||||||||||||||||||||__________ 79.2% GA is running...a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  5  b:  3\n",
      "total assets: 495615.5260907421\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  7\n",
      "total assets: 296085.83695393545\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "||||||||||||||||||||||||||||||||||||||||||________ 83.3% GA is running...a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  3\n",
      "total assets: 611685.5506553344\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  3  b:  4\n",
      "total assets: 507034.9976962768\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "||||||||||||||||||||||||||||||||||||||||||||______ 87.5% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  5\n",
      "total assets: 415749.4186744384\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  4\n",
      "total assets: 480853.7405031298\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  5\n",
      "total assets: 414447.0160928052\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "||||||||||||||||||||||||||||||||||||||||||||||____ 91.7% GA is running...a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  4\n",
      "total assets: 516064.864847688\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||__ 95.8% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  6\n",
      "total assets: 341006.25613507314\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  3  b:  1\n",
      "total assets: 563273.3900552075\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  5\n",
      "total assets: 432323.59917759756\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  3  b:  2\n",
      "total assets: 547926.4620295434\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||| 100.0% GA is running...a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  2\n",
      "total assets: 551203.1823914037\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  6  b:  1\n",
      "total assets: 563463.0973104539\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  2  b:  1\n",
      "total assets: 409001.9543155395\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  7  b:  7\n",
      "total assets: 437324.66377362295\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  1  b:  1\n",
      "total assets: 422167.27914403804\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  5  b:  1\n",
      "total assets: 562264.8490201244\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  3\n",
      "total assets: 498377.9460181884\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  4\n",
      "total assets: 506839.3442400072\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  5\n",
      "total assets: 472044.41729908925\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  2\n",
      "total assets: 532850.4614732836\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  6\n",
      "total assets: 488583.95745053457\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  1  b:  3\n",
      "total assets: 389745.43540166743\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      "a:  7  b:  1\n",
      "total assets: 604696.7747694848\n",
      "a:  4  b:  1\n",
      "total assets: 574281.8284970531\n",
      " The best solution found:                                                                           \n",
      " [7. 1.]\n",
      "\n",
      " Objective function:\n",
      " -1184173.6994094849\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "varbound=np.array([[1,step],[1,step]])\n",
    "vartype=np.array([['int'],['int']])\n",
    "\n",
    "ga_model=ga(function=test,dimension=2,variable_type_mixed=vartype,variable_boundaries=varbound,function_timeout=500)\n",
    "\n",
    "ga_model.run()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
